{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e893c60-b6e3-4e1a-b329-c10d0baf61dc",
   "metadata": {},
   "source": [
    "# SPMpy \n",
    "* Authors : Dr. Jewook Park at CNMS, ORNL\n",
    "    * Center for Nanophase Materials Sciences (CNMS), Oak Ridge National Laboratory (ORNL)\n",
    "    * email :  parkj1@ornl.gov\n",
    "        \n",
    "> **SPMpy** is a python package to analysis scanning probe microscopy (SPM) data analysis, such as scanning tunneling microscopy and spectroscopy (STM/S) data and atomic force microscopy (AFM) images, which are inherently multidimensional. SPMpy exploits recent image processing(a.k.a. Computer Vision) techniques, and utilzes [building blocks](https://scipy-lectures.org/intro/intro.html#the-scientific-python-ecosystem) and excellent visualization tools available in the [scientific python ecosystem](https://holoviz.org/index.html). Many parts are inspired by well-known SPM data analysis programs, for example, [Wsxm](http://www.wsxm.eu/) and [Gwyddion](http://gwyddion.net/). SPMpy is trying to apply lessons from [Fundamentals in Data Visualization](https://clauswilke.com/dataviz/).\n",
    "\n",
    ">  **SPMpy** is an open-source project. (Github: https://github.com/Jewook-Park/SPMPY )\n",
    "> * Contributions, comments, ideas, and error reports are always welcome. Please use the Github page or email parkj1@ornl.gov. Comments & remarks should be in Korean or English. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d4ac66-b3df-4bc8-80e2-b9165fbe1dfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# file_loading functions \n",
    "\n",
    "## 0. Choose the working folder\n",
    "## 1. Check file_list (DataFrame) \n",
    "*  *def* files_in_folder(path)\n",
    "\n",
    "## 2. Image to xarray \n",
    "*  *def* img2xr\n",
    "    * 2D image (topography & LDOS) to xarray\n",
    "    * input: nanonis 2D data (*.sxm)\n",
    "    * output : Xarray (_xr) with attributes \n",
    "    * nanonis (sxm) $\\to $ numpy $\\to $ pd.DataFrame(_df) $\\to $ xr.DataSet (_xr)\n",
    "    * (Xarray) attributes \n",
    "        * title, X_spacing, Y_spacing, freq_X_spacing, freq_Y_spacing\n",
    "        * attributes can be added later. \n",
    "\n",
    "## 3. Grid 3D to xarray \n",
    "*  *def* grid2xr* \n",
    "    * 3D data (grid spectroscopy) to xarray\n",
    "    * input: nanonis grid3d data set (*.3ds)\n",
    "    * output: Xarray (_xr) with attributes\n",
    "    * nanonis 3D data set (3ds)  $\\to $ numpy $\\to$ pd.DataFrame(_df) $\\to$ xr.DataSet (_xr) \n",
    "    * (Xarray) attributes\n",
    "        * title, X_spacing, Y_spacing, bias mV info, freq_X_spacing, freq_Y_spacing\n",
    "        * attributes can be added later. * attributes can be added later. \n",
    "        \n",
    "## 4. Line spectroscopy (1D grid) to xarray   \n",
    "*  *def* gridline2xr* \n",
    "    * in case of line spectroscopy: step_dy = 0 $\\to$ **error** \n",
    "    * input: *.3ds file (Line spectroscopy) \n",
    "    * output: Xarray (_xr) with attributes\n",
    "    * nanonis 3D data set (3ds)  $\\to $ numpy $\\to$ pd.DataFrame(_df) $\\to$ xr.DataSet (_xr) \n",
    "    * simply not using the step_dx\n",
    "\n",
    "\n",
    "## 5. Gwyddion 2D image to PANDAS Dataframe or Xarray\n",
    "### 5.1. gwy_image2df : gwy file name \n",
    "* Gwyddion data container to PANDAS DataFrame\n",
    "* input: *.gwy file\n",
    "    * gwyddion 2D image data (*gwy) $\\to $ numpy $\\to $  pd.DataFrame(_df)\n",
    "* output: PANDAS DataFrame\n",
    "    \n",
    "\n",
    "### 5.2. gwy_df_channel2xr : Choose a data channe in gwy_df \n",
    "* Gwyddion data container to Xarray DataArray\n",
    "* input: gwy_df dataframe & channel number ( N=0)\n",
    "    * pd.DataFrame(_df) $\\to $  xarray Dataset (_xr)\n",
    "* output: Xarray DataSet \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d3179-1d93-4b84-968b-77fad1f7a7b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <font color=blue>0. Choose the working folder </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8be2ae-1003-479b-91d0-bca494c24f6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# check all necessary package\n",
    "#############################\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from warnings import warn\n",
    "\n",
    "try:\n",
    "    from ipyfilechooser import FileChooser\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named ipyfilechooser')\n",
    "    %from ipyfilechooser import FileChooser\n",
    "\n",
    "try:\n",
    "    import xrft\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named xrft')\n",
    "    !pip install xrft \n",
    "    import xrft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ec26b8-0d42-42d7-a7cd-16f20995ac1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0e4a5369a043168137858bada521b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='C:\\Users\\gkp\\OneDrive - Oak Ridge National Laboratory\\Research\\Data Analysis (python)\\SPMpy_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################################\n",
    "# Create and display a FileChooser widget #\n",
    "###########################################\n",
    "file_chooser = FileChooser('')\n",
    "display(file_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d115dad9-33c2-41f7-8175-5d0c3a9a1ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_path =  C:\\Users\\gkp\\OneDrive - Oak Ridge National Laboratory\\mK STM DATA\\2023\\0506 FeTe0.55Se0.45_new_batch1_PtIrTip3_LHeT_Jewook\n",
      "selected file name =  Bias-Spectroscopy(x0.01_f0.01)_00004.dat\n",
      "Current Path =  C:\\Users\\gkp\\OneDrive - Oak Ridge National Laboratory\\Research\\Data Analysis (python)\\SPMpy_ornl\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# show the selected path & filename #\n",
    "#####################################\n",
    "\n",
    "defalut_folder = r\"C:\\Users\\gkp\\OneDrive - Oak Ridge National Laboratory\\mK STM DATA\\2023\\0503 NbSe2_PtIrtip2_LHeT_Jewook\"\n",
    "print(\"folder_path = \", file_chooser.selected_path)\n",
    "print(\"selected file name = \",file_chooser.selected_filename)\n",
    "folder_path = file_chooser.selected_path\n",
    "\n",
    "currentPath = os.getcwd() #get current path\n",
    "print (\"Current Path = \", os.getcwd()) # print current path \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a6d09-4eeb-4064-878b-15df0b5449f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <font color=blue>1. Check file_list (DataFrame) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2308a3d-386c-468d-addf-79e5e9e3888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_in_folder(path): \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str \n",
    "        folder path \n",
    "        * copy and paste the folder path\n",
    "        * add 'r' to avoid unicodeerror \n",
    "    Returns\n",
    "    -------\n",
    "    file_list_df : PANDAS DataFrame\n",
    "        file list dataframe \n",
    "\"\"\"\n",
    "    import os\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import nanonispy as nap\n",
    "    currentPath = os.getcwd() #get current path\n",
    "    print (\"Current Path = \", os.getcwd()) # print current path \n",
    "    #######################################\n",
    "    working_folder = path\n",
    "    # copy & paste the \"SPM data file\" location (folder(path)) \n",
    "    os.chdir(working_folder)\n",
    "    print (\"Changed Path = \", os.getcwd()) \n",
    "    # check the re-located path \n",
    "    ####################################\n",
    "\n",
    "    ######################################\n",
    "    # call all the sxm  files in path    #\n",
    "    ######################################\n",
    "    path = \"./*\"\n",
    "    # pt_spec_file_list = (glob.glob('*.dat')) \n",
    "    sxm_file_list = (glob.glob('*.sxm')) \n",
    "    grid_file_list = (glob.glob('*.3ds')) \n",
    "    csv_file_list = (glob.glob('*.csv')) \n",
    "    gwy_file_list = (glob.glob('*.gwy')) \n",
    "    # using \"glob\"  all \" *.sxm\" files  in file_list\n",
    "    #####################################\n",
    "    ## sxm file\n",
    "    file_list_sxm_df = pd.DataFrame([[\n",
    "        file[:-7],file[-7:-4],file] \n",
    "                                     for file in sxm_file_list],\n",
    "        columns =['group','num','file_name'])\n",
    "\n",
    "    sxm_file_groups= list (set(file_list_sxm_df['group']))\n",
    "    ## 3ds file\n",
    "    file_list_3ds_df = pd.DataFrame([[\n",
    "    file[:-7],file[-7:-4],file] \n",
    "                                 for file in grid_file_list],\n",
    "    columns =['group','num','file_name'])\n",
    "    ## csv file\n",
    "    file_list_csv_df = pd.DataFrame([[\n",
    "        file[:-7],file[-7:-4],file] \n",
    "                                     for file in csv_file_list],\n",
    "        columns =['group','num','file_name'])\n",
    "    ## gwy file\n",
    "    file_list_gwy_df = pd.DataFrame([[\n",
    "        file[:-4], np.nan, file] \n",
    "                                     for file in gwy_file_list],\n",
    "        columns =['group','num','file_name'])   \n",
    "    \n",
    "    file_list_df = pd.concat ([file_list_sxm_df, file_list_3ds_df, file_list_csv_df, file_list_gwy_df],ignore_index= True)\n",
    "    file_list_df['type'] = [file_name[-3:] for file_name in  file_list_df.file_name]\n",
    "    print (file_list_df)\n",
    "\n",
    "    \n",
    "    #############################################################\n",
    "    # to call all the files in sxm_file_groups[0]\n",
    "    ##  file_list_df[file_list_df['group'] == sxm_file_groups[0]]\n",
    "    #############################################################\n",
    "    #print (file_list_sxm_df)\n",
    "    #print (file_list_3ds_df)\n",
    "    # indicates # of files in each group \n",
    "    for group in sxm_file_groups:\n",
    "        print ('sxm file groups :  ', group, ':  # of files = ',\n",
    "               len(file_list_sxm_df[file_list_sxm_df['group'] == group]) )\n",
    "    if len(file_list_df[file_list_df['type'] == '3ds']) ==0 :\n",
    "        print ('No GridSpectroscopy data')\n",
    "    else :\n",
    "        print ('# of GridSpectroscopy',\n",
    "               list(set(file_list_df[file_list_df['type'] == '3ds'].group))[0], \n",
    "               ' = ',           \n",
    "               file_list_df[file_list_df['type'] == '3ds'].group.count())\n",
    "\n",
    "    return file_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7702f6-65d4-4295-bc8e-0d8afb4a301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Path =  C:\\Users\\gkp\\OneDrive - Oak Ridge National Laboratory\\Research\\Data Analysis (python)\\SPMpy_ornl\n",
      "Changed Path =  C:\\Users\\gkp\\OneDrive - Oak Ridge National Laboratory\\mK STM DATA\\2023\\0506 FeTe0.55Se0.45_new_batch1_PtIrTip3_LHeT_Jewook\n",
      "                                                group  num  \\\n",
      "0   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  001   \n",
      "1   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  002   \n",
      "2   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  003   \n",
      "3   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  004   \n",
      "4   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  005   \n",
      "5   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  006   \n",
      "6   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  007   \n",
      "7   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  008   \n",
      "8   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  009   \n",
      "9   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  010   \n",
      "10  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  011   \n",
      "11  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  012   \n",
      "12  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  013   \n",
      "13  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  014   \n",
      "14  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  015   \n",
      "15  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  001   \n",
      "16  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  002   \n",
      "17  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  003   \n",
      "18  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  004   \n",
      "19  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  101   \n",
      "20  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  001   \n",
      "21  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  002   \n",
      "22  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  003   \n",
      "23       Grid Line Spectroscopy X0.01F0.01_after0014_  001   \n",
      "24       Grid Line Spectroscopy X0.01F0.01_after0014_  002   \n",
      "25            Grid Spectroscopy X0.01F0.01_after0015_  001   \n",
      "26  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "27  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "28  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "29  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "30  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "31  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "32  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "33  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "34  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "35  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "36  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "37  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "38  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "39  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "40  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "41  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "42  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "43  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  NaN   \n",
      "44  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  NaN   \n",
      "45  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  NaN   \n",
      "46  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  NaN   \n",
      "\n",
      "                                            file_name type  \n",
      "0   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "1   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "2   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "3   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "4   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "5   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "6   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "7   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "8   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "9   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "10  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "11  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "12  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "13  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "14  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "15  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "16  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "17  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "18  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "19  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  sxm  \n",
      "20  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  sxm  \n",
      "21  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  sxm  \n",
      "22  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  sxm  \n",
      "23  Grid Line Spectroscopy X0.01F0.01_after0014_00...  3ds  \n",
      "24  Grid Line Spectroscopy X0.01F0.01_after0014_00...  3ds  \n",
      "25     Grid Spectroscopy X0.01F0.01_after0015_001.3ds  3ds  \n",
      "26  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "27  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "28  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "29  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "30  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "31  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "32  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "33  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "34  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "35  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "36  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "37  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "38  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "39  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "40  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "41  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "42  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "43  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x...  gwy  \n",
      "44  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  gwy  \n",
      "45  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  gwy  \n",
      "46  FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x...  gwy  \n",
      "sxm file groups :   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0507_(x0.01Bias_Factor0.01)_0 :  # of files =  3\n",
      "sxm file groups :   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x0.01Bias_Factor0.01)_0 :  # of files =  15\n",
      "sxm file groups :   FeTe0.55Se0.45(new)_PtIrTip3_LHeT_2023_0506_(x1Bias_Factor1)_0 :  # of files =  5\n",
      "# of GridSpectroscopy Grid Spectroscopy X0.01F0.01_after0015_  =  3\n"
     ]
    }
   ],
   "source": [
    "file_list_df = files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89505e5e-9876-4ba8-8ae0-2fcfe756e6a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <font color=blue>2. Image to xarray</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3025d8-385d-49d7-91b3-a8d85c44e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata in c:\\users\\gkp\\appdata\\local\\anaconda3\\lib\\site-packages (6.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gkp\\appdata\\local\\anaconda3\\lib\\site-packages (from importlib-metadata) (3.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# check all necessary package #\n",
    "# for img2xr                  #\n",
    "###############################\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from warnings import warn\n",
    "%pip install importlib-metadata\n",
    "# 2023 0510 added \n",
    "\n",
    "try:\n",
    "    import nanonispy as nap\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named nanonispy')\n",
    "    %pip install nanonispy\n",
    "    import nanonispy as nap\n",
    "\n",
    "try:\n",
    "    import xarray as xr\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named xarray')\n",
    "    #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "    %pip install xarray \n",
    "    import xarray as xr\n",
    "\n",
    "try:\n",
    "    import seaborn_image as isns\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "    #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "    %pip install --upgrade seaborn-image    \n",
    "    import seaborn_image as isns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c48d7c1-e2f8-4978-a94a-16d7b2750a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2xr (loading_sxm_file, center_offset = False):\n",
    "    # import necessary module \n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import math\n",
    "    import matplotlib.pyplot as plt\n",
    "    import re\n",
    "\n",
    "    from warnings import warn\n",
    "\n",
    "    try:\n",
    "        import nanonispy as nap\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named nanonispy')\n",
    "        %pip install nanonispy\n",
    "        import nanonispy as nap\n",
    "\n",
    "    try:\n",
    "        import xarray as xr\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xarray')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        %pip install xarray \n",
    "        import xarray as xr\n",
    "\n",
    "    try:\n",
    "        import seaborn_image as isns\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        %pip install --upgrade seaborn-image    \n",
    "        import seaborn_image as isns\n",
    "\n",
    "\n",
    "    NF = nap.read.NanonisFile(loading_sxm_file)\n",
    "    Scan = nap.read.Scan(NF.fname)\n",
    "    #Scan.basename # file name only *.sxm \n",
    "    #Scan.header # heater dict \n",
    "    ##############################\n",
    "    # Scan conditions from the header\n",
    "    V_b = float(Scan.header['bias>bias (v)'])\n",
    "    I_t = float(Scan.header['z-controller>setpoint'])\n",
    "\n",
    "    [size_x,size_y] = Scan.header['scan_range']\n",
    "    [cntr_x, cntr_y] = Scan.header['scan_offset']\n",
    "    [dim_px,dim_py] = Scan.header['scan_pixels']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size = size / pixel\n",
    "    Rot_Rad = math.radians( float(Scan.header['scan_angle'])) \n",
    "    #str --> degree to radian \n",
    "\n",
    "    print ('scan direction (up/down): ', Scan.header['scan_dir'])\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])\n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])\n",
    "    # nX,nY for meshgrid (start from 1/2, not 0 )\n",
    "    # x, y steps with dimension \n",
    "    # In case of rotation ==0\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    \n",
    "    #########################################################################\n",
    "    # np.meshgrid \n",
    "    x_mesh_0, y_mesh_0 = np.meshgrid(nX, nY)\n",
    "    x_mesh = cntr_x - size_x + x_mesh_0\n",
    "    y_mesh = cntr_y - size_y + y_mesh_0 \n",
    "    # if there is rotation \n",
    "    x_mesh_r   =  np.cos(Rot_Rad)*x_mesh_0 + np.sin(Rot_Rad)*y_mesh_0  # \"cloclwise\"\n",
    "    y_mesh_r   = -np.sin(Rot_Rad)*x_mesh_0 + np.cos(Rot_Rad)*y_mesh_0\n",
    "    #########################################################################\n",
    "    # image title \n",
    "    # if there is rotation ( rot !=0 ), display it. \n",
    "    if Rot_Rad ==0 : \n",
    "        image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                    ' V = '+ str(V_b) + ' V ' +\\\n",
    "                        ' I = ' + str(round(I_t *1E12)) + ' pA ' \n",
    "    else: \n",
    "        image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                    ' V = '+ str(V_b) + ' V ' +\\\n",
    "                        ' I = ' + str(round(I_t *1E12)) + ' pA ' +\\\n",
    "                            ' R = ' + str(int(math.degrees(Rot_Rad))) + 'deg'\n",
    "    print(image_title)\n",
    "    #########################################################################\n",
    "    # scan channels in DataFrame\n",
    "\n",
    "    #Scan.signals.keys()\n",
    "    Scan.signals['Z'].keys()\n",
    "    \n",
    "    Scan.signals['Z']['forward'].shape\n",
    "    z_fwd = Scan.signals['Z']['forward']\n",
    "    z_bwd = Scan.signals['Z']['backward'][:,::-1]\n",
    "\n",
    "    \n",
    "    #print(Scan.signals.keys())\n",
    "    \n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_key = [s  for s in Scan.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "    print(LIX_key)\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIX_fwd  = Scan.signals[LIX_key[0]]['forward']\n",
    "    LIX_bwd  = Scan.signals[LIX_key[0]]['backward'][:,::-1]\n",
    "\n",
    "    #LIX_fwd = Scan.signals['LI_Demod_1_X']['forward']\n",
    "    #LIX_bwd = Scan.signals['LI_Demod_1_X']['backward'][:,::-1]\n",
    "    # LIX channel name varies w.r.t nanonis version \n",
    "    \n",
    "    # same for LIY --> update later.. if needed \n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    #LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    #LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "     \n",
    "    #bwd channel : opposite data direction in X ==> reverse it. \n",
    "    ########################################\n",
    "    if Scan.header['scan_dir'] == 'down':\n",
    "        z_fwd = z_fwd[::-1,:]\n",
    "        z_bwd = z_bwd[::-1,:]\n",
    "        LIX_fwd = LIX_fwd[::-1,:]\n",
    "        LIX_bwd = LIX_bwd[::-1,:]\n",
    "    # if scan_direction == down, flip the data (Y)\n",
    "    ########################################\n",
    "    z_fwd_df = pd.DataFrame(z_fwd)\n",
    "    z_fwd_df.index.name ='row_y'\n",
    "    z_fwd_df.columns.name ='col_x'\n",
    "\n",
    "    z_bwd_df = pd.DataFrame(z_bwd)\n",
    "    z_bwd_df.index.name ='row_y'\n",
    "    z_bwd_df.columns.name ='col_x'\n",
    "\n",
    "    LIX_fwd_df = pd.DataFrame(LIX_fwd)\n",
    "    LIX_fwd_df.index.name ='row_y'\n",
    "    LIX_fwd_df.columns.name ='col_x'\n",
    "\n",
    "    LIX_bwd_df = pd.DataFrame(LIX_bwd)\n",
    "    LIX_bwd_df.index.name ='row_y'\n",
    "    LIX_bwd_df.columns.name ='col_x'\n",
    "    # save data channels as DataFrame\n",
    "    ########################################\n",
    "    z_fwd_df = z_fwd_df.fillna(0)\n",
    "    z_bwd_df = z_bwd_df.fillna(0)\n",
    "    LIX_fwd_df = LIX_fwd_df.fillna(0)   \n",
    "    LIX_bwd_df = LIX_bwd_df.fillna(0)\n",
    "    # in case of incompleted scan ==> np.nan in data point, ==> fillna()\n",
    "    ########################################\n",
    "\n",
    "    ############################\n",
    "    # conver to DataFrame (PANDAS) \n",
    "    z_LIX_fNb_df = pd.concat([z_fwd_df.stack(),\n",
    "                              z_bwd_df.stack(),\n",
    "                              LIX_fwd_df.stack(),\n",
    "                              LIX_bwd_df.stack()], axis = 1)\n",
    "    # set colunm name for new DataFrame\n",
    "    z_LIX_fNb_df.columns =['z_fwd','z_bwd', 'LIX_fwd','LIX_bwd']\n",
    "    # z_LIX_fNb_df\n",
    "    ############################\n",
    "    # conver to xarray \n",
    "    ############################\n",
    "    z_LIX_fNb_xr = z_LIX_fNb_df.to_xarray()\n",
    "    # rename coord as \"X\", \"Y\" \n",
    "    z_LIX_fNb_xr = z_LIX_fNb_xr.rename(\n",
    "        {\"row_y\": \"Y\", \"col_x\":\"X\"})\n",
    "    # real size of XY \n",
    "    z_LIX_fNb_xr= z_LIX_fNb_xr.assign_coords(\n",
    "        X = z_LIX_fNb_xr.X.values *step_dx, \n",
    "        Y = z_LIX_fNb_xr.Y.values *step_dy )\n",
    "    # XY axis: 0 ~ size_XY\n",
    "\n",
    "    ############################\n",
    "    # check the XY ratio \n",
    "    ############################\n",
    "    if  size_x == size_y : \n",
    "        pass\n",
    "    else : \n",
    "        print ('size_x != size_y')\n",
    "    # if xy size is not same, report it! \n",
    "\n",
    "    if step_dx != step_dy :\n",
    "        xystep_ratio = step_dy/step_dx # check the XY pixel_ratio\n",
    "        X_interp = np.linspace(z_LIX_fNb_xr.X[0], z_LIX_fNb_xr.X[-1], z_LIX_fNb_xr.X.shape[0]*1)\n",
    "        step_dx = step_dx # step_dx check \n",
    "\n",
    "        Y_interp = np.linspace(z_LIX_fNb_xr.Y[0], z_LIX_fNb_xr.Y[-1], int(z_LIX_fNb_xr.Y.shape[0]*xystep_ratio)) \n",
    "        step_dy = step_dy/ xystep_ratio # step_dy check \n",
    "\n",
    "        # interpolation ratio should be int\n",
    "        z_LIX_fNb_xr= z_LIX_fNb_xr.interp(X = X_interp, Y = Y_interp, method=\"linear\")\n",
    "        print('step_dx/step_dy = ', xystep_ratio)\n",
    "        print ('z_LIX_fNb_xr ==> reshaped')\n",
    "    else: \n",
    "        z_LIX_fNb_xr =z_LIX_fNb_xr\n",
    "        print('step_dx == step_dy')\n",
    "    #print('z_LIX_fNb_xr', 'step_dx, step_dy = ',  z_LIX_fNb_xr.dims)\n",
    "    print('z_LIX_fNb_xr', 'step_dx, step_dy = ', \n",
    "          re.findall('\\{([^}]+)', str(z_LIX_fNb_xr.dims)))\n",
    "    # regex practice\n",
    "\n",
    "\n",
    "    ##########\n",
    "    #################################\n",
    "    # assigne attributes \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    z_LIX_fNb_xr.attrs['title'] = image_title\n",
    "    if 'Wtip' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'W'\n",
    "    elif 'Ni_tip' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Ni'\n",
    "    elif 'Co_coated' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Co_coated'\n",
    "    elif 'AFM' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'AFM'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'To Be Announced'\n",
    "        print('tip material will be announced')\n",
    "    \n",
    "    if 'NbSe2' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'NbSe2'\n",
    "    elif 'Cu(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Cu(111)'\n",
    "    elif 'Au(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Au(111)'\n",
    "    elif 'MoS2' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'MoS2'\n",
    "    elif 'FeTe0.55Se0.45' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'FeTe0.55Se0.45'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'To Be Announced'\n",
    "        print('sample type will be announced')\n",
    "    \n",
    "    z_LIX_fNb_xr.attrs['image_size'] = [size_x,size_y]\n",
    "    z_LIX_fNb_xr.attrs['X_spacing'] = step_dx\n",
    "    z_LIX_fNb_xr.attrs['Y_spacing'] = step_dy    \n",
    "    z_LIX_fNb_xr.attrs['freq_X_spacing'] = 1/step_dx\n",
    "    z_LIX_fNb_xr.attrs['freq_Y_spacing'] = 1/step_dy\n",
    "\n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        z_LIX_fNb_xr.assign_coords(X=(z_LIX_fNb_xr.X + cntr_x -  size_x/2))\n",
    "        z_LIX_fNb_xr.assign_coords(Y=(z_LIX_fNb_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "\n",
    "\n",
    "    #################################\n",
    "    # test & how to use xr data \n",
    "    # z_LIX_fNb_xr  # xr dataset (with data array channels )\n",
    "    #z_LIX_fNb_xr.z_fwd # select data channel\n",
    "    #z_LIX_fNb_xr.data_vars # data channels check \n",
    "    #z_LIX_fNb_xr.z_fwd.values  # to call data array in nd array \n",
    "    #z_yLIX_fNb_xr.dims # data channel dimension (coords) \n",
    "    #z_LIX_fNb_xr.coords # data  channel coordinates check \n",
    "    #z_LIX_fNb_xr.attrs # data  channel attributes check \n",
    "\n",
    "    return z_LIX_fNb_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1958f1-925f-46e1-8e27-6f5ac9484654",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <font color=blue>3. Grid to xarray </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240b41b0-284a-4d26-8515-43467d53de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# check all necessary package #\n",
    "# for img2xr                  #\n",
    "###############################\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.fft as npf\n",
    "#import xarray as xr\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "try:\n",
    "    import nanonispy as nap\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named nanonispy')\n",
    "    !pip install nanonispy\n",
    "    import nanonispy as nap\n",
    "\n",
    "try:\n",
    "    import xarray as xr\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named xarray')\n",
    "    #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "    !pip install xarray \n",
    "    import xarray as xr\n",
    "\n",
    "try:\n",
    "    import seaborn_image as isns\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "    #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "    !pip install --upgrade seaborn-image    \n",
    "    import seaborn_image as isns\n",
    "\n",
    "\n",
    "try:\n",
    "    import xrft\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named xrft')\n",
    "    !pip install xrft \n",
    "    import xrft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf81d0ea-0ff4-4e28-9c1a-4fa28b59e5aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#griddata_file = file_list_df[file_list_df.type=='3ds'].iloc[0].file_name\n",
    "\n",
    "def grid2xr(griddata_file, center_offset = True): \n",
    "\n",
    "    file = griddata_file\n",
    "    #####################\n",
    "    # conver the given 3ds file\n",
    "    # to  xarray DataSet (check the attributes)\n",
    "    NF = nap.read.NanonisFile(file)\n",
    "    Gr = nap.read.Grid(NF.fname)#\n",
    "    channel_name = Gr.signals.keys()  \n",
    "    #print (channel_name)\n",
    "    N = len(file);\n",
    "    f_name = file[0:N-4]\n",
    "    print (f_name) # Gr.basename\n",
    "\n",
    "    #####################################\n",
    "    #  Header part\n",
    "    #  Gr.header\n",
    "    #####################################\n",
    "    [dim_px,dim_py] = Gr.header['dim_px'] \n",
    "    [cntr_x, cntr_y] = Gr.header['pos_xy']\n",
    "    [size_x,size_y] = Gr.header['size_xy']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size =  size / pixel \n",
    "\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])\n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])\n",
    "\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    \n",
    "    #####################################\n",
    "    # signal part\n",
    "    # Gr.signals\n",
    "    #####################################\n",
    "    topography = Gr.signals['topo']\n",
    "    params_v = Gr.signals['params'] \n",
    "    # params_v.shape = (dim_px,dim_py,15) \n",
    "    # 15: 3ds infos. \n",
    "    bias = Gr.signals['sweep_signal']\n",
    "    # check the shape (# of 'original' bias points)\n",
    "    I_fwd = Gr.signals['Current (A)'] # 3d set (dim_px,dim_py,bias)\n",
    "    I_bwd = Gr.signals['Current [bwd] (A)'] # I bwd\n",
    "    # sometimes, LI channel names are inconsistent depends on program ver. \n",
    "    # find 'LI Demod 1 X (A)'  or  'LI X 1 omega (A)'\n",
    "\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIX_fwd, LIX_bwd = Gr.signals[LIX_keys[0]] ,Gr.signals[LIX_keys[1] ]\n",
    "\n",
    "    # same for LIY\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #plt.imshow(topography) # toppography check\n",
    "    #plt.imshow(I_fwd[:,:,0]) # LIX  check\n",
    "    ###########################################################\n",
    "\n",
    "    ##########################################################\n",
    "    #\t\t Title for Grid data \n",
    "    #       grid size, pixel, bias condition, and so on.\n",
    "    #############################################################\n",
    "    # Gr.header.get('Bias>Bias (V)') # bias condition \n",
    "    # Gr.header.get('Z-Controller>Setpoint') # current set  condition\n",
    "    # Gr.header.get('dim_px')  # jpixel dimension \n",
    "    title = Gr.basename +' ('  + str(\n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep Start (V)'))\n",
    "    ) +' V ~ ' +str( \n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep End (V)'))\n",
    "    )+ ' V) \\n at Bias = '+ Gr.header.get(\n",
    "        'Bias>Bias (V)'\n",
    "    )[0:-3]+' mV, I_t =  ' + Gr.header.get(\n",
    "        'Z-Controller>Setpoint'\n",
    "    )[0:-4]+ ' pA, '+str(\n",
    "        Gr.header.get('dim_px')[0]\n",
    "    )+' x '+str(\n",
    "        Gr.header.get('dim_px')[1]\n",
    "    )+' points'\n",
    "    #############################################################       \n",
    "\n",
    "    ### some times the topography does not look right. \n",
    "    # * then use the reshaping function \n",
    "    # only for asymmetry grid data set\n",
    "\n",
    "    # eg) JW's MoS2 on HOPG exp. data \n",
    "\n",
    "    ###########################################################\n",
    "    # assign topography as topography_reshape\n",
    "    ###########################################################\n",
    "    topo_dimension_true = True\n",
    "    # if topography looks normal.\n",
    "    ################################\n",
    "    if topo_dimension_true == True:\n",
    "        topography_reshape = topography   \n",
    "        #################################\n",
    "        I_fwd_copy = I_fwd\n",
    "        I_bwd_copy = I_bwd\n",
    "        LIX_fwd_copy = LIX_fwd \n",
    "        LIX_bwd_copy = LIX_bwd \t\n",
    "        \n",
    "    else:\n",
    "        # if a topography looks abnormal\n",
    "        # it is very rare case, \n",
    "        # but I leave manual setting to remind \"mistake!\"\n",
    "        \n",
    "        \n",
    "        ##########################################################\n",
    "        # if there is an error or mixed array for \n",
    "        ##########################################################\n",
    "        # adjust lattice manually \n",
    "        ##########################################################\n",
    "        # for example\n",
    "        # some times 40 x 80 array shape --> 40x40 + 40 x40\n",
    "        # because of mischoosen step & shape setting \n",
    "        # X one line = 0-39: 1st line + 40-79 \n",
    "        # in this case \n",
    "        # make a new arrary (vertically)\n",
    "        # 0-39 --> 2n & 40-79 -->  2n+1 \n",
    "        # topo # LIX f&b # I f&b #\n",
    "        ##########################################################\n",
    "\n",
    "        \n",
    "        topography_reshape = np.transpose(np.copy(topography),(1,0)) \n",
    "        # make a new lattcie with reshaped dimension \n",
    "        for x_indx, y_indx in enumerate (topography):\n",
    "        # print(x_indx) # 0-39 # print(y_indx.shape)\n",
    "            topography_reshape[2*x_indx,:] = y_indx[:40] # reshaping first half\n",
    "            topography_reshape[2*x_indx+1,:] = y_indx[40:80] # reshaping second half\n",
    "        #################################\n",
    "        # same deformation for I& LIX \n",
    "        #################################\n",
    "        # check the topographyt \n",
    "        plt.imshow(topography_reshape) # 80 * 40 OK\n",
    "        # topography_reshape is done. \n",
    "        \n",
    "        #################################\n",
    "        # make a new lattcie with reshaped dimension \n",
    "        I_fwd_copy = np.transpose(np.copy(I_fwd),(1,0,2))\n",
    "        I_bwd_copy = np.transpose(np.copy(I_bwd),(1,0,2)) \n",
    "        \n",
    "        for x_indx, yNbias_plane in enumerate (I_fwd): \n",
    "            # make a new lattcie with reshaped dimension \n",
    "            print(x_indx) # 0-39 \n",
    "            I_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            I_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "\n",
    "        for x_indx, yNbias_plane in enumerate (I_bwd): \n",
    "            # make a new lattcie with reshaped dimension \n",
    "            print(x_indx) # 0-39 \n",
    "            I_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            I_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        #################################\n",
    "        # I reshape is done \n",
    "        #################################\n",
    "        LIX_fwd_copy = np.transpose(np.copy(LIX_fwd),(1,0,2)) \n",
    "        LIX_bwd_copy = np.transpose(np.copy(LIX_bwd),(1,0,2)) \n",
    "        # make a new lattcie with reshaped dimension \n",
    "        for x_indx, yNbias_plane in enumerate (LIX_fwd): \n",
    "            LIX_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            LIX_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        for x_indx, yNbias_plane in enumerate (LIX_bwd): \n",
    "            LIX_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            LIX_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        #################################\n",
    "        # LIX reshape is done \n",
    "        #################################\n",
    "\n",
    "    # after reshaping \n",
    "\n",
    "    topography = topography_reshape \n",
    "    #################################\n",
    "    I_fwd = I_fwd_copy \n",
    "    I_bwd = I_bwd_copy \n",
    "    LIX_fwd  = LIX_fwd_copy \n",
    "    LIX_bwd  = LIX_bwd_copy\n",
    "    ##########################################################\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # Bias segment check      #\n",
    "    ###########################\n",
    "    Segment = Gr.header['Bias>Bias (V)']\n",
    "    # bias unit : '(V)' \n",
    "\n",
    "    if type(Segment) == str: # single segment case\n",
    "        print ('No Segments\\n'+ 'Grid data acquired at bias = '+  str(float(Segment)) + 'V')    \n",
    "    ## No Segments # +  bias setting \n",
    "\n",
    "    ########################\n",
    "    # bias interpolation to have a \"zero\" bias \n",
    "    # interpolate bias_mV that include \"zero\" bias \n",
    "    # in 3D data : center x,y bias interpolation \n",
    "    # e.g  256--> including end points + zero  = 256+1 ( the center is \"0\")\n",
    "        if len(bias)%2==0:\n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias)+1)) \n",
    "            # if bias length is even_number \n",
    "            # including \"0\", total size is \"len+1\" \n",
    "        else:# if bias length is odd_number \n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias))) \n",
    "            # bias_new make a odd number of length\n",
    "            # make only one value is closest to the zero. \n",
    "            \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # find the index of closest to \"0\" bias \n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # assign closest zero vavlue as a zero. \n",
    "        #bias_new[np.where(bias_new == np.amin(abs(bias_new)))]=0\n",
    "\n",
    "    ##############################################\n",
    "    #'Segment Start (V), Segment End (V), Settling (s), Integration (s), Steps (xn)'\n",
    "    elif len(Segment) == 3:\n",
    "        print('Number of Segments =' + str(len(Segment))) \n",
    "        Segments = np.array([[ float(Segments) \n",
    "                              for Segments in Seg.split(',') ] \n",
    "                             for Seg in Segment], dtype = np.float64)\n",
    "        # in the Segment, split strings sith \",\" \n",
    "        #  make a array after change it as float. \n",
    "        # check Nanonispy version\n",
    "        # bias value could be not correct. \n",
    "        \n",
    "        Seg1 = np.linspace(Segments[0,0],Segments[0,1],int(Segments[0,-1]))\n",
    "        Seg2 = np.linspace(Segments[1,0],Segments[1,1],int(Segments[1,-1]))\n",
    "        Seg3 = np.linspace(Segments[2,0],Segments[2,1],int(Segments[2,-1]))\n",
    "        # except boundary end points,  combine segments ([1:]), Seg1, Seg2[1:], Seg3[1:] \n",
    "        bias_Seg = np.append(np.append(Seg1,Seg2[1:]),Seg3[1:]) \n",
    "        # Seg1 +  Seg2[1:] +  Se3[1:] \n",
    "        # make a clever & shoter way 'later...'\n",
    "        print ('bias_Seg size = ' + str(len(bias_Seg)))\n",
    "        bias_Nsteps=int(int(Segments[1,-1])/\n",
    "                        (Seg2[-1]-Seg2[0])*(bias_Seg[-1]-bias_Seg[0]))\n",
    "        # New bias Steps uses smallest step as a new stpe size. \n",
    "        bias_Nsteps_size = (Seg2[-1]-Seg2[0])/(Segments[1,-1])\n",
    "        # (Segments[1,0]-Segments[1,1])/int(Segments[1,-1]) # bias step size    \n",
    "        Neg_bias=-1*np.arange(\n",
    "            0,bias_Nsteps_size*bias_Nsteps/2, bias_Nsteps_size)\n",
    "        Pos_bias=np.flip(\n",
    "            np.arange(0,bias_Nsteps_size*bias_Nsteps/2,bias_Nsteps_size))\n",
    "        bias_new = np.flip( np.append(Pos_bias,Neg_bias[1:])) \n",
    "        # after segments, \n",
    "        # bias is called as  bias_new\n",
    "        ##################################\n",
    "        # now make the bias_new as an odd number. \n",
    "        ###################################\n",
    "        if len(bias_new)%2==0:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new)+1)) \n",
    "        else:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new))) \n",
    "        # check  bias_new contians \"zero\" \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # check index of the nearest value to zero \"0\"\n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # adjust bias range for bias_new has \"zero\" \n",
    "        print ('bias_new size = ' + str(len(bias_new)))\n",
    "        # bias \n",
    "    # make a new list for Bias\n",
    "    else:\n",
    "        print (\"Segment error /n code a 5 Sements case\")\n",
    "    #\n",
    "    ######################################################################\n",
    "    # make a new bias length (including Segments) as a odd number, including zero\n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # interpolation using bias_new \n",
    "    # I_fwd, I_bwd, LIX_fwd, LIX_bwd\n",
    "    # => I_fwd_interpolate\n",
    "    #######################################################################\n",
    "    # assign a function using interpolation \n",
    "    # the same as original bias values \n",
    "    # make empty np array  & interpolate using scipy\n",
    "    # xy dim is not changed here, \n",
    "    # only 3rd axis changed as new bias \n",
    "    ###########################\n",
    "    def sweep_interpolation(np3Ddata, bias, bias_new):\n",
    "        np3Ddata_interpolate = np.empty(\n",
    "                    (np3Ddata.shape[0],np3Ddata.shape[1],bias_new.shape[0])) \n",
    "\n",
    "        for x_i,np3Ddata_xi in enumerate(np3Ddata):\n",
    "            for y_j,np3Ddata_xi_yj in enumerate(np3Ddata_xi):\n",
    "                #print (np3Ddata_xi_yj.shape)\n",
    "                Interpolation1D_i_f = sp.interpolate.interp1d(\n",
    "                    bias,\n",
    "                    np3Ddata_xi_yj,\n",
    "                    fill_value = \"extrapolate\",\n",
    "                    kind = 'cubic')\n",
    "                np3Ddata_interpolate[x_i,y_j,:] = Interpolation1D_i_f(bias_new)\n",
    "        return np3Ddata_interpolate\n",
    "\n",
    "    I_fwd_interpolate = sweep_interpolation (I_fwd, bias, bias_new)\n",
    "    I_bwd_interpolate = sweep_interpolation (I_bwd, bias, bias_new)\n",
    "    LIX_fwd_interpolate = sweep_interpolation (LIX_fwd, bias, bias_new)\n",
    "    LIX_bwd_interpolate = sweep_interpolation (LIX_bwd, bias, bias_new)\n",
    "\n",
    "    ####################################################\n",
    "    # to prevent error for bias direction \n",
    "    # \n",
    "    ##\n",
    "    #  assign the bias direction \n",
    "    ## up or down ==> up anyway. \n",
    "    ###################################################\n",
    "    if bias[0]>bias[-1]: \n",
    "        # if starting point is larger than end point. \n",
    "        # start from pos & end to neg\n",
    "        # no changes. \n",
    "        print ('start from POS bias')\n",
    "        I_fwd = I_fwd_interpolate\n",
    "        I_bwd = I_bwd_interpolate\n",
    "        LIX_fwd = LIX_fwd_interpolate\n",
    "        LIX_bwd = LIX_bwd_interpolate\n",
    "        bias_mV = bias_new*1000\n",
    "    else:  # if end point is larger than start point. \n",
    "        # start from neg & end to pos\n",
    "        # change to negative \n",
    "        print ('start from NEG bias')\n",
    "        I_fwd = np.flip(I_fwd_interpolate,2)\n",
    "        I_bwd = np.flip(I_bwd_interpolate,2)\n",
    "        LIX_fwd = np.flip(LIX_fwd_interpolate,2)\n",
    "        LIX_bwd = np.flip(LIX_bwd_interpolate,2)\n",
    "        bias_new_flip = np.flip(bias_new)\n",
    "        bias_mV = bias_new_flip*1000\n",
    "        print ('Flip => start from POS bias')\n",
    "    ####################################################\n",
    "\n",
    "    ###################################################\n",
    "    # convert data XR DataSet\n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "    # col = x \n",
    "    # row = y\n",
    "    # I_fwd grid data ==> [Y, X, bias]\n",
    "    grid_xr = xr.Dataset(\n",
    "        {\n",
    "            \"I_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_fwd),\n",
    "            \"I_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_bwd),\n",
    "            \"LIX_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_fwd),\n",
    "            \"LIX_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_bwd),\n",
    "            \"topography\" : ([\"Y\",\"X\"], topography)\n",
    "        },\n",
    "        coords = {\n",
    "            \"X\": ([\"X\"], x),\n",
    "            \"Y\": ([\"Y\"], y),\n",
    "            \"bias_mV\": ([\"bias_mV\"], bias_mV)\n",
    "        }\n",
    "    )\n",
    "    grid_xr.attrs[\"title\"] = title\n",
    "    #grid_xr.attrs['image_size'] = \n",
    "    #grid_xr.attrs['samlpe'] = \n",
    "    \n",
    "    grid_xr.attrs['image_size']= [size_x,size_y]\n",
    "    grid_xr.attrs['X_spacing']= step_dx\n",
    "    grid_xr.attrs['Y_spacing']= step_dy    \n",
    "    grid_xr.attrs['freq_X_spacing']= 1/step_dx\n",
    "    grid_xr.attrs['freq_Y_spacing']= 1/step_dy\n",
    "\n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        grid_xr.assign_coords( X = (grid_xr.X + cntr_x -  size_x/2))\n",
    "        grid_xr.assign_coords( Y = (grid_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "    \n",
    "    \n",
    "    \n",
    "    return grid_xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efdd06-6abb-43f0-a018-92fc9ccd05b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <font color=blue>4. Grid Line to xarray </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "929b03c9-7050-4f9b-931f-df3530e6acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_line2xr(griddata_file, center_offset = True): \n",
    "\n",
    "    file = griddata_file\n",
    "    #####################\n",
    "    # conver the given 3ds file\n",
    "    # to  xarray DataSet (check the attributes)\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import numpy.fft as npf\n",
    "    #import xarray as xr\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import matplotlib.pyplot as plt\n",
    "    import nanonispy as nap\n",
    "    import xarray as xr\n",
    "    import seaborn_image as isns\n",
    "    import xrft\n",
    "    \n",
    "\n",
    "    NF = nap.read.NanonisFile(file)\n",
    "    Gr = nap.read.Grid(NF.fname)#\n",
    "    channel_name = Gr.signals.keys()  \n",
    "    #print (channel_name)\n",
    "    N = len(file);\n",
    "    f_name = file[0:N-4]\n",
    "    print (f_name) # Gr.basename\n",
    "\n",
    "    #####################################\n",
    "    #Header part\n",
    "    #####################################\n",
    "    #  Gr.header\n",
    "    #####################################\n",
    "    [dim_px,dim_py] = Gr.header['dim_px'] \n",
    "    [cntr_x, cntr_y] = Gr.header['pos_xy']\n",
    "    [size_x,size_y] = Gr.header['size_xy']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    \n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])# dimesionë§žì¶˜ xstep \n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])# dimesionë§žì¶˜ ystep \n",
    "\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    \n",
    "    #####################################\n",
    "    # signal part\n",
    "    # Gr.signals\n",
    "    #####################################\n",
    "    topography = Gr.signals['topo']\n",
    "    params_v = Gr.signals['params'] \n",
    "    # params_v.shape = (dim_px,dim_py,15) \n",
    "    # 15: 3ds infos. \n",
    "    bias = Gr.signals['sweep_signal']\n",
    "    # check the shape (# of 'original' bias points)\n",
    "    I_fwd = Gr.signals['Current (A)'] # 3d set (dim_px,dim_py,bias)\n",
    "    I_bwd = Gr.signals['Current [bwd] (A)'] # I bwd\n",
    "    # sometimes, LI channel names are inconsistent depends on program ver. \n",
    "    # find 'LI Demod 1 X (A)'  or  'LI X 1 omega (A)'\n",
    "\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIX_fwd, LIX_bwd = Gr.signals[LIX_keys[0]] ,Gr.signals[LIX_keys[1] ]\n",
    "\n",
    "    # same for LIY\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #plt.imshow(topography) # toppography check\n",
    "    #plt.imshow(I_fwd[:,:,0]) # LIX  check\n",
    "    ###########################################################\n",
    "\n",
    "    ##########################################################\n",
    "    # Title for Grid data \n",
    "    #############################################################\n",
    "    # Gr.header.get('Bias>Bias (V)') # bias condition \n",
    "    # Gr.header.get('Z-Controller>Setpoint') # current set  condition\n",
    "    # Gr.header.get('dim_px')  # jpixel dimension \n",
    "    title = Gr.basename +' ('  + str(\n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep Start (V)'))\n",
    "    ) +' V ~ ' +str( \n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep End (V)'))\n",
    "    )+ ' V) \\n at Bias = '+ Gr.header.get(\n",
    "        'Bias>Bias (V)'\n",
    "    )[0:-3]+' mV, I_t =  ' + Gr.header.get(\n",
    "        'Z-Controller>Setpoint'\n",
    "    )[0:-4]+ ' pA, '+str(\n",
    "        Gr.header.get('dim_px')[0]\n",
    "    )+' x '+str(\n",
    "        Gr.header.get('dim_px')[1]\n",
    "    )+' points' + '1D line spectroscopy'\n",
    "    #############################################################       \n",
    "\n",
    "    ### some times the topography does not look right. \n",
    "    # * then use the reshaping function \n",
    "    # only for asymmetry grid data set\n",
    "\n",
    "    # eg) JW's MoS2 on HOPG exp. data \n",
    "\n",
    "    ###########################################################\n",
    "    # assign topography as topography_reshape\n",
    "    ###########################################################\n",
    "    topo_dimension_true = True\n",
    "    # if topography looks normal.\n",
    "    ################################\n",
    "    if topo_dimension_true == True:\n",
    "        topography_reshape = topography   \n",
    "        #################################\n",
    "        I_fwd_copy = I_fwd\n",
    "        I_bwd_copy = I_bwd\n",
    "        LIX_fwd_copy = LIX_fwd \n",
    "        LIX_bwd_copy = LIX_bwd \t\n",
    "        \n",
    "    else:\n",
    "        # if a topography looks abnormal\n",
    "        # it is very rare case, \n",
    "        # but I leave manual setting to remind \"mistake!\"\n",
    "        \n",
    "        \n",
    "        ##########################################################\n",
    "        # if there is an error or mixed array for \n",
    "        ##########################################################\n",
    "        # adjust lattice manually \n",
    "        ##########################################################\n",
    "        # for example\n",
    "        # some times 40 x 80 array shape --> 40x40 + 40 x40\n",
    "        # because of mischoosen step & shape setting \n",
    "        # X one line = 0-39: 1st line + 40-79 \n",
    "        # in this case \n",
    "        # make a new arrary (vertically)\n",
    "        # 0-39 --> 2n & 40-79 -->  2n+1 \n",
    "        # topo # LIX f&b # I f&b #\n",
    "        ##########################################################\n",
    "\n",
    "        \n",
    "        topography_reshape = np.transpose(np.copy(topography),(1,0)) \n",
    "        # make a new lattcie with reshaped dimension \n",
    "        for x_indx, y_indx in enumerate (topography):\n",
    "        # print(x_indx) # 0-39 # print(y_indx.shape)\n",
    "            topography_reshape[2*x_indx,:] = y_indx[:40] # reshaping first half\n",
    "            topography_reshape[2*x_indx+1,:] = y_indx[40:80] # reshaping second half\n",
    "        #################################\n",
    "        # same deformation for I& LIX \n",
    "        #################################\n",
    "        # check the topographyt \n",
    "        plt.imshow(topography_reshape) # 80 * 40 OK\n",
    "        # topography_reshape is done. \n",
    "        \n",
    "        #################################\n",
    "        # make a new lattcie with reshaped dimension \n",
    "        I_fwd_copy = np.transpose(np.copy(I_fwd),(1,0,2))\n",
    "        I_bwd_copy = np.transpose(np.copy(I_bwd),(1,0,2)) \n",
    "        \n",
    "        for x_indx, yNbias_plane in enumerate (I_fwd): \n",
    "            # make a new lattcie with reshaped dimension \n",
    "            print(x_indx) # 0-39 \n",
    "            I_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            I_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "\n",
    "        for x_indx, yNbias_plane in enumerate (I_bwd): \n",
    "            # make a new lattcie with reshaped dimension \n",
    "            print(x_indx) # 0-39 \n",
    "            I_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            I_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        #################################\n",
    "        # I reshape is done \n",
    "        #################################\n",
    "        LIX_fwd_copy = np.transpose(np.copy(LIX_fwd),(1,0,2)) \n",
    "        LIX_bwd_copy = np.transpose(np.copy(LIX_bwd),(1,0,2)) \n",
    "        # make a new lattcie with reshaped dimension \n",
    "        for x_indx, yNbias_plane in enumerate (LIX_fwd): \n",
    "            LIX_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            LIX_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        for x_indx, yNbias_plane in enumerate (LIX_bwd): \n",
    "            LIX_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            LIX_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        #################################\n",
    "        # LIX reshape is done \n",
    "        #################################\n",
    "\n",
    "    # after reshaping \n",
    "\n",
    "    topography = topography_reshape \n",
    "    #################################\n",
    "    I_fwd = I_fwd_copy \n",
    "    I_bwd = I_bwd_copy \n",
    "    LIX_fwd  = LIX_fwd_copy \n",
    "    LIX_bwd  = LIX_bwd_copy\n",
    "    ##########################################################\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # Bias segment check      #\n",
    "    ###########################\n",
    "    Segment = Gr.header['Bias>Bias (V)']\n",
    "    # bias unit : '(V)' \n",
    "\n",
    "    if type(Segment) == str: # single segment case\n",
    "        print ('No Segments\\n'+ 'Grid data acquired at bias = '+  str(float(Segment)) + 'V')    \n",
    "    ## No Segments # +  bias setting \n",
    "\n",
    "    ########################\n",
    "    # bias interpolation to have a \"zero\" bias \n",
    "    # interpolate bias_mV that include \"zero\" bias \n",
    "    # in 3D data : center x,y bias interpolation \n",
    "    # e.g  256--> including end points + zero  = 256+1 ( the center is \"0\")\n",
    "        if len(bias)%2==0:\n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias)+1)) \n",
    "            # if bias length is even_number \n",
    "            # including \"0\", total size is \"len+1\" \n",
    "        else:# if bias length is odd_number \n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias))) \n",
    "            # bias_new make a odd number of length\n",
    "            # make only one value is closest to the zero. \n",
    "            \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # find the index of closest to \"0\" bias \n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # assign closest zero vavlue as a zero. \n",
    "        #bias_new[np.where(bias_new == np.amin(abs(bias_new)))]=0\n",
    "\n",
    "    ##############################################\n",
    "    #'Segment Start (V), Segment End (V), Settling (s), Integration (s), Steps (xn)'\n",
    "    elif len(Segment) == 3:\n",
    "        print('Number of Segments =' + str(len(Segment))) \n",
    "        Segments = np.array([[ float(Segments) \n",
    "                              for Segments in Seg.split(',') ] \n",
    "                             for Seg in Segment], dtype = np.float64)\n",
    "        # in the Segment, split strings sith \",\" \n",
    "        #  make a array after change it as float. \n",
    "        # check Nanonispy version\n",
    "        # bias value could be not correct. \n",
    "        \n",
    "        Seg1 = np.linspace(Segments[0,0],Segments[0,1],int(Segments[0,-1]))\n",
    "        Seg2 = np.linspace(Segments[1,0],Segments[1,1],int(Segments[1,-1]))\n",
    "        Seg3 = np.linspace(Segments[2,0],Segments[2,1],int(Segments[2,-1]))\n",
    "        # except boundary end points,  combine segments ([1:]), Seg1, Seg2[1:], Seg3[1:] \n",
    "        bias_Seg = np.append(np.append(Seg1,Seg2[1:]),Seg3[1:]) \n",
    "        # Seg1 +  Seg2[1:] +  Se3[1:] \n",
    "        # make a clever & shoter way 'later...'\n",
    "        print ('bias_Seg size = ' + str(len(bias_Seg)))\n",
    "        bias_Nsteps=int(int(Segments[1,-1])/\n",
    "                        (Seg2[-1]-Seg2[0])*(bias_Seg[-1]-bias_Seg[0]))\n",
    "        # New bias Steps uses smallest step as a new stpe size. \n",
    "        bias_Nsteps_size = (Seg2[-1]-Seg2[0])/(Segments[1,-1])\n",
    "        # (Segments[1,0]-Segments[1,1])/int(Segments[1,-1]) # bias step size    \n",
    "        Neg_bias=-1*np.arange(\n",
    "            0,bias_Nsteps_size*bias_Nsteps/2, bias_Nsteps_size)\n",
    "        Pos_bias=np.flip(\n",
    "            np.arange(0,bias_Nsteps_size*bias_Nsteps/2,bias_Nsteps_size))\n",
    "        bias_new = np.flip( np.append(Pos_bias,Neg_bias[1:])) \n",
    "        # after segments, \n",
    "        # bias is called as  bias_new\n",
    "        ##################################\n",
    "        # now make the bias_new as an odd number. \n",
    "        ###################################\n",
    "        if len(bias_new)%2==0:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new)+1)) \n",
    "        else:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new))) \n",
    "        # check  bias_new contians \"zero\" \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # check index of the nearest value to zero \"0\"\n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # adjust bias range for bias_new has \"zero\" \n",
    "        print ('bias_new size = ' + str(len(bias_new)))\n",
    "        # bias \n",
    "    # make a new list for Bias\n",
    "    else:\n",
    "        print (\"Segment error /n code a 5 Sements case\")\n",
    "    #\n",
    "    ######################################################################\n",
    "    # make a new bias length (including Segments) as a odd number, including zero\n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # interpolation using bias_new \n",
    "    # I_fwd, I_bwd, LIX_fwd, LIX_bwd\n",
    "    # => I_fwd_interpolate\n",
    "    #######################################################################\n",
    "    # assign a function using interpolation \n",
    "    # the same as original bias values \n",
    "    # make empty np array  & interpolate using scipy\n",
    "    # xy dim is not changed here, \n",
    "    # only 3rd axis changed as new bias \n",
    "    ###########################\n",
    "    def sweep_interpolation(np3Ddata, bias, bias_new):\n",
    "        np3Ddata_interpolate = np.empty(\n",
    "                    (np3Ddata.shape[0],np3Ddata.shape[1],bias_new.shape[0])) \n",
    "\n",
    "        for x_i,np3Ddata_xi in enumerate(np3Ddata):\n",
    "            for y_j,np3Ddata_xi_yj in enumerate(np3Ddata_xi):\n",
    "                #print (np3Ddata_xi_yj.shape)\n",
    "                Interpolation1D_i_f = sp.interpolate.interp1d(\n",
    "                    bias,\n",
    "                    np3Ddata_xi_yj,\n",
    "                    fill_value = \"extrapolate\",\n",
    "                    kind = 'cubic')\n",
    "                np3Ddata_interpolate[x_i,y_j,:] = Interpolation1D_i_f(bias_new)\n",
    "        return np3Ddata_interpolate\n",
    "\n",
    "    I_fwd_interpolate = sweep_interpolation (I_fwd, bias, bias_new)\n",
    "    I_bwd_interpolate = sweep_interpolation (I_bwd, bias, bias_new)\n",
    "    LIX_fwd_interpolate = sweep_interpolation (LIX_fwd, bias, bias_new)\n",
    "    LIX_bwd_interpolate = sweep_interpolation (LIX_bwd, bias, bias_new)\n",
    "\n",
    "    ####################################################\n",
    "    # to prevent error for bias direction \n",
    "    # \n",
    "    ##\n",
    "    #  assign the bias direction \n",
    "    ## up or down ==> up anyway. \n",
    "    ###################################################\n",
    "    if bias[0]>bias[-1]: \n",
    "        # if starting point is larger than end point. \n",
    "        # start from pos & end to neg\n",
    "        # no changes. \n",
    "        print ('start from POS bias')\n",
    "        I_fwd = I_fwd_interpolate\n",
    "        I_bwd = I_bwd_interpolate\n",
    "        LIX_fwd = LIX_fwd_interpolate\n",
    "        LIX_bwd = LIX_bwd_interpolate\n",
    "        bias_mV = bias_new*1000\n",
    "    else:  # if end point is larger than start point. \n",
    "        # start from neg & end to pos\n",
    "        # change to negative \n",
    "        print ('start from NEG bias')\n",
    "        I_fwd = np.flip(I_fwd_interpolate,2)\n",
    "        I_bwd = np.flip(I_bwd_interpolate,2)\n",
    "        LIX_fwd = np.flip(LIX_fwd_interpolate,2)\n",
    "        LIX_bwd = np.flip(LIX_bwd_interpolate,2)\n",
    "        bias_new_flip = np.flip(bias_new)\n",
    "        bias_mV = bias_new_flip*1000\n",
    "        print ('Flip => start from POS bias')\n",
    "    ####################################################\n",
    "\n",
    "    ###################################################\n",
    "    # convert data XR DataSet\n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "    # col = x \n",
    "    # row = y\n",
    "    # I_fwd grid data ==> [Y, X, bias]\n",
    "    grid_xr = xr.Dataset(\n",
    "        {\n",
    "            \"I_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_fwd),\n",
    "            \"I_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_bwd),\n",
    "            \"LIX_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_fwd),\n",
    "            \"LIX_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_bwd),\n",
    "            \"topography\" : ([\"Y\",\"X\"], topography)\n",
    "        },\n",
    "        coords = {\n",
    "            \"X\": ([\"X\"], x),\n",
    "            \"Y\": ([\"Y\"], y),\n",
    "            \"bias_mV\": ([\"bias_mV\"], bias_mV)\n",
    "        }\n",
    "    )\n",
    "    grid_xr.attrs[\"title\"] = title\n",
    "    #grid_xr.attrs['image_size'] = \n",
    "    #grid_xr.attrs['samlpe'] = \n",
    "    \n",
    "    grid_xr.attrs['image_size']= [size_x,size_y]\n",
    "    grid_xr.attrs['X_spacing']= step_dx\n",
    "    grid_xr.attrs['Y_spacing']= step_dy    \n",
    "    grid_xr.attrs['freq_X_spacing']= 1/step_dx\n",
    "    grid_xr.attrs['freq_Y_spacing']= np.nan\n",
    "    \n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        grid_xr.assign_coords( X = (grid_xr.X + cntr_x -  size_x/2))\n",
    "        grid_xr.assign_coords( Y = (grid_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "    \n",
    "    \n",
    "    return grid_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc9430-17e8-4ff9-9bbc-7782236e0c2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <font color=blue>5. Gwyddion 2D image to PANDAS Dataframe or Xarray </font>\n",
    "### 5.1. gwy_image2df \n",
    "* convert to df \n",
    "### 5.2. gwy_df_channel2xr \n",
    "* convert to xr\n",
    "* need some upgrade.. (later) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9a9226b-4b6a-498c-86ff-404719d17dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gwy_image2df (gwy_file_name):\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        import gwyfile\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named gwyfile')\n",
    "        %pip install gwyfile\n",
    "        import gwyfile\n",
    "    gwyfile_df = pd.DataFrame(gwyfile.util.get_datafields(gwyfile.load(gwy_file_name)))\n",
    "    # convert all gwy file channels to pd.DataFrame\n",
    "    pd.set_option('display.float_format', '{:.3e}'.format)\n",
    "    return gwyfile_df\n",
    "\n",
    "#gwy_df = gwyImage2df( file_list_df.file_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2efb2bee-f46e-4d6c-bd41-658b0f104e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gwy_df_channel2xr (gwy_df, ch_N=0): \n",
    "    import pandas as pd\n",
    "    #convert a channel data to xr DataArray format\n",
    "    chN_df = gwy_df.iloc[:,ch_N]\n",
    "    chNdf_temp = pd.DataFrame(chN_df.data.reshape((chN_df.yres, chN_df.xres))).stack()\n",
    "    chNdf_temp = chNdf_temp.rename_axis (['Y','X'])\n",
    "    x_step = chN_df.xreal / chN_df.xres \n",
    "    y_step = chN_df.yreal / chN_df.yres \n",
    "    chNxr = chNdf_temp.to_xarray()\n",
    "    chNxr = chNxr.assign_coords(X = chNxr.X.values * x_step, \n",
    "                                Y = chNxr.Y.values * y_step )\n",
    "    return chNxr\n",
    "\n",
    "# gwy_ch_xr = gwy_df_channel2xr(gwy_df, ch_N=3)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
