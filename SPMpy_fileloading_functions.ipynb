{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e893c60-b6e3-4e1a-b329-c10d0baf61dc",
   "metadata": {},
   "source": [
    "# SPMpy \n",
    "* Authors : Dr. Jewook Park at CNMS, ORNL\n",
    "    * Center for Nanophase Materials Sciences (CNMS), Oak Ridge National Laboratory (ORNL)\n",
    "    * email :  parkj1@ornl.gov\n",
    "        \n",
    "> **SPMpy** is a python package to analysis scanning probe microscopy (SPM) data analysis, such as scanning tunneling microscopy and spectroscopy (STM/S) data and atomic force microscopy (AFM) images, which are inherently multidimensional. SPMpy exploits recent image processing(a.k.a. Computer Vision) techniques, and utilzes [building blocks](https://scipy-lectures.org/intro/intro.html#the-scientific-python-ecosystem) and excellent visualization tools available in the [scientific python ecosystem](https://holoviz.org/index.html). Many parts are inspired by well-known SPM data analysis programs, for example, [Wsxm](http://www.wsxm.eu/) and [Gwyddion](http://gwyddion.net/). SPMpy is trying to apply lessons from [Fundamentals in Data Visualization](https://clauswilke.com/dataviz/).\n",
    "\n",
    ">  **SPMpy** is an open-source project. (Github: https://github.com/Jewook-Park/SPMPY )\n",
    "> * Contributions, comments, ideas, and error reports are always welcome. Please use the Github page or email parkj1@ornl.gov. Comments & remarks should be in Korean or English. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d4ac66-b3df-4bc8-80e2-b9165fbe1dfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# file_loading functions \n",
    "\n",
    "## 0. Choose the working folder\n",
    "## 1. Check file_list (DataFrame) \n",
    "*  *def* files_in_folder(path)\n",
    "\n",
    "## 2. Image to xarray \n",
    "*  *def* img2xr\n",
    "    * 2D image (topography & LDOS) to xarray\n",
    "    * input: nanonis 2D data (*.sxm)\n",
    "    * output : Xarray (_xr) with attributes \n",
    "    * nanonis (sxm) $\\to $ numpy $\\to $ pd.DataFrame(_df) $\\to $ xr.DataSet (_xr)\n",
    "    * (Xarray) attributes \n",
    "        * title, X_spacing, Y_spacing, freq_X_spacing, freq_Y_spacing\n",
    "        * attributes can be added later. \n",
    "\n",
    "## 3. Grid 3D to xarray \n",
    "*  *def* grid2xr* \n",
    "    * 3D data (grid spectroscopy) to xarray\n",
    "    * input: nanonis grid3d data set (*.3ds)\n",
    "    * output: Xarray (_xr) with attributes\n",
    "    * nanonis 3D data set (3ds)  $\\to $ numpy $\\to$ pd.DataFrame(_df) $\\to$ xr.DataSet (_xr) \n",
    "    * (Xarray) attributes\n",
    "        * title, X_spacing, Y_spacing, bias mV info, freq_X_spacing, freq_Y_spacing\n",
    "        * attributes can be added later. * attributes can be added later. \n",
    "        \n",
    "## 4. Line spectroscopy (1D grid) to xarray   \n",
    "*  *def* gridline2xr* \n",
    "    * in case of line spectroscopy: step_dy = 0 $\\to$ **error** \n",
    "    * input: *.3ds file (Line spectroscopy) \n",
    "    * output: Xarray (_xr) with attributes\n",
    "    * nanonis 3D data set (3ds)  $\\to $ numpy $\\to$ pd.DataFrame(_df) $\\to$ xr.DataSet (_xr) \n",
    "    * simply not using the step_dx\n",
    "\n",
    "\n",
    "## 5. Gwyddion 2D image to PANDAS Dataframe or Xarray\n",
    "### 5.1. gwy_img2df : gwy file name \n",
    "* Gwyddion data container to PANDAS DataFrame\n",
    "* input: *.gwy file\n",
    "    * gwyddion 2D image data (*gwy) $\\to $ numpy $\\to $  pd.DataFrame(_df)\n",
    "* output: PANDAS DataFrame\n",
    "    \n",
    "\n",
    "### 5.2. gwy_df_ch2xr : Choose a data channe in gwy_df \n",
    "* Gwyddion data container to Xarray DataArray\n",
    "* input: gwy_df dataframe & channel number ( N=0)\n",
    "    * pd.DataFrame(_df) $\\to $  xarray Dataset (_xr)\n",
    "* output: Xarray DataSet \n",
    "\n",
    "### 5.3. gwy_df2xr : Choose a data channe in gwy_df \n",
    "* Gwyddion data container to Xarray DataArray\n",
    "* using gwy_df_ch2xr function \n",
    "* input: gwy_df dataframe\n",
    "    * pd.DataFrame(_df) $\\to $  xarray Dataset (_xr)\n",
    "* output: Xarray DataSet \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d3179-1d93-4b84-968b-77fad1f7a7b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=blue>0. Choose the working folder </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8be2ae-1003-479b-91d0-bca494c24f6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# check all necessary package\n",
    "#############################\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from warnings import warn\n",
    "\n",
    "try:\n",
    "    from ipyfilechooser import FileChooser\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named ipyfilechooser')\n",
    "    %from ipyfilechooser import FileChooser\n",
    "\n",
    "try:\n",
    "    import xrft\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named xrft')\n",
    "    !pip install xrft \n",
    "    import xrft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ec26b8-0d42-42d7-a7cd-16f20995ac1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Create and display a FileChooser widget #\n",
    "###########################################\n",
    "#file_chooser = FileChooser('')\n",
    "#display(file_chooser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a6d09-4eeb-4064-878b-15df0b5449f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=blue>1. Check file_list (DataFrame) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66bf2c37-5736-484a-a8dd-e361000ce79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def files_in_folder(path_input): \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str \n",
    "        folder path \n",
    "        * copy and paste the folder path\n",
    "        * add 'r' to avoid unicodeerror \n",
    "    Returns\n",
    "    -------\n",
    "    file_list_df : PANDAS DataFrame\n",
    "        file list dataframe \n",
    "\"\"\"\n",
    "    import os\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import nanonispy as nap\n",
    "    currentPath = os.getcwd() #get current path\n",
    "    print (\"Current Path = \", os.getcwd()) # print current path \n",
    "    #######################################\n",
    "    working_folder = path_input\n",
    "    # copy & paste the \"SPM data file\" location (folder(path)) \n",
    "    os.chdir(working_folder)\n",
    "    print (\"Changed Path = \", os.getcwd()) \n",
    "    # check the re-located path \n",
    "    ####################################\n",
    "\n",
    "    ######################################\n",
    "    # call all the sxm  files in path    #\n",
    "    ######################################\n",
    "    path = \"./*\"\n",
    "    # pt_spec_file_list = (glob.glob('*.dat')) \n",
    "    sxm_file_list = (glob.glob('*.sxm')) \n",
    "    grid_file_list = (glob.glob('*.3ds')) \n",
    "    csv_file_list = (glob.glob('*.csv')) \n",
    "    gwy_file_list = (glob.glob('*.gwy')) \n",
    "    xlsx_file_list = (glob.glob('*.xlsx')) \n",
    "    # using \"glob\"  all \" *.sxm\" files  in file_list\n",
    "    #####################################\n",
    "    ## sxm file\n",
    "    file_list_sxm_df = pd.DataFrame([[\n",
    "        file[:-7],file[-7:-4],file] \n",
    "                                     for file in sxm_file_list],\n",
    "        columns =['group','num','file_name'])\n",
    "\n",
    "    sxm_file_groups= list (set(file_list_sxm_df['group']))\n",
    "    ## 3ds file\n",
    "    file_list_3ds_df = pd.DataFrame([[\n",
    "    file[:-7],file[-7:-4],file] \n",
    "                                 for file in grid_file_list],\n",
    "    columns =['group','num','file_name'])\n",
    "    ## csv file\n",
    "    file_list_csv_df = pd.DataFrame([[\n",
    "        file[:-7],file[-7:-4],file] \n",
    "                                     for file in csv_file_list],\n",
    "        columns =['group','num','file_name'])\n",
    "    ## gwy file\n",
    "    file_list_gwy_df = pd.DataFrame([[\n",
    "        file[:-4], np.nan, file] \n",
    "                                     for file in gwy_file_list],\n",
    "        columns =['group','num','file_name'])   \n",
    "    \n",
    "    ## excel file\n",
    "    file_list_xlsx_df = pd.DataFrame([[\n",
    "        file[:-5], np.nan, file] \n",
    "                                     for file in xlsx_file_list],\n",
    "        columns =['group','num','file_name']) \n",
    "    \n",
    "    file_list_df = pd.concat ([file_list_sxm_df, file_list_3ds_df, file_list_csv_df, file_list_gwy_df,file_list_xlsx_df],ignore_index= True)\n",
    "    file_list_df['type'] = [file_name[-3:] for file_name in  file_list_df.file_name]\n",
    "    file_list_df.type [ file_list_df.type == 'lsx']  = 'xlsx'\n",
    "    print (file_list_df)\n",
    "\n",
    "    \n",
    "    #############################################################\n",
    "    # to call all the files in sxm_file_groups[0]\n",
    "    ##  file_list_df[file_list_df['group'] == sxm_file_groups[0]]\n",
    "    #############################################################\n",
    "    #print (file_list_sxm_df)\n",
    "    #print (file_list_3ds_df)\n",
    "    # indicates # of files in each group \n",
    "    for group in sxm_file_groups:\n",
    "        print ('sxm file groups :  ', group, ':  # of files = ',\n",
    "               len(file_list_sxm_df[file_list_sxm_df['group'] == group]) )\n",
    "    if len(file_list_df[file_list_df['type'] == '3ds']) ==0 :\n",
    "        print ('No GridSpectroscopy data')\n",
    "    else :\n",
    "        print ('# of GridSpectroscopy',\n",
    "               list(set(file_list_df[file_list_df['type'] == '3ds'].group))[0], \n",
    "               ' = ',           \n",
    "               file_list_df[file_list_df['type'] == '3ds'].group.count())\n",
    "\n",
    "    return file_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566bf38-936f-4e33-b2d7-72442238c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nanonispy as nap\n",
    "\n",
    "def files_in_folder(path_input):\n",
    "    \"\"\"\n",
    "    Retrieve file information from a specified folder path.\n",
    "\n",
    "    Parameters:\n",
    "    - path_input (str): \n",
    "    Folder path where files are located.\n",
    "    Use 'r' to avoid UnicodeError.\n",
    "\n",
    "    Returns:\n",
    "    - file_list_df (pd.DataFrame): \n",
    "    DataFrame containing information about files in the folder.\n",
    "    ---\n",
    "    Summary\n",
    "    \n",
    "    Imports necessary libraries, including os, glob, pandas, numpy, and nanonispy.\n",
    "    Gets the current working directory using os.getcwd() and prints it.\n",
    "    Changes the working directory to the provided folder path\n",
    "    using os.chdir() and prints the new working directory.\n",
    "    Uses glob.glob() to find specific types of files \n",
    "    (*.sxm, *.3ds, *.csv, *.gwy, and *.xlsx) \n",
    "    in the folder and stores their filenames in separate lists.\n",
    "\n",
    "    Creates Pandas DataFrames \n",
    "    (file_list_sxm_df, \n",
    "    file_list_3ds_df,\n",
    "    file_list_csv_df,\n",
    "    file_list_gwy_df,\n",
    "    and file_list_xlsx_df) for each type of file,\n",
    "    extracting the group, number, and file name from the filenames.\n",
    "\n",
    "    Concatenates these DataFrames into a single Pandas DataFrame called file_list_df.\n",
    "    Assigns file types based on the file extensions, converting 'lsx' to 'xlsx' for Excel files.\n",
    "    Prints information about the files, including the resulting DataFrame.\n",
    "    Optionally, it provides additional information about the number of files in each group and the presence of GridSpectroscopy data.\n",
    "    Returns the file_list_df DataFrame as the function's output.\n",
    "    ---\n",
    "    \n",
    "    \"\"\"\n",
    "    import os\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import nanonispy as nap\n",
    "    currentPath = os.getcwd()\n",
    "    print(\"Current Path = \", os.getcwd())\n",
    "\n",
    "    working_folder = path_input\n",
    "    os.chdir(working_folder)\n",
    "    print(\"Changed Path = \", os.getcwd())\n",
    "\n",
    "    path = \"./*\"\n",
    "    sxm_file_list = (glob.glob('*.sxm'))\n",
    "    grid_file_list = (glob.glob('*.3ds'))\n",
    "    csv_file_list = (glob.glob('*.csv'))\n",
    "    gwy_file_list = (glob.glob('*.gwy'))\n",
    "    xlsx_file_list = (glob.glob('*.xlsx'))\n",
    "\n",
    "    file_list_sxm_df = pd.DataFrame([[\n",
    "        file[:-7], file[-7:-4], file]\n",
    "                                     for file in sxm_file_list],\n",
    "                                    columns=['group', 'num', 'file_name'])\n",
    "\n",
    "    sxm_file_groups = list(set(file_list_sxm_df['group']))\n",
    "\n",
    "    file_list_3ds_df = pd.DataFrame([[\n",
    "        file[:-7], file[-7:-4], file]\n",
    "                                     for file in grid_file_list],\n",
    "                                    columns=['group', 'num', 'file_name'])\n",
    "\n",
    "    file_list_csv_df = pd.DataFrame([[\n",
    "        file[:-7], file[-7:-4], file]\n",
    "                                    for file in csv_file_list],\n",
    "                                   columns=['group', 'num', 'file_name'])\n",
    "\n",
    "    file_list_gwy_df = pd.DataFrame([[\n",
    "        file[:-4], np.nan, file]\n",
    "                                    for file in gwy_file_list],\n",
    "                                   columns=['group', 'num', 'file_name'])\n",
    "\n",
    "    file_list_xlsx_df = pd.DataFrame([[\n",
    "        file[:-5], np.nan, file]\n",
    "                                      for file in xlsx_file_list],\n",
    "                                     columns=['group', 'num', 'file_name'])\n",
    "\n",
    "    file_list_df = pd.concat([file_list_sxm_df, \n",
    "                              file_list_3ds_df, \n",
    "                              file_list_csv_df, \n",
    "                              file_list_gwy_df, \n",
    "                              file_list_xlsx_df],\n",
    "                             ignore_index=True)\n",
    "    file_list_df['type'] = [file_name[-3:] for file_name in file_list_df.file_name]\n",
    "    file_list_df.type[file_list_df.type == 'lsx'] = 'xlsx'\n",
    "    print(file_list_df)\n",
    "\n",
    "    for group in sxm_file_groups:\n",
    "        print('sxm file groups: ', group, ': # of files = ',\n",
    "              len(file_list_sxm_df[file_list_sxm_df['group'] == group]))\n",
    "\n",
    "    if len(file_list_df[file_list_df['type'] == '3ds']) == 0:\n",
    "        print('No GridSpectroscopy data')\n",
    "    else:\n",
    "        print('# of GridSpectroscopy',\n",
    "              list(set(file_list_df[file_list_df['type'] == '3ds'].group))[0],\n",
    "              ' = ',\n",
    "              file_list_df[file_list_df['type'] == '3ds'].group.count())\n",
    "\n",
    "    return file_list_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89505e5e-9876-4ba8-8ae0-2fcfe756e6a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=blue>2. Image to xarray</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3025d8-385d-49d7-91b3-a8d85c44e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata in c:\\users\\gkp\\appdata\\local\\anaconda3\\lib\\site-packages (6.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gkp\\appdata\\local\\anaconda3\\lib\\site-packages (from importlib-metadata) (3.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# check all necessary package #\n",
    "# for img2xr                  #\n",
    "###############################\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from warnings import warn\n",
    "%pip install importlib-metadata\n",
    "# 2023 0510 added \n",
    "\n",
    "try:\n",
    "    import nanonispy as nap\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named nanonispy')\n",
    "    %pip install nanonispy\n",
    "    import nanonispy as nap\n",
    "\n",
    "try:\n",
    "    import xarray as xr\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named xarray')\n",
    "    #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "    %pip install xarray \n",
    "    import xarray as xr\n",
    "\n",
    "try:\n",
    "    import seaborn_image as isns\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "    #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "    %pip install --upgrade seaborn-image    \n",
    "    import seaborn_image as isns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a09e74c3-bdd3-44e4-9675-1271a664af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original img2xr \n",
    "# not consider multipass cases\n",
    "\"\"\"\n",
    "def img2xr (loading_sxm_file, center_offset = False):\n",
    "    # import necessary module \n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import math\n",
    "    import matplotlib.pyplot as plt\n",
    "    import re\n",
    "\n",
    "    from warnings import warn\n",
    "\n",
    "    try:\n",
    "        import nanonispy as nap\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named nanonispy')\n",
    "        %pip install nanonispy\n",
    "        import nanonispy as nap\n",
    "\n",
    "    try:\n",
    "        import xarray as xr\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xarray')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        %pip install xarray \n",
    "        import xarray as xr\n",
    "\n",
    "    try:\n",
    "        import seaborn_image as isns\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        %pip install --upgrade seaborn-image    \n",
    "        import seaborn_image as isns\n",
    "\n",
    "\n",
    "    NF = nap.read.NanonisFile(loading_sxm_file)\n",
    "    Scan = nap.read.Scan(NF.fname)\n",
    "    #Scan.basename # file name only *.sxm \n",
    "    #Scan.header # heater dict \n",
    "    ##############################\n",
    "    # Scan conditions from the header\n",
    "    V_b = float(Scan.header['bias>bias (v)'])\n",
    "    I_t = float(Scan.header['z-controller>setpoint'])\n",
    "\n",
    "    [size_x,size_y] = Scan.header['scan_range']\n",
    "    [cntr_x, cntr_y] = Scan.header['scan_offset']\n",
    "    [dim_px,dim_py] = Scan.header['scan_pixels']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size = size / pixel\n",
    "    Rot_Rad = math.radians( float(Scan.header['scan_angle'])) \n",
    "    #str --> degree to radian \n",
    "\n",
    "    print ('scan direction (up/down): ', Scan.header['scan_dir'])\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])\n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])\n",
    "    # nX,nY for meshgrid (start from 1/2, not 0 )\n",
    "    # x, y steps with dimension \n",
    "    # In case of rotation ==0\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    \n",
    "    #########################################################################\n",
    "    # np.meshgrid \n",
    "    x_mesh_0, y_mesh_0 = np.meshgrid(nX, nY)\n",
    "    x_mesh = cntr_x - size_x + x_mesh_0\n",
    "    y_mesh = cntr_y - size_y + y_mesh_0 \n",
    "    # if there is rotation \n",
    "    x_mesh_r   =  np.cos(Rot_Rad)*x_mesh_0 + np.sin(Rot_Rad)*y_mesh_0  # \"cloclwise\"\n",
    "    y_mesh_r   = -np.sin(Rot_Rad)*x_mesh_0 + np.cos(Rot_Rad)*y_mesh_0\n",
    "    #########################################################################\n",
    "    # image title \n",
    "    # if there is rotation ( rot !=0 ), display it. \n",
    "    if Rot_Rad ==0 : \n",
    "        image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                    ' V = '+ str(V_b) + ' V ' +\\\n",
    "                        ' I = ' + str(round(I_t *1E12)) + ' pA ' \n",
    "    else: \n",
    "        image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                    ' V = '+ str(V_b) + ' V ' +\\\n",
    "                        ' I = ' + str(round(I_t *1E12)) + ' pA ' +\\\n",
    "                            ' R = ' + str(int(math.degrees(Rot_Rad))) + 'deg'\n",
    "    print(image_title)\n",
    "    #########################################################################\n",
    "    # scan channels in DataFrame\n",
    "\n",
    "    #Scan.signals.keys()\n",
    "    Scan.signals['Z'].keys()\n",
    "    \n",
    "    Scan.signals['Z']['forward'].shape\n",
    "    z_fwd = Scan.signals['Z']['forward']\n",
    "    z_bwd = Scan.signals['Z']['backward'][:,::-1]\n",
    "\n",
    "    \n",
    "    #print(Scan.signals.keys())\n",
    "    \n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_key = [s  for s in Scan.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "    print(LIX_key)\n",
    "    # chech the LIX is empty or not \n",
    "    if len(LIX_key) == 0: \n",
    "        print(\"LIX is empty, Current ch substitutes LIX \")\n",
    "        LIX_fwd  = Scan.signals['Current']['forward']\n",
    "        LIX_bwd  = Scan.signals['Current']['backward'][:,::-1]\n",
    "    else:\n",
    "        # 0 is fwd, 1 is bwd \n",
    "        LIX_fwd  = Scan.signals[LIX_key[0]]['forward']\n",
    "        LIX_bwd  = Scan.signals[LIX_key[0]]['backward'][:,::-1]\n",
    "\n",
    "    #LIX_fwd = Scan.signals['LI_Demod_1_X']['forward']\n",
    "    #LIX_bwd = Scan.signals['LI_Demod_1_X']['backward'][:,::-1]\n",
    "    # LIX channel name varies w.r.t nanonis version \n",
    "    \n",
    "    # same for LIY --> update later.. if needed \n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    #LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    #LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "     \n",
    "    #bwd channel : opposite data direction in X ==> reverse it. \n",
    "    ########################################\n",
    "    if Scan.header['scan_dir'] == 'down':\n",
    "        z_fwd = z_fwd[::-1,:]\n",
    "        z_bwd = z_bwd[::-1,:]\n",
    "        LIX_fwd = LIX_fwd[::-1,:]\n",
    "        LIX_bwd = LIX_bwd[::-1,:]\n",
    "    # if scan_direction == down, flip the data (Y)\n",
    "    ########################################\n",
    "    z_fwd_df = pd.DataFrame(z_fwd)\n",
    "    z_fwd_df.index.name ='row_y'\n",
    "    z_fwd_df.columns.name ='col_x'\n",
    "\n",
    "    z_bwd_df = pd.DataFrame(z_bwd)\n",
    "    z_bwd_df.index.name ='row_y'\n",
    "    z_bwd_df.columns.name ='col_x'\n",
    "\n",
    "    LIX_fwd_df = pd.DataFrame(LIX_fwd)\n",
    "    LIX_fwd_df.index.name ='row_y'\n",
    "    LIX_fwd_df.columns.name ='col_x'\n",
    "\n",
    "    LIX_bwd_df = pd.DataFrame(LIX_bwd)\n",
    "    LIX_bwd_df.index.name ='row_y'\n",
    "    LIX_bwd_df.columns.name ='col_x'\n",
    "    # save data channels as DataFrame\n",
    "    ########################################\n",
    "    z_fwd_df = z_fwd_df.fillna(0)\n",
    "    z_bwd_df = z_bwd_df.fillna(0)\n",
    "    LIX_fwd_df = LIX_fwd_df.fillna(0)   \n",
    "    LIX_bwd_df = LIX_bwd_df.fillna(0)\n",
    "    # in case of incompleted scan ==> np.nan in data point, ==> fillna()\n",
    "    ########################################\n",
    "\n",
    "    ############################\n",
    "    # conver to DataFrame (PANDAS) \n",
    "    z_LIX_fNb_df = pd.concat([z_fwd_df.stack(),\n",
    "                              z_bwd_df.stack(),\n",
    "                              LIX_fwd_df.stack(),\n",
    "                              LIX_bwd_df.stack()], axis = 1)\n",
    "    # set colunm name for new DataFrame\n",
    "    z_LIX_fNb_df.columns =['z_fwd','z_bwd', 'LIX_fwd','LIX_bwd']\n",
    "    # z_LIX_fNb_df\n",
    "    ############################\n",
    "    # conver to xarray \n",
    "    ############################\n",
    "    z_LIX_fNb_xr = z_LIX_fNb_df.to_xarray()\n",
    "    # rename coord as \"X\", \"Y\" \n",
    "    z_LIX_fNb_xr = z_LIX_fNb_xr.rename(\n",
    "        {\"row_y\": \"Y\", \"col_x\":\"X\"})\n",
    "    # real size of XY \n",
    "    z_LIX_fNb_xr= z_LIX_fNb_xr.assign_coords(\n",
    "        X = z_LIX_fNb_xr.X.values *step_dx, \n",
    "        Y = z_LIX_fNb_xr.Y.values *step_dy )\n",
    "    # XY axis: 0 ~ size_XY\n",
    "\n",
    "    ############################\n",
    "    # check the XY ratio \n",
    "    ############################\n",
    "    if  size_x == size_y : \n",
    "        pass\n",
    "    else : \n",
    "        print ('size_x != size_y')\n",
    "    # if xy size is not same, report it! \n",
    "\n",
    "    if step_dx != step_dy :\n",
    "        xystep_ratio = step_dy/step_dx # check the XY pixel_ratio\n",
    "        X_interp = np.linspace(z_LIX_fNb_xr.X[0], z_LIX_fNb_xr.X[-1], z_LIX_fNb_xr.X.shape[0]*1)\n",
    "        step_dx = step_dx # step_dx check \n",
    "\n",
    "        Y_interp = np.linspace(z_LIX_fNb_xr.Y[0], z_LIX_fNb_xr.Y[-1], int(z_LIX_fNb_xr.Y.shape[0]*xystep_ratio)) \n",
    "        step_dy = step_dy/ xystep_ratio # step_dy check \n",
    "\n",
    "        # interpolation ratio should be int\n",
    "        z_LIX_fNb_xr= z_LIX_fNb_xr.interp(X = X_interp, Y = Y_interp, method=\"linear\")\n",
    "        print('step_dx/step_dy = ', xystep_ratio)\n",
    "        print ('z_LIX_fNb_xr ==> reshaped')\n",
    "    else: \n",
    "        z_LIX_fNb_xr =z_LIX_fNb_xr\n",
    "        print('step_dx == step_dy')\n",
    "    #print('z_LIX_fNb_xr', 'step_dx, step_dy = ',  z_LIX_fNb_xr.dims)\n",
    "    print('z_LIX_fNb_xr', 'step_dx, step_dy = ', \n",
    "          re.findall('\\{([^}]+)', str(z_LIX_fNb_xr.dims)))\n",
    "    # regex practice\n",
    "\n",
    "\n",
    "    ##########\n",
    "    #################################\n",
    "    # assigne attributes \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    z_LIX_fNb_xr.attrs['title'] = image_title\n",
    "    if 'Wtip' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'W'\n",
    "    elif 'Ni_tip' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Ni'\n",
    "    elif 'Co_coated' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Co_coated'\n",
    "    elif 'AFM' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'AFM'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'To Be Announced'\n",
    "        print('tip material will be announced')\n",
    "    \n",
    "    if 'NbSe2' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'NbSe2'\n",
    "    elif 'Cu(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Cu(111)'\n",
    "    elif 'Au(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Au(111)'\n",
    "    elif 'MoS2' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'MoS2'\n",
    "    elif 'FeTe0.55Se0.45' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'FeTe0.55Se0.45'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'To Be Announced'\n",
    "        print('sample type will be announced')\n",
    "    \n",
    "    z_LIX_fNb_xr.attrs['image_size'] = [size_x,size_y]\n",
    "    z_LIX_fNb_xr.attrs['X_spacing'] = step_dx\n",
    "    z_LIX_fNb_xr.attrs['Y_spacing'] = step_dy    \n",
    "    z_LIX_fNb_xr.attrs['freq_X_spacing'] = 1/step_dx\n",
    "    z_LIX_fNb_xr.attrs['freq_Y_spacing'] = 1/step_dy\n",
    "\n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        z_LIX_fNb_xr.assign_coords(X=(z_LIX_fNb_xr.X + cntr_x -  size_x/2))\n",
    "        z_LIX_fNb_xr.assign_coords(Y=(z_LIX_fNb_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "\n",
    "\n",
    "    #################################\n",
    "    # test & how to use xr data \n",
    "    # z_LIX_fNb_xr  # xr dataset (with data array channels )\n",
    "    #z_LIX_fNb_xr.z_fwd # select data channel\n",
    "    #z_LIX_fNb_xr.data_vars # data channels check \n",
    "    #z_LIX_fNb_xr.z_fwd.values  # to call data array in nd array \n",
    "    #z_yLIX_fNb_xr.dims # data channel dimension (coords) \n",
    "    #z_LIX_fNb_xr.coords # data  channel coordinates check \n",
    "    #z_LIX_fNb_xr.attrs # data  channel attributes check \n",
    "\n",
    "    return z_LIX_fNb_xr\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d267ab0f-05fe-40a3-94b0-7fd09e65b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2xr (loading_sxm_file, center_offset = False):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    Convert Nanonis .sxm file data to an xarray dataset.\n",
    "\n",
    "    Parameters:\n",
    "    loading_sxm_file (str): The path to the Nanonis .sxm file to be loaded.\n",
    "    center_offset (bool): If True, \n",
    "        adjusts the scan data to center it within the scanner's field of view.\n",
    "\n",
    "    Returns:\n",
    "    xarray.Dataset: An xarray dataset containing the scan data.\n",
    "\n",
    "    Raises:\n",
    "    ModuleNotFoundError: \n",
    "        If required modules (nanonispy, xarray, seaborn-image) are not found, \n",
    "        it attempts to install them.\n",
    "\n",
    "    Example:\n",
    "    >>> data = img2xr('path/to/your/file.sxm', center_offset=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # updated for multipass \n",
    "    # import necessary module \n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import math\n",
    "    import matplotlib.pyplot as plt\n",
    "    import re\n",
    "\n",
    "    from warnings import warn\n",
    "\n",
    "    try:\n",
    "        import nanonispy as nap\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named nanonispy')\n",
    "        %pip install nanonispy\n",
    "        import nanonispy as nap\n",
    "\n",
    "    try:\n",
    "        import xarray as xr\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xarray')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        %pip install xarray \n",
    "        import xarray as xr\n",
    "\n",
    "    try:\n",
    "        import seaborn_image as isns\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        %pip install --upgrade seaborn-image    \n",
    "        import seaborn_image as isns\n",
    "\n",
    "\n",
    "    NF = nap.read.NanonisFile(loading_sxm_file)\n",
    "    Scan = nap.read.Scan(NF.fname)\n",
    "    #Scan.basename # file name only *.sxm \n",
    "    #Scan.header # heater dict \n",
    "    ##############################\n",
    "    # Scan conditions from the header\n",
    "    V_b = float(Scan.header['bias>bias (v)'])\n",
    "    I_t = float(Scan.header['z-controller>setpoint'])\n",
    "\n",
    "    [size_x,size_y] = Scan.header['scan_range']\n",
    "    [cntr_x, cntr_y] = Scan.header['scan_offset']\n",
    "    [dim_px,dim_py] = Scan.header['scan_pixels']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size = size / pixel\n",
    "    Rot_Rad = math.radians( float(Scan.header['scan_angle'])) \n",
    "    #str --> degree to radian \n",
    "\n",
    "    print ('scan direction (up/down): ', Scan.header['scan_dir'])\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])\n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])\n",
    "    # nX,nY for meshgrid (start from 1/2, not 0 )\n",
    "    # x, y steps with dimension \n",
    "    # In case of rotation ==0\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    \n",
    "    #########################################################################\n",
    "    # np.meshgrid \n",
    "    x_mesh_0, y_mesh_0 = np.meshgrid(nX, nY)\n",
    "    x_mesh = cntr_x - size_x + x_mesh_0\n",
    "    y_mesh = cntr_y - size_y + y_mesh_0 \n",
    "    # if there is rotation \n",
    "    x_mesh_r   =  np.cos(Rot_Rad)*x_mesh_0 + np.sin(Rot_Rad)*y_mesh_0  # \"cloclwise\"\n",
    "    y_mesh_r   = -np.sin(Rot_Rad)*x_mesh_0 + np.cos(Rot_Rad)*y_mesh_0\n",
    "    #########################################################################\n",
    "\n",
    "    \n",
    "    #########################################################################\n",
    "    # scan channels in DataFrame\n",
    "\n",
    "    if 'multipass-config' in Scan.header.keys():\n",
    "        print ('multipass detected')\n",
    "        multipass = True\n",
    "        # add xr attribute 'multipass' = True \n",
    "\n",
    "    else: \n",
    "        multipass = False\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "    # check image names --> multi pass? --> rotate? \n",
    "    if multipass == True :\n",
    "        # image title \n",
    "        # multi pass bias voltage in str\n",
    "        # 'Pass1 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][0])*1000,2)) +' mV' +\n",
    "        # '/ Pass1 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][1])*1000,2)) +' mV' +\n",
    "        # '// Pass2 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][2])*1000,2)) +' mV' + \n",
    "        # '/ Pass2 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][3])*1000,2)) +' mV'\n",
    "\n",
    "        # if there is rotation ( rot !=0 ), display it. \n",
    "        if Rot_Rad ==0 : \n",
    "            image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "            str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "            ' V = '+ str(V_b) + ' V ' +\\\n",
    "            ' I = ' + str(round(I_t *1E12)) + ' pA '  + '\\n' + \\\n",
    "            'Pass1 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][0])*1000,2)) +' mV' +\\\n",
    "            '/ Pass1 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][1])*1000,2)) +' mV' +\\\n",
    "            '// Pass2 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][2])*1000,2)) +' mV' + \\\n",
    "            '/ Pass2 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][3])*1000,2)) +' mV'\n",
    "            \n",
    "        else: \n",
    "            image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "            str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "            ' V = '+ str(V_b) + ' V ' +\\\n",
    "            ' I = ' + str(round(I_t *1E12)) + ' pA ' +\\\n",
    "            ' R = ' + str(int(math.degrees(Rot_Rad))) + 'deg' +\\\n",
    "            'Pass1 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][0])*1000,2)) +' mV' +\\\n",
    "            '/ Pass1 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][1])*1000,2)) +' mV' +\\\n",
    "            '// Pass2 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][2])*1000,2)) +' mV' + \\\n",
    "            '/ Pass2 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][3])*1000,2)) +' mV'\n",
    "            \n",
    "        print(image_title)\n",
    "\n",
    "        \n",
    "    else : \n",
    "        # normal without multi pass. only check rot \n",
    "\n",
    "        # if there is rotation ( rot !=0 ), display it. \n",
    "        if Rot_Rad ==0 : \n",
    "            image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "                str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                    str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                        ' V = '+ str(V_b) + ' V ' +\\\n",
    "                            ' I = ' + str(round(I_t *1E12)) + ' pA ' \n",
    "        else: \n",
    "            image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "                str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                    str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                        ' V = '+ str(V_b) + ' V ' +\\\n",
    "                            ' I = ' + str(round(I_t *1E12)) + ' pA ' +\\\n",
    "                                ' R = ' + str(int(math.degrees(Rot_Rad))) + 'deg'\n",
    "        print(image_title)\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################\n",
    "    if multipass == True :\n",
    "\n",
    "        P1_Z_keys =  [s  for s in Scan.signals.keys()  if \"P1\"  in s  if \"Z\" in s ]\n",
    "        P2_Z_keys =  [s  for s in Scan.signals.keys()  if \"P2\"  in s  if \"Z\" in s ]\n",
    "\n",
    "        P1_LIX_keys =  [s  for s in Scan.signals.keys()  if \"P1\"  in s  if \"LI\" in s if \"X\" in s ]\n",
    "        P2_LIX_keys =  [s  for s in Scan.signals.keys()  if \"P2\"  in s  if \"LI\" in s if \"X\" in s ]\n",
    "\n",
    "\n",
    "        # add xr attribute 'multipass' = True \n",
    "        Z_P1fwd = Scan.signals[P1_Z_keys[0]]['forward']\n",
    "        Z_P1bwd = Scan.signals[P1_Z_keys[0]]['backward'][:,::-1]\n",
    "        Z_P2fwd = Scan.signals[P2_Z_keys[0]]['forward']\n",
    "        Z_P2bwd = Scan.signals[P2_Z_keys[0]]['backward'][:,::-1]\n",
    "\n",
    "        LIX_P1fwd = Scan.signals[P1_LIX_keys[0]]['forward']\n",
    "        LIX_P1bwd = Scan.signals[P1_LIX_keys[0]]['backward'][:,::-1]\n",
    "        LIX_P2fwd = Scan.signals[P2_LIX_keys[0]]['forward']\n",
    "        LIX_P2bwd = Scan.signals[P2_LIX_keys[0]]['backward'][:,::-1]\n",
    "\n",
    "        data_vars_name = [Z_P1fwd, Z_P1bwd, LIX_P1fwd,LIX_P1bwd, Z_P2fwd, Z_P2bwd, LIX_P2fwd,LIX_P2bwd]\n",
    "    else:    \n",
    "\n",
    "\n",
    "        #Scan.signals.keys()\n",
    "        Scan.signals['Z'].keys()\n",
    "\n",
    "        Scan.signals['Z']['forward'].shape\n",
    "        z_fwd = Scan.signals['Z']['forward']\n",
    "        z_bwd = Scan.signals['Z']['backward'][:,::-1]\n",
    "\n",
    "\n",
    "        #print(Scan.signals.keys())\n",
    "\n",
    "        #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "        # 'LI' & 'X' in  channel name (signal.keys) \n",
    "        LIX_key = [s  for s in Scan.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "        print(LIX_key)\n",
    "        # chech the LIX is empty or not \n",
    "        if len(LIX_key) == 0: \n",
    "            print(\"LIX is empty, Current ch substitutes LIX \")\n",
    "            LIX_fwd  = Scan.signals['Current']['forward']\n",
    "            LIX_bwd  = Scan.signals['Current']['backward'][:,::-1]\n",
    "        else:\n",
    "            # 0 is fwd, 1 is bwd \n",
    "            LIX_fwd  = Scan.signals[LIX_key[0]]['forward']\n",
    "            LIX_bwd  = Scan.signals[LIX_key[0]]['backward'][:,::-1]\n",
    "\n",
    "        #LIX_fwd = Scan.signals['LI_Demod_1_X']['forward']\n",
    "        #LIX_bwd = Scan.signals['LI_Demod_1_X']['backward'][:,::-1]\n",
    "        # LIX channel name varies w.r.t nanonis version \n",
    "\n",
    "        # same for LIY --> update later.. if needed \n",
    "        #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "        # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "        #LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "        # 0 is fwd, 1 is bwd \n",
    "        #LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "\n",
    "        #bwd channel : opposite data direction in X ==> reverse it. \n",
    "\n",
    "\n",
    "    ########################################\n",
    "    if Scan.header['scan_dir'] == 'down':\n",
    "        if multipass == True : \n",
    "            for data_var_name in data_vars_name : \n",
    "                data_var_name = data_var_name[::-1,:]\n",
    "\n",
    "        else: \n",
    "            z_fwd = z_fwd[::-1,:]\n",
    "            z_bwd = z_bwd[::-1,:]\n",
    "            LIX_fwd = LIX_fwd[::-1,:]\n",
    "            LIX_bwd = LIX_bwd[::-1,:]\n",
    "    # if scan_direction == down, flip the data (Y)\n",
    "    ########################################\n",
    "    if multipass == True :\n",
    "        #Z_P1fwd, Z_P1bwd, LIX_P1fwd,LIX_Pbwd, Z_P2fwd, Z_P2bwd, LIX_P2fwd,LIX_P2bwd\n",
    "\n",
    "        Z_P1fwd_df  = pd.DataFrame(Z_P1fwd)\n",
    "        Z_P1fwd_df.index.name ='row_y'\n",
    "        Z_P1fwd_df.columns.name ='col_x'\n",
    "\n",
    "        Z_P1bwd_df  = pd.DataFrame(Z_P1bwd)\n",
    "        Z_P1bwd_df.index.name ='row_y'\n",
    "        Z_P1bwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_P1fwd_df  = pd.DataFrame(LIX_P1fwd)\n",
    "        LIX_P1fwd_df.index.name ='row_y'\n",
    "        LIX_P1fwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_P1bwd_df  = pd.DataFrame(LIX_P1bwd)\n",
    "        LIX_P1bwd_df.index.name ='row_y'\n",
    "        LIX_P1bwd_df.columns.name ='col_x'\n",
    "\n",
    "        Z_P2fwd_df  = pd.DataFrame(Z_P2fwd)\n",
    "        Z_P2fwd_df.index.name ='row_y'\n",
    "        Z_P2fwd_df.columns.name ='col_x'\n",
    "\n",
    "        Z_P2bwd_df  = pd.DataFrame(Z_P2bwd)\n",
    "        Z_P2bwd_df.index.name ='row_y'\n",
    "        Z_P2bwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_P2fwd_df  = pd.DataFrame(LIX_P2fwd)\n",
    "        LIX_P2fwd_df.index.name ='row_y'\n",
    "        LIX_P2fwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_P2bwd_df  = pd.DataFrame(LIX_P2bwd)\n",
    "        LIX_P2bwd_df.index.name ='row_y'\n",
    "        LIX_P2bwd_df.columns.name ='col_x'\n",
    "               # save data channels as DataFrame\n",
    "\n",
    "        ########################################\n",
    "        Z_P1fwd_df = Z_P1fwd_df.fillna(Z_P1fwd.mean())\n",
    "        Z_P1bwd_df = Z_P1bwd_df.fillna(Z_P1bwd.mean())\n",
    "        Z_P2fwd_df = Z_P2fwd_df.fillna(Z_P2fwd.mean())\n",
    "        Z_P2bwd_df = Z_P2bwd_df.fillna(Z_P2bwd.mean())\n",
    "        # fillna using previous numpy array. \n",
    "        LIX_P1fwd_df = LIX_P1fwd_df.fillna(LIX_P1fwd.mean())\n",
    "        LIX_P1bwd_df = LIX_P1bwd_df.fillna(LIX_P1bwd.mean())\n",
    "        LIX_P2fwd_df = LIX_P2fwd_df.fillna(LIX_P2fwd.mean())\n",
    "        LIX_P2bwd_df = LIX_P2bwd_df.fillna(LIX_P2bwd.mean())\n",
    "        # in case of incompleted scan ==> np.nan in data point, ==> fillna()\n",
    "        # how about fill df.mean ? \n",
    "    else : \n",
    "    ########################################\n",
    "\n",
    "        z_fwd_df = pd.DataFrame(z_fwd)\n",
    "        z_fwd_df.index.name ='row_y'\n",
    "        z_fwd_df.columns.name ='col_x'\n",
    "\n",
    "        z_bwd_df = pd.DataFrame(z_bwd)\n",
    "        z_bwd_df.index.name ='row_y'\n",
    "        z_bwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_fwd_df = pd.DataFrame(LIX_fwd)\n",
    "        LIX_fwd_df.index.name ='row_y'\n",
    "        LIX_fwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_bwd_df = pd.DataFrame(LIX_bwd)\n",
    "        LIX_bwd_df.index.name ='row_y'\n",
    "        LIX_bwd_df.columns.name ='col_x'\n",
    "            # save data channels as DataFrame\n",
    "        ########################################\n",
    "        z_fwd_df = z_fwd_df.fillna(0)\n",
    "        z_bwd_df = z_bwd_df.fillna(0)\n",
    "        LIX_fwd_df = LIX_fwd_df.fillna(0)   \n",
    "        LIX_bwd_df = LIX_bwd_df.fillna(0)\n",
    "        # in case of incompleted scan ==> np.nan in data point, ==> fillna()\n",
    "        # how about fill df.mean ? \n",
    "            #  we can keep the max & min values \n",
    "            # or just leave as np.nan --> FFT calc. issue. \n",
    "            # 2D sxm summary --> fillna(0) , otherwise --> leave it as nan\n",
    "        ########################################\n",
    "\n",
    "\n",
    "    if multipass == True :\n",
    "        ############################\n",
    "        # conver to DataFrame (PANDAS) \n",
    "        z_LIX_fNb_df = pd.concat([Z_P1fwd_df.stack(),Z_P1bwd_df.stack(),\n",
    "                                  LIX_P1fwd_df.stack(),LIX_P1bwd_df.stack(),\n",
    "                                  Z_P2fwd_df.stack(),Z_P2bwd_df.stack(),\n",
    "                                  LIX_P2fwd_df.stack(),LIX_P2bwd_df.stack()],\n",
    "                                 axis = 1)\n",
    "        # set colunm name for new DataFrame\n",
    "        z_LIX_fNb_df.columns =['Z_P1fwd','Z_P1bwd', 'LIX_P1fwd','LIX_P1bwd','Z_P2fwd','Z_P2bwd', 'LIX_P2fwd','LIX_P2bwd']\n",
    "        # z_LIX_fNb_df      \n",
    "\n",
    "    else:\n",
    "        ############################\n",
    "        # conver to DataFrame (PANDAS) \n",
    "        z_LIX_fNb_df = pd.concat([z_fwd_df.stack(),\n",
    "                                  z_bwd_df.stack(),\n",
    "                                  LIX_fwd_df.stack(),\n",
    "                                  LIX_bwd_df.stack()], axis = 1)\n",
    "        # set colunm name for new DataFrame\n",
    "        z_LIX_fNb_df.columns =['z_fwd','z_bwd', 'LIX_fwd','LIX_bwd']\n",
    "        # z_LIX_fNb_df\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # conver to xarray \n",
    "    ############################\n",
    "    z_LIX_fNb_xr = z_LIX_fNb_df.to_xarray()\n",
    "    # rename coord as \"X\", \"Y\" \n",
    "    z_LIX_fNb_xr = z_LIX_fNb_xr.rename(\n",
    "        {\"row_y\": \"Y\", \"col_x\":\"X\"})\n",
    "    # real size of XY \n",
    "    z_LIX_fNb_xr= z_LIX_fNb_xr.assign_coords(\n",
    "        X = z_LIX_fNb_xr.X.values *step_dx, \n",
    "        Y = z_LIX_fNb_xr.Y.values *step_dy )\n",
    "    # XY axis: 0 ~ size_XY\n",
    "\n",
    "    ############################\n",
    "    # check the XY ratio \n",
    "    ############################\n",
    "    #    if  size_x == size_y : \n",
    "    if  dim_px == dim_py : \n",
    "\n",
    "        pass\n",
    "    else : \n",
    "        print ('dim_px != dim_py')\n",
    "    # if xy size is not same, report it! \n",
    "\n",
    "    if step_dx != step_dy :\n",
    "        xystep_ratio = step_dy/step_dx # check the XY pixel_ratio\n",
    "        X_interp = np.linspace(z_LIX_fNb_xr.X[0], z_LIX_fNb_xr.X[-1], z_LIX_fNb_xr.X.shape[0]*1)\n",
    "        step_dx = step_dx # step_dx check \n",
    "\n",
    "        Y_interp = np.linspace(z_LIX_fNb_xr.Y[0], z_LIX_fNb_xr.Y[-1], int(z_LIX_fNb_xr.Y.shape[0]*xystep_ratio)) \n",
    "        step_dy = step_dy/ xystep_ratio # step_dy check \n",
    "\n",
    "        # interpolation ratio should be int\n",
    "        z_LIX_fNb_xr= z_LIX_fNb_xr.interp(X = X_interp, Y = Y_interp, method=\"linear\")\n",
    "        print('step_dx/step_dy = ', xystep_ratio)\n",
    "        print ('z_LIX_fNb_xr ==> reshaped')\n",
    "    else: \n",
    "        z_LIX_fNb_xr =z_LIX_fNb_xr\n",
    "        print('step_dx == step_dy')\n",
    "    #print('z_LIX_fNb_xr', 'step_dx, step_dy = ',  z_LIX_fNb_xr.dims)\n",
    "    print('z_LIX_fNb_xr', 'step_dx, step_dy = ', \n",
    "          re.findall('\\{([^}]+)', str(z_LIX_fNb_xr.dims)))\n",
    "    # regex practice\n",
    "\n",
    "\n",
    "    ##########\n",
    "    #################################\n",
    "    # assign attributes \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    # attribute 'multipass' set\n",
    "    z_LIX_fNb_xr.attrs['multipass'] = multipass\n",
    "    if multipass == True : \n",
    "        z_LIX_fNb_xr.attrs['multipass_Ch#'] =  int( len(data_vars_name)/4  )\n",
    "    if multipass == False : \n",
    "        z_LIX_fNb_xr.attrs['multipass_Ch#'] =  1\n",
    "    # data_vars_names  =  [Z_P1fwd, Z_P1bwd, LIX_P1fwd,LIX_P1bwd, Z_P2fwd, Z_P2bwd, LIX_P2fwd,LIX_P2bwd]\n",
    "    z_LIX_fNb_xr.attrs['title'] = image_title\n",
    "    if 'Wtip' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'W'\n",
    "    elif 'PtIr' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'PtIr'\n",
    "    elif '_Ni' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Ni'\n",
    "    elif 'Co_coated' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Co_coated'\n",
    "    elif 'AFM' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'AFM'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'To Be Announced'\n",
    "        print('tip material will be announced')\n",
    "    \n",
    "    if 'NbSe2' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'NbSe2'\n",
    "    elif 'Cu(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Cu(111)'\n",
    "    elif 'Au(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Au(111)'\n",
    "    elif 'MoS2' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'MoS2'\n",
    "    elif 'FeTe0.55Se0.45' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'FeTe0.55Se0.45'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'To Be Announced'\n",
    "        print('sample type will be announced')\n",
    "    \n",
    "    z_LIX_fNb_xr.attrs['image_size'] = [size_x,size_y]\n",
    "    z_LIX_fNb_xr.attrs['X_spacing'] = step_dx\n",
    "    z_LIX_fNb_xr.attrs['Y_spacing'] = step_dy    \n",
    "    #z_LIX_fNb_xr.attrs['freq_X_spacing'] = 1/step_dx\n",
    "    #z_LIX_fNb_xr.attrs['freq_Y_spacing'] = 1/step_dy\n",
    "    # use xrft with complex128= True, \n",
    "    # freq_X.spacing will provide new axis spacing info\n",
    "\n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        z_LIX_fNb_xr.assign_coords(X=(z_LIX_fNb_xr.X + cntr_x -  size_x/2))\n",
    "        z_LIX_fNb_xr.assign_coords(Y=(z_LIX_fNb_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "\n",
    "\n",
    "    #################################\n",
    "    # test & how to use xr data \n",
    "    # z_LIX_fNb_xr  # xr dataset (with data array channels )\n",
    "    #z_LIX_fNb_xr.z_fwd # select data channel\n",
    "    #z_LIX_fNb_xr.data_vars # data channels check \n",
    "    #z_LIX_fNb_xr.z_fwd.values  # to call data array in nd array \n",
    "    #z_yLIX_fNb_xr.dims # data channel dimension (coords) \n",
    "    #z_LIX_fNb_xr.coords # data  channel coordinates check \n",
    "    #z_LIX_fNb_xr.attrs # data  channel attributes check \n",
    "\n",
    "    return z_LIX_fNb_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91462937-8074-47eb-8ab6-5405d8870fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2xr_Vth (loading_sxm_file, center_offset = False):\n",
    "    \n",
    "    ###############\n",
    "    # multipass was not considered for img2xr_Vth\n",
    "    ###############\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    Convert Nanonis .sxm file data to an xarray dataset.\n",
    "\n",
    "    Parameters:\n",
    "    loading_sxm_file (str): The path to the Nanonis .sxm file to be loaded.\n",
    "    center_offset (bool): If True, \n",
    "        adjusts the scan data to center it within the scanner's field of view.\n",
    "\n",
    "    Returns:\n",
    "    xarray.Dataset: An xarray dataset containing the scan data.\n",
    "\n",
    "    Raises:\n",
    "    ModuleNotFoundError: \n",
    "        If required modules (nanonispy, xarray, seaborn-image) are not found, \n",
    "        it attempts to install them.\n",
    "\n",
    "    Example:\n",
    "    >>> data = img2xr('path/to/your/file.sxm', center_offset=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # updated for multipass \n",
    "    # import necessary module \n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import math\n",
    "    import matplotlib.pyplot as plt\n",
    "    import re\n",
    "\n",
    "    from warnings import warn\n",
    "\n",
    "    try:\n",
    "        import nanonispy as nap\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named nanonispy')\n",
    "        %pip install nanonispy\n",
    "        import nanonispy as nap\n",
    "\n",
    "    try:\n",
    "        import xarray as xr\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xarray')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        %pip install xarray \n",
    "        import xarray as xr\n",
    "\n",
    "    try:\n",
    "        import seaborn_image as isns\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        %pip install --upgrade seaborn-image    \n",
    "        import seaborn_image as isns\n",
    "\n",
    "\n",
    "    NF = nap.read.NanonisFile(loading_sxm_file)\n",
    "    Scan = nap.read.Scan(NF.fname)\n",
    "    #Scan.basename # file name only *.sxm \n",
    "    #Scan.header # heater dict \n",
    "    ##############################\n",
    "    # Scan conditions from the header\n",
    "    V_b = float(Scan.header['bias>bias (v)'])\n",
    "    I_t = float(Scan.header['z-controller>setpoint'])\n",
    "\n",
    "    [size_x,size_y] = Scan.header['scan_range']\n",
    "    [cntr_x, cntr_y] = Scan.header['scan_offset']\n",
    "    [dim_px,dim_py] = Scan.header['scan_pixels']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size = size / pixel\n",
    "    Rot_Rad = math.radians( float(Scan.header['scan_angle'])) \n",
    "    #str --> degree to radian \n",
    "\n",
    "    print ('scan direction (up/down): ', Scan.header['scan_dir'])\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])\n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])\n",
    "    # nX,nY for meshgrid (start from 1/2, not 0 )\n",
    "    # x, y steps with dimension \n",
    "    # In case of rotation ==0\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    \n",
    "    #########################################################################\n",
    "    # np.meshgrid \n",
    "    x_mesh_0, y_mesh_0 = np.meshgrid(nX, nY)\n",
    "    x_mesh = cntr_x - size_x + x_mesh_0\n",
    "    y_mesh = cntr_y - size_y + y_mesh_0 \n",
    "    # if there is rotation \n",
    "    x_mesh_r   =  np.cos(Rot_Rad)*x_mesh_0 + np.sin(Rot_Rad)*y_mesh_0  # \"cloclwise\"\n",
    "    y_mesh_r   = -np.sin(Rot_Rad)*x_mesh_0 + np.cos(Rot_Rad)*y_mesh_0\n",
    "    #########################################################################\n",
    "\n",
    "    \n",
    "    #########################################################################\n",
    "    # scan channels in DataFrame\n",
    "\n",
    "    if 'multipass-config' in Scan.header.keys():\n",
    "        print ('multipass detected')\n",
    "        multipass = True\n",
    "        # add xr attribute 'multipass' = True \n",
    "\n",
    "    else: \n",
    "        multipass = False\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "    # check image names --> multi pass? --> rotate? \n",
    "    if multipass == True :\n",
    "        # image title \n",
    "        # multi pass bias voltage in str\n",
    "        # 'Pass1 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][0])*1000,2)) +' mV' +\n",
    "        # '/ Pass1 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][1])*1000,2)) +' mV' +\n",
    "        # '// Pass2 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][2])*1000,2)) +' mV' + \n",
    "        # '/ Pass2 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][3])*1000,2)) +' mV'\n",
    "\n",
    "        # if there is rotation ( rot !=0 ), display it. \n",
    "        if Rot_Rad ==0 : \n",
    "            image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "            str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "            ' V = '+ str(V_b) + ' V ' +\\\n",
    "            ' I = ' + str(round(I_t *1E12)) + ' pA '  + '\\n' + \\\n",
    "            'Pass1 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][0])*1000,2)) +' mV' +\\\n",
    "            '/ Pass1 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][1])*1000,2)) +' mV' +\\\n",
    "            '// Pass2 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][2])*1000,2)) +' mV' + \\\n",
    "            '/ Pass2 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][3])*1000,2)) +' mV'\n",
    "            \n",
    "        else: \n",
    "            image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "            str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "            ' V = '+ str(V_b) + ' V ' +\\\n",
    "            ' I = ' + str(round(I_t *1E12)) + ' pA ' +\\\n",
    "            ' R = ' + str(int(math.degrees(Rot_Rad))) + 'deg' +\\\n",
    "            'Pass1 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][0])*1000,2)) +' mV' +\\\n",
    "            '/ Pass1 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][1])*1000,2)) +' mV' +\\\n",
    "            '// Pass2 fwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][2])*1000,2)) +' mV' + \\\n",
    "            '/ Pass2 bwd @' + str(round(float(Scan.header['multipass-config']['Bias_override_value'][3])*1000,2)) +' mV'\n",
    "            \n",
    "        print(image_title)\n",
    "\n",
    "        \n",
    "    else : \n",
    "        # normal without multi pass. only check rot \n",
    "\n",
    "        # if there is rotation ( rot !=0 ), display it. \n",
    "        if Rot_Rad ==0 : \n",
    "            image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "                str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                    str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                        ' V = '+ str(V_b) + ' V ' +\\\n",
    "                            ' I = ' + str(round(I_t *1E12)) + ' pA ' \n",
    "        else: \n",
    "            image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "                str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                    str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                        ' V = '+ str(V_b) + ' V ' +\\\n",
    "                            ' I = ' + str(round(I_t *1E12)) + ' pA ' +\\\n",
    "                                ' R = ' + str(int(math.degrees(Rot_Rad))) + 'deg'\n",
    "        print(image_title)\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################\n",
    "    if multipass == True :\n",
    "\n",
    "        P1_Z_keys =  [s  for s in Scan.signals.keys()  if \"P1\"  in s  if \"Z\" in s ]\n",
    "        P2_Z_keys =  [s  for s in Scan.signals.keys()  if \"P2\"  in s  if \"Z\" in s ]\n",
    "\n",
    "        P1_LIX_keys =  [s  for s in Scan.signals.keys()  if \"P1\"  in s  if \"LI\" in s if \"X\" in s ]\n",
    "        P2_LIX_keys =  [s  for s in Scan.signals.keys()  if \"P2\"  in s  if \"LI\" in s if \"X\" in s ]\n",
    "\n",
    "\n",
    "        # add xr attribute 'multipass' = True \n",
    "        Z_P1fwd = Scan.signals[P1_Z_keys[0]]['forward']\n",
    "        Z_P1bwd = Scan.signals[P1_Z_keys[0]]['backward'][:,::-1]\n",
    "        Z_P2fwd = Scan.signals[P2_Z_keys[0]]['forward']\n",
    "        Z_P2bwd = Scan.signals[P2_Z_keys[0]]['backward'][:,::-1]\n",
    "\n",
    "        LIX_P1fwd = Scan.signals[P1_LIX_keys[0]]['forward']\n",
    "        LIX_P1bwd = Scan.signals[P1_LIX_keys[0]]['backward'][:,::-1]\n",
    "        LIX_P2fwd = Scan.signals[P2_LIX_keys[0]]['forward']\n",
    "        LIX_P2bwd = Scan.signals[P2_LIX_keys[0]]['backward'][:,::-1]\n",
    "\n",
    "        data_vars_name = [Z_P1fwd, Z_P1bwd, LIX_P1fwd,LIX_P1bwd, Z_P2fwd, Z_P2bwd, LIX_P2fwd,LIX_P2bwd]\n",
    "    else:    \n",
    "\n",
    "\n",
    "        #Scan.signals.keys()\n",
    "        Scan.signals['Z'].keys()\n",
    "\n",
    "        Scan.signals['Z']['forward'].shape\n",
    "        z_fwd = Scan.signals['Z']['forward']\n",
    "        z_bwd = Scan.signals['Z']['backward'][:,::-1]\n",
    "\n",
    "        ###################\n",
    "        Vth_fwd = Scan.signals['Bias']['forward']\n",
    "        Vth_bwd = Scan.signals['Bias']['backward'][:,::-1]\n",
    "\n",
    "\n",
    "        ####################\n",
    "        #print(Scan.signals.keys())\n",
    "\n",
    "        #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "        # 'LI' & 'X' in  channel name (signal.keys) \n",
    "        LIX_key = [s  for s in Scan.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "        print(LIX_key)\n",
    "        # chech the LIX is empty or not \n",
    "        if len(LIX_key) == 0: \n",
    "            print(\"LIX is empty, Current ch substitutes LIX \")\n",
    "            LIX_fwd  = Scan.signals['Current']['forward']\n",
    "            LIX_bwd  = Scan.signals['Current']['backward'][:,::-1]\n",
    "        else:\n",
    "            # 0 is fwd, 1 is bwd \n",
    "            LIX_fwd  = Scan.signals[LIX_key[0]]['forward']\n",
    "            LIX_bwd  = Scan.signals[LIX_key[0]]['backward'][:,::-1]\n",
    "\n",
    "        #LIX_fwd = Scan.signals['LI_Demod_1_X']['forward']\n",
    "        #LIX_bwd = Scan.signals['LI_Demod_1_X']['backward'][:,::-1]\n",
    "        # LIX channel name varies w.r.t nanonis version \n",
    "\n",
    "        # same for LIY --> update later.. if needed \n",
    "        #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "        # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "        #LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "        # 0 is fwd, 1 is bwd \n",
    "        #LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "\n",
    "        #bwd channel : opposite data direction in X ==> reverse it. \n",
    "\n",
    "\n",
    "    ########################################\n",
    "    if Scan.header['scan_dir'] == 'down':\n",
    "        if multipass == True : \n",
    "            for data_var_name in data_vars_name : \n",
    "                data_var_name = data_var_name[::-1,:]\n",
    "\n",
    "        else: \n",
    "            z_fwd = z_fwd[::-1,:]\n",
    "            z_bwd = z_bwd[::-1,:]\n",
    "\n",
    "            Vth_fwd = Vth_fwd[::-1,:]\n",
    "            Vth_bwd = Vth_bwd[::-1,:]\n",
    "            \n",
    "            LIX_fwd = LIX_fwd[::-1,:]\n",
    "            LIX_bwd = LIX_bwd[::-1,:]\n",
    "    # if scan_direction == down, flip the data (Y)\n",
    "    ########################################\n",
    "    if multipass == True :\n",
    "        #Z_P1fwd, Z_P1bwd, LIX_P1fwd,LIX_Pbwd, Z_P2fwd, Z_P2bwd, LIX_P2fwd,LIX_P2bwd\n",
    "\n",
    "        Z_P1fwd_df  = pd.DataFrame(Z_P1fwd)\n",
    "        Z_P1fwd_df.index.name ='row_y'\n",
    "        Z_P1fwd_df.columns.name ='col_x'\n",
    "\n",
    "        Z_P1bwd_df  = pd.DataFrame(Z_P1bwd)\n",
    "        Z_P1bwd_df.index.name ='row_y'\n",
    "        Z_P1bwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_P1fwd_df  = pd.DataFrame(LIX_P1fwd)\n",
    "        LIX_P1fwd_df.index.name ='row_y'\n",
    "        LIX_P1fwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_P1bwd_df  = pd.DataFrame(LIX_P1bwd)\n",
    "        LIX_P1bwd_df.index.name ='row_y'\n",
    "        LIX_P1bwd_df.columns.name ='col_x'\n",
    "\n",
    "        Z_P2fwd_df  = pd.DataFrame(Z_P2fwd)\n",
    "        Z_P2fwd_df.index.name ='row_y'\n",
    "        Z_P2fwd_df.columns.name ='col_x'\n",
    "\n",
    "        Z_P2bwd_df  = pd.DataFrame(Z_P2bwd)\n",
    "        Z_P2bwd_df.index.name ='row_y'\n",
    "        Z_P2bwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_P2fwd_df  = pd.DataFrame(LIX_P2fwd)\n",
    "        LIX_P2fwd_df.index.name ='row_y'\n",
    "        LIX_P2fwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_P2bwd_df  = pd.DataFrame(LIX_P2bwd)\n",
    "        LIX_P2bwd_df.index.name ='row_y'\n",
    "        LIX_P2bwd_df.columns.name ='col_x'\n",
    "               # save data channels as DataFrame\n",
    "\n",
    "        ########################################\n",
    "        Z_P1fwd_df = Z_P1fwd_df.fillna(Z_P1fwd.mean())\n",
    "        Z_P1bwd_df = Z_P1bwd_df.fillna(Z_P1bwd.mean())\n",
    "        Z_P2fwd_df = Z_P2fwd_df.fillna(Z_P2fwd.mean())\n",
    "        Z_P2bwd_df = Z_P2bwd_df.fillna(Z_P2bwd.mean())\n",
    "        # fillna using previous numpy array. \n",
    "        LIX_P1fwd_df = LIX_P1fwd_df.fillna(LIX_P1fwd.mean())\n",
    "        LIX_P1bwd_df = LIX_P1bwd_df.fillna(LIX_P1bwd.mean())\n",
    "        LIX_P2fwd_df = LIX_P2fwd_df.fillna(LIX_P2fwd.mean())\n",
    "        LIX_P2bwd_df = LIX_P2bwd_df.fillna(LIX_P2bwd.mean())\n",
    "        # in case of incompleted scan ==> np.nan in data point, ==> fillna()\n",
    "        # how about fill df.mean ? \n",
    "    else : \n",
    "    ########################################\n",
    "\n",
    "        z_fwd_df = pd.DataFrame(z_fwd)\n",
    "        z_fwd_df.index.name ='row_y'\n",
    "        z_fwd_df.columns.name ='col_x'\n",
    "\n",
    "        z_bwd_df = pd.DataFrame(z_bwd)\n",
    "        z_bwd_df.index.name ='row_y'\n",
    "        z_bwd_df.columns.name ='col_x'\n",
    "\n",
    "\n",
    "        \n",
    "        Vth_fwd_df = pd.DataFrame(Vth_fwd)\n",
    "        Vth_fwd_df.index.name ='row_y'\n",
    "        Vth_fwd_df.columns.name ='col_x'\n",
    "\n",
    "        Vth_bwd_df = pd.DataFrame(Vth_bwd)\n",
    "        Vth_bwd_df.index.name ='row_y'\n",
    "        Vth_bwd_df.columns.name ='col_x'\n",
    "\n",
    "\n",
    "        \n",
    "        LIX_fwd_df = pd.DataFrame(LIX_fwd)\n",
    "        LIX_fwd_df.index.name ='row_y'\n",
    "        LIX_fwd_df.columns.name ='col_x'\n",
    "\n",
    "        LIX_bwd_df = pd.DataFrame(LIX_bwd)\n",
    "        LIX_bwd_df.index.name ='row_y'\n",
    "        LIX_bwd_df.columns.name ='col_x'\n",
    "            # save data channels as DataFrame\n",
    "        ########################################\n",
    "        z_fwd_df = z_fwd_df.fillna(0)\n",
    "        z_bwd_df = z_bwd_df.fillna(0)\n",
    "\n",
    "        Vth_fwd_df = Vth_fwd_df.fillna(0)\n",
    "        Vth_bwd_df = Vth_bwd_df.fillna(0)\n",
    "                                   \n",
    "        LIX_fwd_df = LIX_fwd_df.fillna(0)   \n",
    "        LIX_bwd_df = LIX_bwd_df.fillna(0)\n",
    "        # in case of incompleted scan ==> np.nan in data point, ==> fillna()\n",
    "        # how about fill df.mean ? \n",
    "            #  we can keep the max & min values \n",
    "            # or just leave as np.nan --> FFT calc. issue. \n",
    "            # 2D sxm summary --> fillna(0) , otherwise --> leave it as nan\n",
    "        ########################################\n",
    "\n",
    "\n",
    "    if multipass == True :\n",
    "        ############################\n",
    "        # conver to DataFrame (PANDAS) \n",
    "        z_LIX_fNb_df = pd.concat([Z_P1fwd_df.stack(),Z_P1bwd_df.stack(),\n",
    "                                  LIX_P1fwd_df.stack(),LIX_P1bwd_df.stack(),\n",
    "                                  Z_P2fwd_df.stack(),Z_P2bwd_df.stack(),\n",
    "                                  LIX_P2fwd_df.stack(),LIX_P2bwd_df.stack()],\n",
    "                                 axis = 1)\n",
    "        # set colunm name for new DataFrame\n",
    "        z_LIX_fNb_df.columns =['Z_P1fwd','Z_P1bwd', 'LIX_P1fwd','LIX_P1bwd','Z_P2fwd','Z_P2bwd', 'LIX_P2fwd','LIX_P2bwd']\n",
    "        # z_LIX_fNb_df      \n",
    "\n",
    "    else:\n",
    "        ############################\n",
    "        # conver to DataFrame (PANDAS) \n",
    "        z_LIX_fNb_df = pd.concat([z_fwd_df.stack(),\n",
    "                                  z_bwd_df.stack(),\n",
    "                                  Vth_fwd_df.stack(),\n",
    "                                  Vth_bwd_df.stack(),\n",
    "                                  LIX_fwd_df.stack(),\n",
    "                                  LIX_bwd_df.stack()], axis = 1)\n",
    "        # set colunm name for new DataFrame\n",
    "        z_LIX_fNb_df.columns =['z_fwd','z_bwd','Vth_fwd','Vth_bwd', 'LIX_fwd','LIX_bwd']\n",
    "        # z_LIX_fNb_df\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # conver to xarray \n",
    "    ############################\n",
    "    z_LIX_fNb_xr = z_LIX_fNb_df.to_xarray()\n",
    "    # rename coord as \"X\", \"Y\" \n",
    "    z_LIX_fNb_xr = z_LIX_fNb_xr.rename(\n",
    "        {\"row_y\": \"Y\", \"col_x\":\"X\"})\n",
    "    # real size of XY \n",
    "    z_LIX_fNb_xr= z_LIX_fNb_xr.assign_coords(\n",
    "        X = z_LIX_fNb_xr.X.values *step_dx, \n",
    "        Y = z_LIX_fNb_xr.Y.values *step_dy )\n",
    "    # XY axis: 0 ~ size_XY\n",
    "\n",
    "    ############################\n",
    "    # check the XY ratio \n",
    "    ############################\n",
    "    #    if  size_x == size_y : \n",
    "    if  dim_px == dim_py : \n",
    "\n",
    "        pass\n",
    "    else : \n",
    "        print ('dim_px != dim_py')\n",
    "    # if xy size is not same, report it! \n",
    "\n",
    "    if step_dx != step_dy :\n",
    "        xystep_ratio = step_dy/step_dx # check the XY pixel_ratio\n",
    "        X_interp = np.linspace(z_LIX_fNb_xr.X[0], z_LIX_fNb_xr.X[-1], z_LIX_fNb_xr.X.shape[0]*1)\n",
    "        step_dx = step_dx # step_dx check \n",
    "\n",
    "        Y_interp = np.linspace(z_LIX_fNb_xr.Y[0], z_LIX_fNb_xr.Y[-1], int(z_LIX_fNb_xr.Y.shape[0]*xystep_ratio)) \n",
    "        step_dy = step_dy/ xystep_ratio # step_dy check \n",
    "\n",
    "        # interpolation ratio should be int\n",
    "        z_LIX_fNb_xr= z_LIX_fNb_xr.interp(X = X_interp, Y = Y_interp, method=\"linear\")\n",
    "        print('step_dx/step_dy = ', xystep_ratio)\n",
    "        print ('z_LIX_fNb_xr ==> reshaped')\n",
    "    else: \n",
    "        z_LIX_fNb_xr =z_LIX_fNb_xr\n",
    "        print('step_dx == step_dy')\n",
    "    #print('z_LIX_fNb_xr', 'step_dx, step_dy = ',  z_LIX_fNb_xr.dims)\n",
    "    print('z_LIX_fNb_xr', 'step_dx, step_dy = ', \n",
    "          re.findall('\\{([^}]+)', str(z_LIX_fNb_xr.dims)))\n",
    "    # regex practice\n",
    "\n",
    "\n",
    "    ##########\n",
    "    #################################\n",
    "    # assign attributes \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    # attribute 'multipass' set\n",
    "    z_LIX_fNb_xr.attrs['multipass'] = multipass\n",
    "    if multipass == True : \n",
    "        z_LIX_fNb_xr.attrs['multipass_Ch#'] =  int( len(data_vars_name)/4  )\n",
    "    if multipass == False : \n",
    "        z_LIX_fNb_xr.attrs['multipass_Ch#'] =  1\n",
    "    # data_vars_names  =  [Z_P1fwd, Z_P1bwd, LIX_P1fwd,LIX_P1bwd, Z_P2fwd, Z_P2bwd, LIX_P2fwd,LIX_P2bwd]\n",
    "    z_LIX_fNb_xr.attrs['title'] = image_title\n",
    "    if 'Wtip' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'W'\n",
    "    elif 'PtIr' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'PtIr'\n",
    "    elif '_Ni' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Ni'\n",
    "    elif 'Co_coated' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Co_coated'\n",
    "    elif 'AFM' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'AFM'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'To Be Announced'\n",
    "        print('tip material will be announced')\n",
    "    \n",
    "    if 'NbSe2' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'NbSe2'\n",
    "    elif 'Cu(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Cu(111)'\n",
    "    elif 'Au(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Au(111)'\n",
    "    elif 'MoS2' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'MoS2'\n",
    "    elif 'FeTe0.55Se0.45' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'FeTe0.55Se0.45'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'To Be Announced'\n",
    "        print('sample type will be announced')\n",
    "    \n",
    "    z_LIX_fNb_xr.attrs['image_size'] = [size_x,size_y]\n",
    "    z_LIX_fNb_xr.attrs['X_spacing'] = step_dx\n",
    "    z_LIX_fNb_xr.attrs['Y_spacing'] = step_dy    \n",
    "    #z_LIX_fNb_xr.attrs['freq_X_spacing'] = 1/step_dx\n",
    "    #z_LIX_fNb_xr.attrs['freq_Y_spacing'] = 1/step_dy\n",
    "    # use xrft with complex128= True, \n",
    "    # freq_X.spacing will provide new axis spacing info\n",
    "\n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        z_LIX_fNb_xr.assign_coords(X=(z_LIX_fNb_xr.X + cntr_x -  size_x/2))\n",
    "        z_LIX_fNb_xr.assign_coords(Y=(z_LIX_fNb_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "\n",
    "\n",
    "    #################################\n",
    "    # test & how to use xr data \n",
    "    # z_LIX_fNb_xr  # xr dataset (with data array channels )\n",
    "    #z_LIX_fNb_xr.z_fwd # select data channel\n",
    "    #z_LIX_fNb_xr.data_vars # data channels check \n",
    "    #z_LIX_fNb_xr.z_fwd.values  # to call data array in nd array \n",
    "    #z_yLIX_fNb_xr.dims # data channel dimension (coords) \n",
    "    #z_LIX_fNb_xr.coords # data  channel coordinates check \n",
    "    #z_LIX_fNb_xr.attrs # data  channel attributes check \n",
    "\n",
    "    return z_LIX_fNb_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1958f1-925f-46e1-8e27-6f5ac9484654",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=blue>3. Grid to xarray </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240b41b0-284a-4d26-8515-43467d53de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# check all necessary package #\n",
    "# for img2xr                  #\n",
    "###############################\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.fft as npf\n",
    "#import xarray as xr\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "try:\n",
    "    import nanonispy as nap\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named nanonispy')\n",
    "    !pip install nanonispy\n",
    "    import nanonispy as nap\n",
    "\n",
    "try:\n",
    "    import xarray as xr\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named xarray')\n",
    "    #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "    !pip install xarray \n",
    "    import xarray as xr\n",
    "\n",
    "try:\n",
    "    import seaborn_image as isns\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "    #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "    !pip install --upgrade seaborn-image    \n",
    "    import seaborn_image as isns\n",
    "\n",
    "\n",
    "try:\n",
    "    import xrft\n",
    "except ModuleNotFoundError:\n",
    "    warn('ModuleNotFoundError: No module named xrft')\n",
    "    !pip install xrft \n",
    "    import xrft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e65bf5f-2052-4a92-9f5e-48a03d98eb9a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#griddata_file = file_list_df[file_list_df.type=='3ds'].iloc[0].file_name\n",
    "\n",
    "def grid2xr(griddata_file, center_offset = True): \n",
    "    \"\"\"\n",
    "    An xarray DataSet representing grid data from a Nanonis 3ds file.\n",
    "\n",
    "    This DataSet contains multiple variables corresponding to different data channels, such as \"I_fwd\" (Forward Current), \"I_bwd\" (Backward Current), \"LIX_fwd\" (Lock-In X Forward), \"LIX_bwd\" (Lock-In X Backward), and \"topography\" (Topography). The data is organized along three dimensions: \"Y\" (Y-coordinate), \"X\" (X-coordinate), and \"bias_mV\" (Bias Voltage in mV).\n",
    "\n",
    "    Attributes:\n",
    "        - title (str): A title or description of the grid data.\n",
    "        - image_size (list): A list containing the size of the image in X and Y dimensions.\n",
    "        - X_spacing (float): The spacing between X-coordinates in nanometers.\n",
    "        - Y_spacing (float): The spacing between Y-coordinates in nanometers.\n",
    "\n",
    "    Additional Information:\n",
    "    - The \"bias_mV\" dimension represents the bias voltage values in mV, and it includes values that are adjusted to have a \"zero\" bias point.\n",
    "    - Depending on the `center_offset` parameter used during conversion, the X and Y coordinates may be adjusted to represent positions in the real scanner field of view or with (0,0) as the origin of the image.\n",
    "\n",
    "    Example Usage:\n",
    "\n",
    "    Convert a Nanonis 3ds file to a grid_xr DataSet\n",
    "    grid_xr = grid2xr(\"example.3ds\")\n",
    "\n",
    "    Access data variables\n",
    "    topography_data = grid_xr[\"topography\"]\n",
    "    forward_current_data = grid_xr[\"I_fwd\"]\n",
    "\n",
    "    Access attributes\n",
    "    title = grid_xr.attrs[\"title\"]\n",
    "    image_size = grid_xr.attrs[\"image_size\"]\n",
    "    x_spacing = grid_xr.attrs[\"X_spacing\"]\n",
    "    y_spacing = grid_xr.attrs[\"Y_spacing\"]\n",
    "\n",
    "\n",
    "    Note: This DataSet is suitable for further analysis, visualization, and manipulation using the xarray library in Python.\n",
    "\n",
    "\n",
    "    ---\n",
    "    Summary \n",
    "    \n",
    "    Here's a breakdown of the main steps in the grid2xr function:\n",
    "    Read the Nanonis 3ds file using NanonisFile and extract relevant information such as grid dimensions, position, size, step sizes, channels (e.g., topography, current), and bias values.\n",
    "    Check the topography data and reshape it if necessary. This step is for handling cases where the topography data is not in the expected shape.\n",
    "    Process and interpolate bias values to ensure they include \"zero\" bias and have an odd number of points. This step is necessary to account for different bias settings in the data.\n",
    "    Interpolate the current and lock-in data (both forward and backward) to match the new bias values.\n",
    "    Create an xarray DataSet named grid_xr with the following variables: \"I_fwd,\" \"I_bwd,\" \"LIX_fwd,\" \"LIX_bwd,\" and \"topography.\" These variables are associated with dimensions \"Y,\" \"X,\" and \"bias_mV.\"\n",
    "    Assign various attributes to the grid_xr DataSet, including the title, image size, spacing, and frequency information.\n",
    "    Optionally, adjust the scan center position in real scanner field-of-view based on the center_offset parameter.\n",
    "    Check and handle cases where the XY dimensions are not equal and may require interpolation.\n",
    "    Return the grid_xr DataSet as the result of the function.\n",
    "    This function seems to be designed for specific data formats and processing tasks related to Nanonis data. You can call this function with a Nanonis 3ds file as input to convert it into an xarray DataSet with the described attributes and dimensions.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    import re\n",
    "    file = griddata_file\n",
    "    #####################\n",
    "    # conver the given 3ds file\n",
    "    # to  xarray DataSet (check the attributes)\n",
    "    NF = nap.read.NanonisFile(file)\n",
    "    Gr = nap.read.Grid(NF.fname)#\n",
    "    channel_name = Gr.signals.keys()  \n",
    "    #print (channel_name)\n",
    "    N = len(file);\n",
    "    f_name = file[0:N-4]\n",
    "    print (f_name) # Gr.basename\n",
    "\n",
    "    #####################################\n",
    "    #  Header part\n",
    "    #  Gr.header\n",
    "    #####################################\n",
    "    [dim_px,dim_py] = Gr.header['dim_px'] \n",
    "    [cntr_x, cntr_y] = Gr.header['pos_xy']\n",
    "    [size_x,size_y] = Gr.header['size_xy']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size =  size / pixel \n",
    "\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])\n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])\n",
    "\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    \n",
    "    #####################################\n",
    "    # signal part\n",
    "    # Gr.signals\n",
    "    #####################################\n",
    "    topography = Gr.signals['topo']\n",
    "    params_v = Gr.signals['params'] \n",
    "    # params_v.shape = (dim_px,dim_py,15) \n",
    "    # 15: 3ds infos. \n",
    "    bias = Gr.signals['sweep_signal']\n",
    "    # check the shape (# of 'original' bias points)\n",
    "    I_fwd = Gr.signals['Current (A)'] # 3d set (dim_px,dim_py,bias)\n",
    "    I_bwd = Gr.signals['Current [bwd] (A)'] # I bwd\n",
    "    # sometimes, LI channel names are inconsistent depends on program ver. \n",
    "    # find 'LI Demod 1 X (A)'  or  'LI X 1 omega (A)'\n",
    "\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIX_fwd, LIX_bwd = Gr.signals[LIX_keys[0]] ,Gr.signals[LIX_keys[1] ]\n",
    "\n",
    "    # same for LIY\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #plt.imshow(topography) # toppography check\n",
    "    #plt.imshow(I_fwd[:,:,0]) # LIX  check\n",
    "    ###########################################################\n",
    "\n",
    "    ##########################################################\n",
    "    #\t\t Title for Grid data \n",
    "    #       grid size, pixel, bias condition, and so on.\n",
    "    #############################################################\n",
    "    # Gr.header.get('Bias>Bias (V)') # bias condition \n",
    "    # Gr.header.get('Z-Controller>Setpoint') # current set  condition\n",
    "    # Gr.header.get('dim_px')  # jpixel dimension \n",
    "    title = Gr.basename +' ('  + str(\n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep Start (V)'))\n",
    "    ) +' V ~ ' +str( \n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep End (V)'))\n",
    "    )+ ' V) \\n at Bias = '+ Gr.header.get(\n",
    "        'Bias>Bias (V)'\n",
    "    )[0:-3]+' mV, I_t =  ' + Gr.header.get(\n",
    "        'Z-Controller>Setpoint'\n",
    "    )[0:-4]+ ' pA, '+str(\n",
    "        Gr.header.get('dim_px')[0]\n",
    "    )+' x '+str(\n",
    "        Gr.header.get('dim_px')[1]\n",
    "    )+' points'\n",
    "    #############################################################       \n",
    "\n",
    "    ### some times the topography does not look right. \n",
    "    # * then use the reshaping function \n",
    "    # only for asymmetry grid data set\n",
    "\n",
    "    # eg) JW's MoS2 on HOPG exp. data \n",
    "\n",
    "    ###########################################################\n",
    "    # assign topography as topography_reshape\n",
    "    ###########################################################\n",
    "    topo_dimension_true = True\n",
    "    # if topography looks normal.\n",
    "    ################################\n",
    "    if topo_dimension_true == True:\n",
    "        topography_reshape = topography   \n",
    "        #################################\n",
    "        I_fwd_copy = I_fwd\n",
    "        I_bwd_copy = I_bwd\n",
    "        LIX_fwd_copy = LIX_fwd \n",
    "        LIX_bwd_copy = LIX_bwd \t\n",
    "        \n",
    "    else:\n",
    "        # if a topography looks abnormal\n",
    "        # it is very rare case, \n",
    "        # but I leave manual setting to remind \"mistake!\"\n",
    "        \n",
    "        \n",
    "        ##########################################################\n",
    "        # if there is an error or mixed array for \n",
    "        ##########################################################\n",
    "        # adjust lattice manually \n",
    "        ##########################################################\n",
    "        # for example\n",
    "        # some times 40 x 80 array shape --> 40x40 + 40 x40\n",
    "        # because of mischoosen step & shape setting \n",
    "        # X one line = 0-39: 1st line + 40-79 \n",
    "        # in this case \n",
    "        # make a new arrary (vertically)\n",
    "        # 0-39 --> 2n & 40-79 -->  2n+1 \n",
    "        # topo # LIX f&b # I f&b #\n",
    "        ##########################################################\n",
    "\n",
    "        \n",
    "        topography_reshape = np.transpose(np.copy(topography),(1,0)) \n",
    "        # make a new lattcie with reshaped dimension \n",
    "        for x_indx, y_indx in enumerate (topography):\n",
    "        # print(x_indx) # 0-39 # print(y_indx.shape)\n",
    "            topography_reshape[2*x_indx,:] = y_indx[:40] # reshaping first half\n",
    "            topography_reshape[2*x_indx+1,:] = y_indx[40:80] # reshaping second half\n",
    "        #################################\n",
    "        # same deformation for I& LIX \n",
    "        #################################\n",
    "        # check the topographyt \n",
    "        plt.imshow(topography_reshape) # 80 * 40 OK\n",
    "        # topography_reshape is done. \n",
    "        \n",
    "        #################################\n",
    "        # make a new lattcie with reshaped dimension \n",
    "        I_fwd_copy = np.transpose(np.copy(I_fwd),(1,0,2))\n",
    "        I_bwd_copy = np.transpose(np.copy(I_bwd),(1,0,2)) \n",
    "        \n",
    "        for x_indx, yNbias_plane in enumerate (I_fwd): \n",
    "            # make a new lattcie with reshaped dimension \n",
    "            print(x_indx) # 0-39 \n",
    "            I_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            I_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "\n",
    "        for x_indx, yNbias_plane in enumerate (I_bwd): \n",
    "            # make a new lattcie with reshaped dimension \n",
    "            print(x_indx) # 0-39 \n",
    "            I_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            I_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        #################################\n",
    "        # I reshape is done \n",
    "        #################################\n",
    "        LIX_fwd_copy = np.transpose(np.copy(LIX_fwd),(1,0,2)) \n",
    "        LIX_bwd_copy = np.transpose(np.copy(LIX_bwd),(1,0,2)) \n",
    "        # make a new lattcie with reshaped dimension \n",
    "        for x_indx, yNbias_plane in enumerate (LIX_fwd): \n",
    "            LIX_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            LIX_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        for x_indx, yNbias_plane in enumerate (LIX_bwd): \n",
    "            LIX_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            LIX_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        #################################\n",
    "        # LIX reshape is done \n",
    "        #################################\n",
    "\n",
    "    # after reshaping \n",
    "\n",
    "    topography = topography_reshape \n",
    "    #################################\n",
    "    I_fwd = I_fwd_copy \n",
    "    I_bwd = I_bwd_copy \n",
    "    LIX_fwd  = LIX_fwd_copy \n",
    "    LIX_bwd  = LIX_bwd_copy\n",
    "    ##########################################################\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # Bias segment check      #\n",
    "    ###########################\n",
    "    Segment = Gr.header['Bias>Bias (V)']\n",
    "    # bias unit : '(V)' \n",
    "\n",
    "    if type(Segment) == str: # single segment case\n",
    "        print ('No Segments\\n'+ 'Grid data acquired at bias = '+  str(float(Segment)) + 'V')    \n",
    "    ## No Segments # +  bias setting \n",
    "\n",
    "    ########################\n",
    "    # bias interpolation to have a \"zero\" bias \n",
    "    # interpolate bias_mV that include \"zero\" bias \n",
    "    # in 3D data : center x,y bias interpolation \n",
    "    # e.g  256--> including end points + zero  = 256+1 ( the center is \"0\")\n",
    "        if len(bias)%2==0:\n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias)+1)) \n",
    "            # if bias length is even_number \n",
    "            # including \"0\", total size is \"len+1\" \n",
    "        else:# if bias length is odd_number \n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias))) \n",
    "            # bias_new make a odd number of length\n",
    "            # make only one value is closest to the zero. \n",
    "            \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # find the index of closest to \"0\" bias \n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # assign closest zero vavlue as a zero. \n",
    "        #bias_new[np.where(bias_new == np.amin(abs(bias_new)))]=0\n",
    "\n",
    "    ##############################################\n",
    "    #'Segment Start (V), Segment End (V), Settling (s), Integration (s), Steps (xn)'\n",
    "    elif len(Segment) == 3:\n",
    "        print('Number of Segments =' + str(len(Segment))) \n",
    "        Segments = np.array([[ float(Segments) \n",
    "                              for Segments in Seg.split(',') ] \n",
    "                             for Seg in Segment], dtype = np.float64)\n",
    "        # in the Segment, split strings sith \",\" \n",
    "        #  make a array after change it as float. \n",
    "        # check Nanonispy version\n",
    "        # bias value could be not correct. \n",
    "        \n",
    "        Seg1 = np.linspace(Segments[0,0],Segments[0,1],int(Segments[0,-1]))\n",
    "        Seg2 = np.linspace(Segments[1,0],Segments[1,1],int(Segments[1,-1]))\n",
    "        Seg3 = np.linspace(Segments[2,0],Segments[2,1],int(Segments[2,-1]))\n",
    "        # except boundary end points,  combine segments ([1:]), Seg1, Seg2[1:], Seg3[1:] \n",
    "        bias_Seg = np.append(np.append(Seg1,Seg2[1:]),Seg3[1:]) \n",
    "        # Seg1 +  Seg2[1:] +  Se3[1:] \n",
    "        # make a clever & shoter way 'later...'\n",
    "        print ('bias_Seg size = ' + str(len(bias_Seg)))\n",
    "        bias_Nsteps=int(int(Segments[1,-1])/\n",
    "                        (Seg2[-1]-Seg2[0])*(bias_Seg[-1]-bias_Seg[0]))\n",
    "        # New bias Steps uses smallest step as a new stpe size. \n",
    "        bias_Nsteps_size = (Seg2[-1]-Seg2[0])/(Segments[1,-1])\n",
    "        # (Segments[1,0]-Segments[1,1])/int(Segments[1,-1]) # bias step size    \n",
    "        Neg_bias=-1*np.arange(\n",
    "            0,bias_Nsteps_size*bias_Nsteps/2, bias_Nsteps_size)\n",
    "        Pos_bias=np.flip(\n",
    "            np.arange(0,bias_Nsteps_size*bias_Nsteps/2,bias_Nsteps_size))\n",
    "        bias_new = np.flip( np.append(Pos_bias,Neg_bias[1:])) \n",
    "        # after segments, \n",
    "        # bias is called as  bias_new\n",
    "        ##################################\n",
    "        # now make the bias_new as an odd number. \n",
    "        ###################################\n",
    "        if len(bias_new)%2==0:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new)+1)) \n",
    "        else:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new))) \n",
    "        # check  bias_new contians \"zero\" \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # check index of the nearest value to zero \"0\"\n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # adjust bias range for bias_new has \"zero\" \n",
    "        print ('bias_new size = ' + str(len(bias_new)))\n",
    "        # bias \n",
    "    # make a new list for Bias\n",
    "    else:\n",
    "        print (\"Segment error /n code a 5 Sements case\")\n",
    "    #\n",
    "    ######################################################################\n",
    "    # make a new bias length (including Segments) as a odd number, including zero\n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # interpolation using bias_new \n",
    "    # I_fwd, I_bwd, LIX_fwd, LIX_bwd\n",
    "    # => I_fwd_interpolate\n",
    "    #######################################################################\n",
    "    # assign a function using interpolation \n",
    "    # the same as original bias values \n",
    "    # make empty np array  & interpolate using scipy\n",
    "    # xy dim is not changed here, \n",
    "    # only 3rd axis changed as new bias \n",
    "    ###########################\n",
    "    def sweep_interpolation(np3Ddata, bias, bias_new):\n",
    "        np3Ddata_interpolate = np.empty(\n",
    "                    (np3Ddata.shape[0],np3Ddata.shape[1],bias_new.shape[0])) \n",
    "\n",
    "        for x_i,np3Ddata_xi in enumerate(np3Ddata):\n",
    "            for y_j,np3Ddata_xi_yj in enumerate(np3Ddata_xi):\n",
    "                #print (np3Ddata_xi_yj.shape)\n",
    "                Interpolation1D_i_f = sp.interpolate.interp1d(\n",
    "                    bias,\n",
    "                    np3Ddata_xi_yj,\n",
    "                    fill_value = \"extrapolate\",\n",
    "                    kind = 'cubic')\n",
    "                np3Ddata_interpolate[x_i,y_j,:] = Interpolation1D_i_f(bias_new)\n",
    "        return np3Ddata_interpolate\n",
    "\n",
    "    I_fwd_interpolate = sweep_interpolation (I_fwd, bias, bias_new)\n",
    "    I_bwd_interpolate = sweep_interpolation (I_bwd, bias, bias_new)\n",
    "    LIX_fwd_interpolate = sweep_interpolation (LIX_fwd, bias, bias_new)\n",
    "    LIX_bwd_interpolate = sweep_interpolation (LIX_bwd, bias, bias_new)\n",
    "\n",
    "    ####################################################\n",
    "    # to prevent error for bias direction \n",
    "    # \n",
    "    ##\n",
    "    #  assign the bias direction \n",
    "    ## up or down ==> up anyway. \n",
    "    ###################################################\n",
    "    if bias[0]>bias[-1]: \n",
    "        # if starting point is larger than end point. \n",
    "        # start from pos & end to neg\n",
    "        # no changes. \n",
    "        print ('start from POS bias')\n",
    "        I_fwd = I_fwd_interpolate\n",
    "        I_bwd = I_bwd_interpolate\n",
    "        LIX_fwd = LIX_fwd_interpolate\n",
    "        LIX_bwd = LIX_bwd_interpolate\n",
    "        bias_mV = bias_new*1000\n",
    "    else:  # if end point is larger than start point. \n",
    "        # start from neg & end to pos\n",
    "        # change to negative \n",
    "        print ('start from NEG bias')\n",
    "        I_fwd = np.flip(I_fwd_interpolate,2)\n",
    "        I_bwd = np.flip(I_bwd_interpolate,2)\n",
    "        LIX_fwd = np.flip(LIX_fwd_interpolate,2)\n",
    "        LIX_bwd = np.flip(LIX_bwd_interpolate,2)\n",
    "        bias_new_flip = np.flip(bias_new)\n",
    "        bias_mV = bias_new_flip*1000\n",
    "        print ('Flip => start from POS bias')\n",
    "    ####################################################\n",
    "\n",
    "    ###################################################\n",
    "    # convert data XR DataSet\n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "    # col = x \n",
    "    # row = y\n",
    "    # I_fwd grid data ==> [Y, X, bias]\n",
    "    grid_xr = xr.Dataset(\n",
    "        {\n",
    "            \"I_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_fwd),\n",
    "            \"I_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_bwd),\n",
    "            \"LIX_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_fwd),\n",
    "            \"LIX_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_bwd),\n",
    "            \"topography\" : ([\"Y\",\"X\"], topography)\n",
    "        },\n",
    "        coords = {\n",
    "            \"X\": ([\"X\"], x),\n",
    "            \"Y\": ([\"Y\"], y),\n",
    "            \"bias_mV\": ([\"bias_mV\"], bias_mV)\n",
    "        }\n",
    "    )\n",
    "    grid_xr.attrs[\"title\"] = title\n",
    "    #grid_xr.attrs['image_size'] = \n",
    "    #grid_xr.attrs['samlpe'] = \n",
    "    \n",
    "    grid_xr.attrs['image_size']= [size_x,size_y]\n",
    "    grid_xr.attrs['X_spacing']= step_dx\n",
    "    grid_xr.attrs['Y_spacing']= step_dy    \n",
    "    #grid_xr.attrs['freq_X_spacing']= 1/step_dx\n",
    "    #grid_xr.attrs['freq_Y_spacing']= 1/step_dy\n",
    "    # use the complex128 = True for xrft, \n",
    "    # then xrdata_fft.freq_X.spacing \n",
    "    # use the attrs in axis info \n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        grid_xr.assign_coords( X = (grid_xr.X + cntr_x -  size_x/2))\n",
    "        grid_xr.assign_coords( Y = (grid_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "    \n",
    "\n",
    "    ############################\n",
    "    # check the XY ratio \n",
    "    ############################\n",
    "    #    if  size_x == size_y : \n",
    "    if  dim_px == dim_py : \n",
    "\n",
    "        pass\n",
    "    else : \n",
    "        print ('dim_px != dim_py')\n",
    "    # if xy size is not same, report it! \n",
    "\n",
    "    if step_dx != step_dy :\n",
    "        xystep_ratio = step_dy/step_dx # check the XY pixel_ratio\n",
    "        X_interp = np.linspace(grid_xr.X[0], grid_xr.X[-1], grid_xr.X.shape[0]*1)\n",
    "        step_dx = step_dx # step_dx check \n",
    "\n",
    "        Y_interp = np.linspace(grid_xr.Y[0], grid_xr.Y[-1], int(grid_xr.Y.shape[0]*xystep_ratio)) \n",
    "        step_dy = step_dy/ xystep_ratio # step_dy check \n",
    "\n",
    "        # interpolation ratio should be int\n",
    "        grid_xr= grid_xr.interp(X = X_interp, Y = Y_interp, method=\"linear\")\n",
    "        print('step_dx/step_dy = ', xystep_ratio)\n",
    "        print ('grid_xr ==> reshaped')\n",
    "    else: \n",
    "        grid_xr =grid_xr\n",
    "        print('step_dx == step_dy')\n",
    "    #print('z_LIX_fNb_xr', 'step_dx, step_dy = ',  z_LIX_fNb_xr.dims)\n",
    "    print('grid_xr', 'step_dx, step_dy = ', \n",
    "          re.findall('\\{([^}]+)', str(grid_xr.dims)))\n",
    "    # regex practice\n",
    "    \n",
    "    \n",
    "    return grid_xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efdd06-6abb-43f0-a018-92fc9ccd05b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=blue>4. Grid Line to xarray </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "929b03c9-7050-4f9b-931f-df3530e6acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_line2xr(griddata_file, center_offset = True): \n",
    "    \"\"\"\n",
    "    Convert 3D scan data from Nanonis file to an xarray DataSet.\n",
    "\n",
    "    Parameters:\n",
    "        griddata_file (str): The path to the Nanonis file containing the 3D scan data.\n",
    "        center_offset (bool, optional): Whether to adjust the scan's center position in real scanner field of view.\n",
    "            If True, the scan's center position is moved to the real scanner field of view. If False, the origin (0,0)\n",
    "            is set as the image's origin. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        xarray.Dataset: An xarray DataSet containing the scan data with dimensions for X, Y, and bias values.\n",
    "            The dataset includes the following variables:\n",
    "            - 'I_fwd': Forward current data (3D array with dimensions [Y, X, bias_mV])\n",
    "            - 'I_bwd': Backward current data (3D array with dimensions [Y, X, bias_mV])\n",
    "            - 'LIX_fwd': Forward lock-in-X data (3D array with dimensions [Y, X, bias_mV])\n",
    "            - 'LIX_bwd': Backward lock-in-X data (3D array with dimensions [Y, X, bias_mV])\n",
    "            - 'topography': Topography data (2D array with dimensions [Y, X])\n",
    "\n",
    "        The dataset also includes metadata attributes:\n",
    "        - 'title': A descriptive title for the scan data.\n",
    "        - 'image_size': The size of the scan image in nanometers [X_size, Y_size].\n",
    "        - 'X_spacing': The spacing between X values in nanometers.\n",
    "        - 'Y_spacing': The spacing between Y values in nanometers.\n",
    "        - 'freq_X_spacing': The reciprocal of X spacing (frequency domain spacing).\n",
    "        - 'freq_Y_spacing': The reciprocal of Y spacing in the frequency domain.\n",
    "\n",
    "    Example:\n",
    "        grid_data = grid_line2xr(\"path/to/grid_data.dat\", center_offset=True)\n",
    "    \"\"\"\n",
    "    file = griddata_file\n",
    "    #####################\n",
    "    # conver the given 3ds file\n",
    "    # to  xarray DataSet (check the attributes)\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import numpy.fft as npf\n",
    "    #import xarray as xr\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import matplotlib.pyplot as plt\n",
    "    import nanonispy as nap\n",
    "    import xarray as xr\n",
    "    import seaborn_image as isns\n",
    "    import xrft\n",
    "    \n",
    "\n",
    "    NF = nap.read.NanonisFile(file)\n",
    "    Gr = nap.read.Grid(NF.fname)#\n",
    "    channel_name = Gr.signals.keys()  \n",
    "    #print (channel_name)\n",
    "    N = len(file);\n",
    "    f_name = file[0:N-4]\n",
    "    print (f_name) # Gr.basename\n",
    "\n",
    "    #####################################\n",
    "    #Header part\n",
    "    #####################################\n",
    "    #  Gr.header\n",
    "    #####################################\n",
    "    [dim_px,dim_py] = Gr.header['dim_px'] \n",
    "    [cntr_x, cntr_y] = Gr.header['pos_xy']\n",
    "    [size_x,size_y] = Gr.header['size_xy']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    \n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])# dimesion맞춘 xstep \n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])# dimesion맞춘 ystep \n",
    "\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    \n",
    "    #####################################\n",
    "    # signal part\n",
    "    # Gr.signals\n",
    "    #####################################\n",
    "    topography = Gr.signals['topo']\n",
    "    params_v = Gr.signals['params'] \n",
    "    # params_v.shape = (dim_px,dim_py,15) \n",
    "    # 15: 3ds infos. \n",
    "    bias = Gr.signals['sweep_signal']\n",
    "    # check the shape (# of 'original' bias points)\n",
    "    I_fwd = Gr.signals['Current (A)'] # 3d set (dim_px,dim_py,bias)\n",
    "    I_bwd = Gr.signals['Current [bwd] (A)'] # I bwd\n",
    "    # sometimes, LI channel names are inconsistent depends on program ver. \n",
    "    # find 'LI Demod 1 X (A)'  or  'LI X 1 omega (A)'\n",
    "\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIX_fwd, LIX_bwd = Gr.signals[LIX_keys[0]] ,Gr.signals[LIX_keys[1] ]\n",
    "\n",
    "    # same for LIY\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #plt.imshow(topography) # toppography check\n",
    "    #plt.imshow(I_fwd[:,:,0]) # LIX  check\n",
    "    ###########################################################\n",
    "\n",
    "    ##########################################################\n",
    "    # Title for Grid data \n",
    "    #############################################################\n",
    "    # Gr.header.get('Bias>Bias (V)') # bias condition \n",
    "    # Gr.header.get('Z-Controller>Setpoint') # current set  condition\n",
    "    # Gr.header.get('dim_px')  # jpixel dimension \n",
    "    title = Gr.basename +' ('  + str(\n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep Start (V)'))\n",
    "    ) +' V ~ ' +str( \n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep End (V)'))\n",
    "    )+ ' V) \\n at Bias = '+ Gr.header.get(\n",
    "        'Bias>Bias (V)'\n",
    "    )[0:-3]+' mV, I_t =  ' + Gr.header.get(\n",
    "        'Z-Controller>Setpoint'\n",
    "    )[0:-4]+ ' pA, '+str(\n",
    "        Gr.header.get('dim_px')[0]\n",
    "    )+' x '+str(\n",
    "        Gr.header.get('dim_px')[1]\n",
    "    )+' points' + '1D line spectroscopy'\n",
    "    #############################################################       \n",
    "\n",
    "    ### some times the topography does not look right. \n",
    "    # * then use the reshaping function \n",
    "    # only for asymmetry grid data set\n",
    "\n",
    "    # eg) JW's MoS2 on HOPG exp. data \n",
    "\n",
    "    ###########################################################\n",
    "    # assign topography as topography_reshape\n",
    "    ###########################################################\n",
    "    topo_dimension_true = True\n",
    "    # if topography looks normal.\n",
    "    ################################\n",
    "    if topo_dimension_true == True:\n",
    "        topography_reshape = topography   \n",
    "        #################################\n",
    "        I_fwd_copy = I_fwd\n",
    "        I_bwd_copy = I_bwd\n",
    "        LIX_fwd_copy = LIX_fwd \n",
    "        LIX_bwd_copy = LIX_bwd \t\n",
    "        \n",
    "    else:\n",
    "        # if a topography looks abnormal\n",
    "        # it is very rare case, \n",
    "        # but I leave manual setting to remind \"mistake!\"\n",
    "        \n",
    "        \n",
    "        ##########################################################\n",
    "        # if there is an error or mixed array for \n",
    "        ##########################################################\n",
    "        # adjust lattice manually \n",
    "        ##########################################################\n",
    "        # for example\n",
    "        # some times 40 x 80 array shape --> 40x40 + 40 x40\n",
    "        # because of mischoosen step & shape setting \n",
    "        # X one line = 0-39: 1st line + 40-79 \n",
    "        # in this case \n",
    "        # make a new arrary (vertically)\n",
    "        # 0-39 --> 2n & 40-79 -->  2n+1 \n",
    "        # topo # LIX f&b # I f&b #\n",
    "        ##########################################################\n",
    "\n",
    "        \n",
    "        topography_reshape = np.transpose(np.copy(topography),(1,0)) \n",
    "        # make a new lattcie with reshaped dimension \n",
    "        for x_indx, y_indx in enumerate (topography):\n",
    "        # print(x_indx) # 0-39 # print(y_indx.shape)\n",
    "            topography_reshape[2*x_indx,:] = y_indx[:40] # reshaping first half\n",
    "            topography_reshape[2*x_indx+1,:] = y_indx[40:80] # reshaping second half\n",
    "        #################################\n",
    "        # same deformation for I& LIX \n",
    "        #################################\n",
    "        # check the topographyt \n",
    "        plt.imshow(topography_reshape) # 80 * 40 OK\n",
    "        # topography_reshape is done. \n",
    "        \n",
    "        #################################\n",
    "        # make a new lattcie with reshaped dimension \n",
    "        I_fwd_copy = np.transpose(np.copy(I_fwd),(1,0,2))\n",
    "        I_bwd_copy = np.transpose(np.copy(I_bwd),(1,0,2)) \n",
    "        \n",
    "        for x_indx, yNbias_plane in enumerate (I_fwd): \n",
    "            # make a new lattcie with reshaped dimension \n",
    "            print(x_indx) # 0-39 \n",
    "            I_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            I_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "\n",
    "        for x_indx, yNbias_plane in enumerate (I_bwd): \n",
    "            # make a new lattcie with reshaped dimension \n",
    "            print(x_indx) # 0-39 \n",
    "            I_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            I_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        #################################\n",
    "        # I reshape is done \n",
    "        #################################\n",
    "        LIX_fwd_copy = np.transpose(np.copy(LIX_fwd),(1,0,2)) \n",
    "        LIX_bwd_copy = np.transpose(np.copy(LIX_bwd),(1,0,2)) \n",
    "        # make a new lattcie with reshaped dimension \n",
    "        for x_indx, yNbias_plane in enumerate (LIX_fwd): \n",
    "            LIX_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            LIX_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        for x_indx, yNbias_plane in enumerate (LIX_bwd): \n",
    "            LIX_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # reshaping first half\n",
    "            LIX_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # reshaping second half\n",
    "        #################################\n",
    "        # LIX reshape is done \n",
    "        #################################\n",
    "\n",
    "    # after reshaping \n",
    "\n",
    "    topography = topography_reshape \n",
    "    #################################\n",
    "    I_fwd = I_fwd_copy \n",
    "    I_bwd = I_bwd_copy \n",
    "    LIX_fwd  = LIX_fwd_copy \n",
    "    LIX_bwd  = LIX_bwd_copy\n",
    "    ##########################################################\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # Bias segment check      #\n",
    "    ###########################\n",
    "    Segment = Gr.header['Bias>Bias (V)']\n",
    "    # bias unit : '(V)' \n",
    "\n",
    "    if type(Segment) == str: # single segment case\n",
    "        print ('No Segments\\n'+ 'Grid data acquired at bias = '+  str(float(Segment)) + 'V')    \n",
    "    ## No Segments # +  bias setting \n",
    "\n",
    "    ########################\n",
    "    # bias interpolation to have a \"zero\" bias \n",
    "    # interpolate bias_mV that include \"zero\" bias \n",
    "    # in 3D data : center x,y bias interpolation \n",
    "    # e.g  256--> including end points + zero  = 256+1 ( the center is \"0\")\n",
    "        if len(bias)%2==0:\n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias)+1)) \n",
    "            # if bias length is even_number \n",
    "            # including \"0\", total size is \"len+1\" \n",
    "        else:# if bias length is odd_number \n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias))) \n",
    "            # bias_new make a odd number of length\n",
    "            # make only one value is closest to the zero. \n",
    "            \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # find the index of closest to \"0\" bias \n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # assign closest zero vavlue as a zero. \n",
    "        #bias_new[np.where(bias_new == np.amin(abs(bias_new)))]=0\n",
    "\n",
    "    ##############################################\n",
    "    #'Segment Start (V), Segment End (V), Settling (s), Integration (s), Steps (xn)'\n",
    "    elif len(Segment) == 3:\n",
    "        print('Number of Segments =' + str(len(Segment))) \n",
    "        Segments = np.array([[ float(Segments) \n",
    "                              for Segments in Seg.split(',') ] \n",
    "                             for Seg in Segment], dtype = np.float64)\n",
    "        # in the Segment, split strings sith \",\" \n",
    "        #  make a array after change it as float. \n",
    "        # check Nanonispy version\n",
    "        # bias value could be not correct. \n",
    "        \n",
    "        Seg1 = np.linspace(Segments[0,0],Segments[0,1],int(Segments[0,-1]))\n",
    "        Seg2 = np.linspace(Segments[1,0],Segments[1,1],int(Segments[1,-1]))\n",
    "        Seg3 = np.linspace(Segments[2,0],Segments[2,1],int(Segments[2,-1]))\n",
    "        # except boundary end points,  combine segments ([1:]), Seg1, Seg2[1:], Seg3[1:] \n",
    "        bias_Seg = np.append(np.append(Seg1,Seg2[1:]),Seg3[1:]) \n",
    "        # Seg1 +  Seg2[1:] +  Se3[1:] \n",
    "        # make a clever & shoter way 'later...'\n",
    "        print ('bias_Seg size = ' + str(len(bias_Seg)))\n",
    "        bias_Nsteps=int(int(Segments[1,-1])/\n",
    "                        (Seg2[-1]-Seg2[0])*(bias_Seg[-1]-bias_Seg[0]))\n",
    "        # New bias Steps uses smallest step as a new stpe size. \n",
    "        bias_Nsteps_size = (Seg2[-1]-Seg2[0])/(Segments[1,-1])\n",
    "        # (Segments[1,0]-Segments[1,1])/int(Segments[1,-1]) # bias step size    \n",
    "        Neg_bias=-1*np.arange(\n",
    "            0,bias_Nsteps_size*bias_Nsteps/2, bias_Nsteps_size)\n",
    "        Pos_bias=np.flip(\n",
    "            np.arange(0,bias_Nsteps_size*bias_Nsteps/2,bias_Nsteps_size))\n",
    "        bias_new = np.flip( np.append(Pos_bias,Neg_bias[1:])) \n",
    "        # after segments, \n",
    "        # bias is called as  bias_new\n",
    "        ##################################\n",
    "        # now make the bias_new as an odd number. \n",
    "        ###################################\n",
    "        if len(bias_new)%2==0:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new)+1)) \n",
    "        else:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new))) \n",
    "        # check  bias_new contians \"zero\" \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # check index of the nearest value to zero \"0\"\n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # adjust bias range for bias_new has \"zero\" \n",
    "        print ('bias_new size = ' + str(len(bias_new)))\n",
    "        # bias \n",
    "    # make a new list for Bias\n",
    "    else:\n",
    "        print (\"Segment error /n code a 5 Sements case\")\n",
    "    #\n",
    "    ######################################################################\n",
    "    # make a new bias length (including Segments) as a odd number, including zero\n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # interpolation using bias_new \n",
    "    # I_fwd, I_bwd, LIX_fwd, LIX_bwd\n",
    "    # => I_fwd_interpolate\n",
    "    #######################################################################\n",
    "    # assign a function using interpolation \n",
    "    # the same as original bias values \n",
    "    # make empty np array  & interpolate using scipy\n",
    "    # xy dim is not changed here, \n",
    "    # only 3rd axis changed as new bias \n",
    "    ###########################\n",
    "    def sweep_interpolation(np3Ddata, bias, bias_new):\n",
    "        np3Ddata_interpolate = np.empty(\n",
    "                    (np3Ddata.shape[0],np3Ddata.shape[1],bias_new.shape[0])) \n",
    "\n",
    "        for x_i,np3Ddata_xi in enumerate(np3Ddata):\n",
    "            for y_j,np3Ddata_xi_yj in enumerate(np3Ddata_xi):\n",
    "                #print (np3Ddata_xi_yj.shape)\n",
    "                Interpolation1D_i_f = sp.interpolate.interp1d(\n",
    "                    bias,\n",
    "                    np3Ddata_xi_yj,\n",
    "                    fill_value = \"extrapolate\",\n",
    "                    kind = 'cubic')\n",
    "                np3Ddata_interpolate[x_i,y_j,:] = Interpolation1D_i_f(bias_new)\n",
    "        return np3Ddata_interpolate\n",
    "\n",
    "    I_fwd_interpolate = sweep_interpolation (I_fwd, bias, bias_new)\n",
    "    I_bwd_interpolate = sweep_interpolation (I_bwd, bias, bias_new)\n",
    "    LIX_fwd_interpolate = sweep_interpolation (LIX_fwd, bias, bias_new)\n",
    "    LIX_bwd_interpolate = sweep_interpolation (LIX_bwd, bias, bias_new)\n",
    "\n",
    "    ####################################################\n",
    "    # to prevent error for bias direction \n",
    "    # \n",
    "    ##\n",
    "    #  assign the bias direction \n",
    "    ## up or down ==> up anyway. \n",
    "    ###################################################\n",
    "    if bias[0]>bias[-1]: \n",
    "        # if starting point is larger than end point. \n",
    "        # start from pos & end to neg\n",
    "        # no changes. \n",
    "        print ('start from POS bias')\n",
    "        I_fwd = I_fwd_interpolate\n",
    "        I_bwd = I_bwd_interpolate\n",
    "        LIX_fwd = LIX_fwd_interpolate\n",
    "        LIX_bwd = LIX_bwd_interpolate\n",
    "        bias_mV = bias_new*1000\n",
    "    else:  # if end point is larger than start point. \n",
    "        # start from neg & end to pos\n",
    "        # change to negative \n",
    "        print ('start from NEG bias')\n",
    "        I_fwd = np.flip(I_fwd_interpolate,2)\n",
    "        I_bwd = np.flip(I_bwd_interpolate,2)\n",
    "        LIX_fwd = np.flip(LIX_fwd_interpolate,2)\n",
    "        LIX_bwd = np.flip(LIX_bwd_interpolate,2)\n",
    "        bias_new_flip = np.flip(bias_new)\n",
    "        bias_mV = bias_new_flip*1000\n",
    "        print ('Flip => start from POS bias')\n",
    "    ####################################################\n",
    "\n",
    "    ###################################################\n",
    "    # convert data XR DataSet\n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "    # col = x \n",
    "    # row = y\n",
    "    # I_fwd grid data ==> [Y, X, bias]\n",
    "    grid_xr = xr.Dataset(\n",
    "        {\n",
    "            \"I_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_fwd),\n",
    "            \"I_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_bwd),\n",
    "            \"LIX_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_fwd),\n",
    "            \"LIX_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_bwd),\n",
    "            \"topography\" : ([\"Y\",\"X\"], topography)\n",
    "        },\n",
    "        coords = {\n",
    "            \"X\": ([\"X\"], x),\n",
    "            \"Y\": ([\"Y\"], y),\n",
    "            \"bias_mV\": ([\"bias_mV\"], bias_mV)\n",
    "        }\n",
    "    )\n",
    "    grid_xr.attrs[\"title\"] = title\n",
    "    #grid_xr.attrs['image_size'] = \n",
    "    #grid_xr.attrs['samlpe'] = \n",
    "    \n",
    "    grid_xr.attrs['image_size']= [size_x,size_y]\n",
    "    grid_xr.attrs['X_spacing']= step_dx\n",
    "    grid_xr.attrs['Y_spacing']= step_dy    \n",
    "    grid_xr.attrs['freq_X_spacing']= 1/step_dx\n",
    "    grid_xr.attrs['freq_Y_spacing']= np.nan\n",
    "    \n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        grid_xr.assign_coords( X = (grid_xr.X + cntr_x -  size_x/2))\n",
    "        grid_xr.assign_coords( Y = (grid_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "    \n",
    "    \n",
    "    return grid_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc9430-17e8-4ff9-9bbc-7782236e0c2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=blue>5. Gwyddion 2D image to PANDAS Dataframe or Xarray </font>\n",
    "### 5.1. gwy_image2df \n",
    "* convert to df \n",
    "### 5.2. gwy_df_channel2xr \n",
    "* convert to xr\n",
    "* need some upgrade.. (later) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9a9226b-4b6a-498c-86ff-404719d17dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gwy_img2df(gwy_file_name):\n",
    "    \"\"\"\n",
    "    Load data from a Gwyddion file and convert it into a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    gwy_file_name (str): The name of the Gwyddion file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing the data from the Gwyddion file.\n",
    "\n",
    "    This function loads data from a Gwyddion file specified by `gwy_file_name` and converts\n",
    "    it into a Pandas DataFrame. It first checks if the required 'gwyfile' module is installed\n",
    "    and installs it if not. The resulting DataFrame contains the data fields from the Gwyddion\n",
    "    file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import gwyfile\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named gwyfile')\n",
    "        %pip install gwyfile\n",
    "        import gwyfile\n",
    "\n",
    "    gwyfile_df = pd.DataFrame(gwyfile.util.get_datafields(gwyfile.load(gwy_file_name)))\n",
    "\n",
    "    # Set display format for scientific notation\n",
    "    pd.set_option('display.float_format', '{:.3e}'.format)\n",
    "\n",
    "    return gwyfile_df\n",
    "\n",
    "\n",
    "#gwy_df = gwyImage2df( file_list_df.file_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2efb2bee-f46e-4d6c-bd41-658b0f104e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "def gwy_df_ch2xr(gwy_df, ch_N=0):\n",
    "    \"\"\"\n",
    "    Convert channel data from a Pandas DataFrame to an xarray DataArray format.\n",
    "\n",
    "    Parameters:\n",
    "    gwy_df (pd.DataFrame): The input Pandas DataFrame containing channel data.\n",
    "    ch_N (int, optional): The channel index to convert (default is 0).\n",
    "\n",
    "    Returns:\n",
    "    xr.DataArray: An xarray DataArray containing the channel data with proper coordinates.\n",
    "    \n",
    "    This function takes a DataFrame (`gwy_df`) and an optional `ch_N` parameter to specify\n",
    "    which channel to convert into an xarray DataArray format. It reshapes the channel data\n",
    "    into a 2D DataFrame, stacks it, and assigns 'Y' and 'X' coordinates with proper scaling.\n",
    "    \n",
    "    Parameters:\n",
    "    - gwy_df (pd.DataFrame): The input Pandas DataFrame containing channel data.\n",
    "    - ch_N (int, optional): The channel index to convert (default is 0).\n",
    "\n",
    "    Returns:\n",
    "    - xr.DataArray: An xarray DataArray containing the channel data with proper coordinates.\n",
    "\n",
    "    This function takes a Pandas DataFrame (`gwy_df`) containing channel data and an optional\n",
    "    parameter `ch_N` to specify the channel index to convert. It reshapes the channel data into\n",
    "    a 2D DataFrame, stacks it, and assigns 'Y' and 'X' coordinates with proper scaling. The result\n",
    "    is returned as an xarray DataArray.\n",
    "\n",
    "    Example:\n",
    "    ch_data = gwy_df_ch2xr(my_dataframe, ch_N=1)\n",
    "    print(ch_data)\n",
    "    \"\"\"\n",
    "    # Extract the channel data from the DataFrame\n",
    "    chN_df = gwy_df.iloc[:, ch_N]\n",
    "\n",
    "    # Reshape the channel data into a 2D DataFrame and stack it\n",
    "    chNdf_temp = pd.DataFrame(chN_df.data.reshape((chN_df.yres, chN_df.xres))).stack()\n",
    "\n",
    "    # Rename the indices as 'Y' and 'X'\n",
    "    chNdf_temp = chNdf_temp.rename_axis(['Y', 'X'])\n",
    "\n",
    "    # Calculate the x and y step sizes\n",
    "    x_step = chN_df.xreal / chN_df.xres\n",
    "    y_step = chN_df.yreal / chN_df.yres\n",
    "\n",
    "    # Convert the DataFrame to an xarray DataArray\n",
    "    chNxr = chNdf_temp.to_xarray()\n",
    "\n",
    "    # Assign coordinates 'X' and 'Y' with proper scaling\n",
    "    if np.isnan(chN_df['xoff']):\n",
    "        chN_df.xoff = 0\n",
    "    else : pass\n",
    "    if np.isnan(chN_df['yoff']):\n",
    "        chN_df.yoff = 0\n",
    "    else : pass\n",
    "    chNxr = chNxr.assign_coords(X=chNxr.X.values * x_step+chN_df.xoff, Y=chNxr.Y.values * y_step+chN_df.xoff)\n",
    "\n",
    "    return chNxr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "140e6471-6538-4b72-8190-947552298c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gwy_df2xr (gwy_df):\n",
    "    \"\"\"\n",
    "    Convert a Pandas DataFrame into a dictionary of Xarray DataArrays and Xarray Datasets.\n",
    "\n",
    "    Parameters:\n",
    "    gwy_df (pandas.DataFrame): The input DataFrame to be converted.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing Xarray DataArrays and Xarray Datasets.\n",
    "\n",
    "    This function takes a Pandas DataFrame 'gwy_df' and performs the following steps:\n",
    "    1. Extracts unique 'xres' values from the DataFrame.\n",
    "    2. Creates a list to store the results.\n",
    "    3. Groups the DataFrame by each unique 'xres' value and creates a separate DataFrame for each group.\n",
    "    4. Checks if each group has the same 'yres' values; if yes, it appends the group to the results list.\n",
    "    5. Initializes an empty dictionary to store Xarray DataArrays and Xarray Datasets.\n",
    "    6. Prepares empty Xarray DataArrays and adds them to the dictionary.\n",
    "    7. Iterates through the dictionary, creating Xarray Datasets and populating them with converted DataArrays.\n",
    "    8. Returns a dictionary containing different-sized Xarray Datasets.\n",
    "\n",
    "    Note: This function relies on 'gwy_df_ch2xr', which should be defined separately to convert DataFrames to Xarray DataArrays.\n",
    "\n",
    "    Example:\n",
    "    gwy_dict = gwy_df2xr(my_dataframe)\n",
    "    for key, value in gwy_dict.items():\n",
    "        print(f\"Name: {key}, Data: {value}\")\n",
    "    \"\"\"\n",
    "    # Get unique xres values.\n",
    "    unique_xres_values = gwy_df.loc['xres'].unique()\n",
    "\n",
    "    # Create a list to store the results.\n",
    "    result_dfs = []\n",
    "    # Create groups for each xres value and create a separate DataFrame for each group.\n",
    "    for xres_value in unique_xres_values:\n",
    "        group_df = gwy_df[gwy_df.columns[gwy_df.loc['xres'] == xres_value]]\n",
    "        # group_df with the same xres\n",
    "        unique_yres_values = group_df.loc['yres'].unique()\n",
    "        if len(unique_yres_values) == 1:\n",
    "            result_dfs.append(group_df)\n",
    "        else:\n",
    "            for yres_value in unique_yres_values:\n",
    "                group_df = gwy_df[gwy_df.columns[gwy_df.loc['yres'] == yres_value]]\n",
    "                result_dfs.append(group_df)\n",
    "        \n",
    "    # result_dfs is group_dfs list with different 'xres'\n",
    "    # group_dfs = channels with unique xres&yres\n",
    "    gwy_xr_dict = {}\n",
    "    # prepare empty dictionary for gwy_xrs \n",
    "    # this is because of different X&Y size of eqch group.  \n",
    "    for results_df_i in range(1,len(result_dfs)+1):\n",
    "        # number of unique groups in result_df \n",
    "\n",
    "        gwy_xr_dict[f'gwy_xr{results_df_i}'] = xr.DataArray()\n",
    "        #prepare Data Set\n",
    "        # Create a dictionary to store empty Xarrays (DataArrays)\n",
    "\n",
    "\n",
    "    for i, gwy_xr_i in enumerate(gwy_xr_dict.keys()):\n",
    "        # call each gwy_xrs\n",
    "        # use keys() \n",
    "        print(gwy_xr_i)\n",
    "        gwy_xr_j  = xr.Dataset()\n",
    "        for j, group_df in enumerate(result_dfs[i]):\n",
    "            # call group_df from results_dfs\n",
    "            print (j)\n",
    "            xr_array = gwy_df_ch2xr(result_dfs[i], ch_N=j)\n",
    "            gwy_xr_j[result_dfs[i].columns[j]] = xr_array\n",
    "            # convert single dataframe, ch_N = j as a xr_array \n",
    "\n",
    "            gwy_xr_dict[gwy_xr_i] = gwy_xr_j\n",
    "            # save Data array in empty DataSet\n",
    "    # Xarray dictionary consist of different size DataSet     \n",
    "    return gwy_xr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d0c56-130c-4f16-b574-a7aeb4413a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cfd16fc7-51e8-4df1-98b4-2cd4d8e28317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_gwy_xr_data_vars(variable):\n",
    "    # Check if \"Corrected\" is included\n",
    "    if \"FFT\" in variable or \"fft\" in variable:\n",
    "        return variable\n",
    "    else :\n",
    "        if \"Corrected\" in variable:\n",
    "            variable = variable.replace(\"Corrected\", \"_C\")\n",
    "            # Check if \"Z\" is included\n",
    "            if \"Z\" in variable or \"z(\" in variable:\n",
    "                # Check if \"forward\" is included\n",
    "                if \"Forward\" in variable or \"fwd\" in variable:            \n",
    "                    # Get the index of the last '_C'.\n",
    "                    #index = variable.rfind(\"_C\")\n",
    "                    #return variable.replace(variable[:index], \"z_f\")\n",
    "                    return variable.replace(variable, \"z_f_C\")\n",
    "                # Check if \"backward\" is included\n",
    "                elif \"Backward\" in variable or \"bwd\" in variable:\n",
    "                    # Get the index of the last '_C'.\n",
    "                    #index = variable.rfind(\"_C\")\n",
    "                    #return variable.replace(variable[:index], \"z_b\")\n",
    "                    return variable.replace(variable, \"z_b_C\")\n",
    "\n",
    "            # Check if \"LI\" is included\n",
    "            elif \"LI\" in variable:\n",
    "                # Check if \"X\" and \"forward\" are included\n",
    "                if \"X\" in variable : \n",
    "                    if \"Forward\" in variable or \"fwd\" in variable:\n",
    "                        # Get the index of the last '_C'.\n",
    "                        #index = variable.rfind(\"_C\")\n",
    "                        #return variable.replace(variable[:index], \"LIX_f\")\n",
    "                        return variable.replace(variable, \"LIX_f_C\")\n",
    "                    if \"Backward\" in variable or \"bwd\" in variable:\n",
    "                        # Get the index of the last '_C'.\n",
    "                        #index = variable.rfind(\"_C\")\n",
    "                        #return variable.replace(variable[:index], \"LIX_b\")\n",
    "                        return variable.replace(variable, \"LIX_b_C\")\n",
    "\n",
    "                elif \"Y\" in variable : \n",
    "                    if \"Forward\" in variable or \"fwd\" in variable:\n",
    "                        # Get the index of the last '_C'.\n",
    "                        #index = variable.rfind(\"_C\")\n",
    "                        #return variable.replace(variable[:index], \"LIY_f\")\n",
    "                        return variable.replace(variable, \"LIY_f_C\")\n",
    "                    if \"Backward\" in variable or \"bwd\" in variable:\n",
    "                        # Get the index of the last '_C'.\n",
    "                        #index = variable.rfind(\"_C\")\n",
    "                        #return variable.replace(variable[:index], \"LIY_b\")\n",
    "                        return variable.replace(variable, \"LIY_b_C\")\n",
    "            else:\n",
    "                return variable\n",
    "        else:\n",
    "            if \"Z\" in variable or  \"z(\" in variable:\n",
    "                # Check if \"forward\" is included\n",
    "                if \"Forward\" in variable or \"fwd\" in variable:            \n",
    "                    return variable.replace(variable, \"z_f\")\n",
    "                # Check if \"backward\" is included\n",
    "                elif \"Backward\" in variable or \"bwd\" in variable:\n",
    "                    return variable.replace(variable, \"z_b\")\n",
    "\n",
    "            elif \"LI\" in variable:\n",
    "                # Check if \"X\" and \"forward\" are included\n",
    "                if \"X\" in variable : \n",
    "                    if \"Forward\" in variable or \"fwd\" in variable:\n",
    "                        return variable.replace(variable, \"LIX_f\")\n",
    "                    if \"Backward\" in variable or \"bwd\" in variable:\n",
    "                        return variable.replace(variable, \"LIX_b\")\n",
    "        return variable\n",
    "\n",
    "# Rename the data variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556f66a-32d9-4a80-a6a4-0e05d4720963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_square(image_xr, ch_name = 'z_f_C'):\n",
    "    \"\"\"\n",
    "    Crop a square from the input image_xr centered at the center of the image.\n",
    "    # DO NOT APPLY WHEN PIXEL ASPECT RATIO IS NOT 1 \n",
    "    # ( eg. 1024x512 case==> not apply ) \n",
    "    # Use it for after affine transformed lattice \n",
    "    \n",
    "    Args:\n",
    "        image (ndarray): Input image as a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Cropped square from the input image.\n",
    "    \"\"\"\n",
    "    # Create the image size and generate nan values in a rectangle\n",
    "    image_size = image_xr[ch_name].shape\n",
    "    image_copy = np.copy(image_xr[ch_name])\n",
    "    #image_copy[np.random.choice(image_size[0], 10), np.random.choice(image_size[1], 10)] = np.nan\n",
    "\n",
    "    # Find the largest square without nan values\n",
    "    max_square_size = 0\n",
    "    for size in range(min(image_size)):\n",
    "        y_start = (image_size[0]) // 2 - size // 2\n",
    "        y_end = (image_size[0]) // 2 + size // 2\n",
    "        x_start = (image_size[1]) // 2 - size // 2\n",
    "        x_end = (image_size[1]) // 2 + size // 2\n",
    "        if np.isnan(image_copy[y_start:y_end+1, x_start:x_end+1]).any():\n",
    "            break\n",
    "    may_square_size = size\n",
    "\n",
    "    # Create a small square with the same size as the large image\n",
    "    #square = np.zeros((may_square_size, may_square_size))\n",
    "\n",
    "    # Set the center coordinates to match the large image and draw the small square\n",
    "    center_y = (image_size[0]+1) // 2\n",
    "    center_x = (image_size[1]+1) // 2\n",
    "    center = (center_y, center_x)\n",
    "    y_start = center_y - may_square_size // 2\n",
    "    y_end = center_y + may_square_size // 2 \n",
    "    x_start = center_x - may_square_size // 2\n",
    "    x_end = center_x + may_square_size // 2 \n",
    "    print(center, 'may_square_size', may_square_size)\n",
    "    print ('X',x_start,y_end,'Y',y_start, y_end)\n",
    "    image_xr_xycrop = image_xr.isel(Y = slice (y_start-1, y_end+1), X = slice (x_start-1,x_end+1))\n",
    "    #image_xr_xycrop = image_xr_xcrop.isel(Y = slice (y_start-1, y_end+1))\n",
    "    \n",
    "    \n",
    "    # Adjust XY size for 1:1 ratio. \n",
    "    size_min = min(image_xr_xycrop.X.shape, image_xr_xycrop.Y.shape)[0]\n",
    "    image_xr_xycrop = image_xr_xycrop.isel( Y = slice (0,size_min),X = slice (0,size_min))\n",
    "    # strangely without this line Y_size != X size \n",
    "    \n",
    "    return image_xr_xycrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e4f29b8-099c-4dc6-81a7-59f705b3b53b",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_spacing != Y_spacing\n",
      "step_dx/step_dy =  2.0\n",
      "xrdata ==> reshaped\n",
      "gwy_xr step_dx, step_dy =  [\"'Y': 1024, 'X': 1024\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:                  (Y: 1024, X: 1024)\n",
       "Coordinates:\n",
       "  * X                        (X) float64 1.1e-07 1.1e-07 ... 1.499e-07 1.5e-07\n",
       "  * Y                        (Y) float64 1.1e-07 1.1e-07 ... 1.499e-07 1.499e-07\n",
       "Data variables:\n",
       "    z_f                      (Y, X) float64 -3.923e-08 -3.923e-08 ... -3.923e-08\n",
       "    z_b                      (Y, X) float64 -3.912e-08 -3.911e-08 ... -3.937e-08\n",
       "    Current (Forward)        (Y, X) float64 1.99e-10 1.981e-10 ... 2.004e-10\n",
       "    Current (Backward)       (Y, X) float64 1.849e-10 2.034e-10 ... 2.002e-10\n",
       "    LIX_f                    (Y, X) float64 1.338e-12 1.397e-12 ... 1.378e-12\n",
       "    LIX_b                    (Y, X) float64 3.378e-12 3.756e-12 ... 1.245e-12\n",
       "    LI_Demod_1_Y (Forward)   (Y, X) float64 -2.519e-13 1.868e-13 ... -5.375e-13\n",
       "    LI_Demod_1_Y (Backward)  (Y, X) float64 -1.035e-12 1.518e-12 ... 5.566e-13\n",
       "Attributes:\n",
       "    ref_a0:   3.8e-10\n",
       "    ref_q0:   2631578947.368421</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-f23121d7-9ebf-465f-822a-12a12bad517a' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-f23121d7-9ebf-465f-822a-12a12bad517a' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>Y</span>: 1024</li><li><span class='xr-has-index'>X</span>: 1024</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-bf8790f6-b407-40be-b2c9-bf20f1c6bfd9' class='xr-section-summary-in' type='checkbox'  checked><label for='section-bf8790f6-b407-40be-b2c9-bf20f1c6bfd9' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>X</span></div><div class='xr-var-dims'>(X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.1e-07 1.1e-07 ... 1.5e-07</div><input id='attrs-dcc880d8-a6d6-4dd5-8cfb-003c05eac415' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-dcc880d8-a6d6-4dd5-8cfb-003c05eac415' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9832bbac-71ec-4367-a121-f3fd66d7c8d3' class='xr-var-data-in' type='checkbox'><label for='data-9832bbac-71ec-4367-a121-f3fd66d7c8d3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>X_spacing :</span></dt><dd>3.902435302734376e-11</dd></dl></div><div class='xr-var-data'><pre>array([1.100000e-07, 1.100391e-07, 1.100781e-07, ..., 1.498828e-07,\n",
       "       1.499219e-07, 1.499609e-07])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>Y</span></div><div class='xr-var-dims'>(Y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.1e-07 1.1e-07 ... 1.499e-07</div><input id='attrs-5bf709ca-e49e-471c-971d-a67f8555cead' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-5bf709ca-e49e-471c-971d-a67f8555cead' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3b4565ca-928a-48d7-8182-0aff076310ef' class='xr-var-data-in' type='checkbox'><label for='data-3b4565ca-928a-48d7-8182-0aff076310ef' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>Y_spacing :</span></dt><dd>7.7972412109375e-11</dd></dl></div><div class='xr-var-data'><pre>array([1.100000e-07, 1.100390e-07, 1.100780e-07, ..., 1.498438e-07,\n",
       "       1.498829e-07, 1.499219e-07])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d4bc7583-bbea-4c8a-991c-05fc94fa7f03' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d4bc7583-bbea-4c8a-991c-05fc94fa7f03' class='xr-section-summary' >Data variables: <span>(8)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>z_f</span></div><div class='xr-var-dims'>(Y, X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-3.923e-08 ... -3.923e-08</div><input id='attrs-cfa51ac3-2445-4146-b675-71cff308617d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-cfa51ac3-2445-4146-b675-71cff308617d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0c1c4fd1-5d42-476a-9ff8-894fa5188feb' class='xr-var-data-in' type='checkbox'><label for='data-0c1c4fd1-5d42-476a-9ff8-894fa5188feb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[-3.92303734e-08, -3.92331694e-08, -3.92325370e-08, ...,\n",
       "        -3.92410387e-08, -3.92652255e-08, -3.92829891e-08],\n",
       "       [-3.92644586e-08, -3.92638632e-08, -3.92555822e-08, ...,\n",
       "        -3.92726713e-08, -3.92827801e-08, -3.92890459e-08],\n",
       "       [-3.92985437e-08, -3.92945571e-08, -3.92786275e-08, ...,\n",
       "        -3.93043039e-08, -3.93003346e-08, -3.92951027e-08],\n",
       "       ...,\n",
       "       [-3.92572765e-08, -3.92560542e-08, -3.92539762e-08, ...,\n",
       "        -3.92266269e-08, -3.92256139e-08, -3.92246022e-08],\n",
       "       [-3.92564602e-08, -3.92551314e-08, -3.92532309e-08, ...,\n",
       "        -3.92292391e-08, -3.92279830e-08, -3.92273848e-08],\n",
       "       [-3.92556439e-08, -3.92542086e-08, -3.92524855e-08, ...,\n",
       "        -3.92318514e-08, -3.92303521e-08, -3.92301674e-08]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>z_b</span></div><div class='xr-var-dims'>(Y, X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-3.912e-08 ... -3.937e-08</div><input id='attrs-64979d4d-169d-4d10-a890-0e8b05909d92' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-64979d4d-169d-4d10-a890-0e8b05909d92' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f22ef5ee-2602-492e-8f20-67abde34c564' class='xr-var-data-in' type='checkbox'><label for='data-f22ef5ee-2602-492e-8f20-67abde34c564' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[-3.91184045e-08, -3.91126065e-08, -3.91115620e-08, ...,\n",
       "        -3.91540382e-08, -3.91528481e-08, -3.91456219e-08],\n",
       "       [-3.91096840e-08, -3.91071850e-08, -3.91050598e-08, ...,\n",
       "        -3.91744410e-08, -3.91714585e-08, -3.91659785e-08],\n",
       "       [-3.91009635e-08, -3.91017636e-08, -3.90985576e-08, ...,\n",
       "        -3.91948439e-08, -3.91900690e-08, -3.91863352e-08],\n",
       "       ...,\n",
       "       [-3.93974605e-08, -3.93961076e-08, -3.93958130e-08, ...,\n",
       "        -3.93619044e-08, -3.93615838e-08, -3.93607192e-08],\n",
       "       [-3.93961224e-08, -3.93951226e-08, -3.93949825e-08, ...,\n",
       "        -3.93639612e-08, -3.93632058e-08, -3.93634645e-08],\n",
       "       [-3.93947843e-08, -3.93941377e-08, -3.93941519e-08, ...,\n",
       "        -3.93660180e-08, -3.93648278e-08, -3.93662098e-08]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>Current (Forward)</span></div><div class='xr-var-dims'>(Y, X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.99e-10 1.981e-10 ... 2.004e-10</div><input id='attrs-334e8918-c998-4568-8f43-04a89f0e695b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-334e8918-c998-4568-8f43-04a89f0e695b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c8d32b97-8a3e-4d2e-9fec-9d0be41b752a' class='xr-var-data-in' type='checkbox'><label for='data-c8d32b97-8a3e-4d2e-9fec-9d0be41b752a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1.99027905e-10, 1.98114983e-10, 2.03027178e-10, ...,\n",
       "        2.06626605e-10, 1.62259275e-10, 2.07816167e-10],\n",
       "       [1.98647672e-10, 2.03967279e-10, 2.10398626e-10, ...,\n",
       "        2.05025786e-10, 1.83500407e-10, 2.06830005e-10],\n",
       "       [1.98267439e-10, 2.09819575e-10, 2.17770073e-10, ...,\n",
       "        2.03424968e-10, 2.04741539e-10, 2.05843843e-10],\n",
       "       ...,\n",
       "       [2.00866872e-10, 2.01533369e-10, 2.02676605e-10, ...,\n",
       "        2.01143488e-10, 2.02573017e-10, 2.00104324e-10],\n",
       "       [2.00466446e-10, 2.01495471e-10, 2.02673028e-10, ...,\n",
       "        2.01461117e-10, 2.01844196e-10, 2.00232783e-10],\n",
       "       [2.00066019e-10, 2.01457573e-10, 2.02669451e-10, ...,\n",
       "        2.01778746e-10, 2.01115374e-10, 2.00361241e-10]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>Current (Backward)</span></div><div class='xr-var-dims'>(Y, X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.849e-10 2.034e-10 ... 2.002e-10</div><input id='attrs-a3103e5b-e94f-4a77-8270-546f605a8327' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a3103e5b-e94f-4a77-8270-546f605a8327' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7fabe94e-d605-4b79-9ae6-2f48691b4229' class='xr-var-data-in' type='checkbox'><label for='data-7fabe94e-d605-4b79-9ae6-2f48691b4229' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[1.84883067e-10, 2.03399089e-10, 1.93971755e-10, ...,\n",
       "        1.98235151e-10, 1.97983269e-10, 1.97069083e-10],\n",
       "       [1.93832000e-10, 2.00637925e-10, 1.95733953e-10, ...,\n",
       "        1.97281750e-10, 1.96508469e-10, 1.99030482e-10],\n",
       "       [2.02780932e-10, 1.97876762e-10, 1.97496151e-10, ...,\n",
       "        1.96328349e-10, 1.95033669e-10, 2.00991882e-10],\n",
       "       ...,\n",
       "       [1.98594668e-10, 1.99187317e-10, 2.00118675e-10, ...,\n",
       "        1.99304086e-10, 1.99792967e-10, 1.99394646e-10],\n",
       "       [2.00189850e-10, 1.99108215e-10, 2.00347101e-10, ...,\n",
       "        1.98948989e-10, 2.01186620e-10, 1.99787814e-10],\n",
       "       [2.01785033e-10, 1.99029113e-10, 2.00575528e-10, ...,\n",
       "        1.98593891e-10, 2.02580272e-10, 2.00180983e-10]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>LIX_f</span></div><div class='xr-var-dims'>(Y, X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.338e-12 1.397e-12 ... 1.378e-12</div><input id='attrs-a7106445-0fb1-441c-835a-bc3aa9b0a3da' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a7106445-0fb1-441c-835a-bc3aa9b0a3da' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e256bbcc-8938-4338-8f10-7550547ea9e3' class='xr-var-data-in' type='checkbox'><label for='data-e256bbcc-8938-4338-8f10-7550547ea9e3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[ 1.33755950e-12,  1.39725459e-12,  1.69401872e-12, ...,\n",
       "        -5.09921160e-13,  9.41370347e-13, -9.92245789e-13],\n",
       "       [ 1.22892786e-12,  1.22682166e-12,  1.41690304e-12, ...,\n",
       "         1.04160096e-14,  1.03527056e-12,  3.72592853e-13],\n",
       "       [ 1.12029621e-12,  1.05638872e-12,  1.13978735e-12, ...,\n",
       "         5.30753179e-13,  1.12917077e-12,  1.73743150e-12],\n",
       "       ...,\n",
       "       [ 5.67949183e-13,  6.28064731e-13,  3.11454782e-13, ...,\n",
       "         2.43870828e-12,  2.68594142e-12,  1.72088687e-12],\n",
       "       [ 1.13878717e-12,  8.56919359e-13,  5.39375904e-13, ...,\n",
       "         2.35758834e-12,  2.37807376e-12,  1.54935596e-12],\n",
       "       [ 1.70962516e-12,  1.08577399e-12,  7.67297026e-13, ...,\n",
       "         2.27646839e-12,  2.07020609e-12,  1.37782504e-12]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>LIX_b</span></div><div class='xr-var-dims'>(Y, X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>3.378e-12 3.756e-12 ... 1.245e-12</div><input id='attrs-ba474c96-9a10-4c4f-92bc-17af7ae8828b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ba474c96-9a10-4c4f-92bc-17af7ae8828b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-759688ef-8215-4a1d-814b-920be54d9671' class='xr-var-data-in' type='checkbox'><label for='data-759688ef-8215-4a1d-814b-920be54d9671' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[ 3.37772453e-12,  3.75575005e-12,  2.40408442e-13, ...,\n",
       "         1.99238195e-12,  1.51244880e-12,  9.96664123e-13],\n",
       "       [ 2.77476063e-12,  2.65117373e-12,  5.21962278e-13, ...,\n",
       "         2.50514208e-12,  2.10200047e-12,  1.76410968e-12],\n",
       "       [ 2.17179674e-12,  1.54659740e-12,  8.03516113e-13, ...,\n",
       "         3.01790221e-12,  2.69155215e-12,  2.53155525e-12],\n",
       "       ...,\n",
       "       [ 8.96684094e-13,  5.22812334e-13,  4.57276149e-13, ...,\n",
       "         1.94996320e-12,  1.24114363e-12,  1.44633953e-12],\n",
       "       [ 6.00611859e-13,  2.92789046e-13,  1.11593585e-13, ...,\n",
       "         1.93201521e-12,  1.49003609e-12,  1.34548327e-12],\n",
       "       [ 3.04539624e-13,  6.27657580e-14, -2.34088980e-13, ...,\n",
       "         1.91406721e-12,  1.73892855e-12,  1.24462701e-12]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>LI_Demod_1_Y (Forward)</span></div><div class='xr-var-dims'>(Y, X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-2.519e-13 1.868e-13 ... -5.375e-13</div><input id='attrs-e6de311f-f77d-47f6-83d7-e34f95c2ae69' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e6de311f-f77d-47f6-83d7-e34f95c2ae69' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-31b6686d-de05-46c6-86b1-d5cf887b46f0' class='xr-var-data-in' type='checkbox'><label for='data-31b6686d-de05-46c6-86b1-d5cf887b46f0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[-2.51892772e-13,  1.86759191e-13, -3.03593251e-13, ...,\n",
       "         2.83774514e-11,  1.65438704e-11,  1.16634705e-11],\n",
       "       [-1.32004517e-13, -3.86091809e-14, -2.42484546e-13, ...,\n",
       "         1.36254586e-11,  8.03438475e-12,  5.68440349e-12],\n",
       "       [-1.21162612e-14, -2.63977553e-13, -1.81375842e-13, ...,\n",
       "        -1.12653427e-12, -4.75100942e-13, -2.94663564e-13],\n",
       "       ...,\n",
       "       [ 5.47875549e-13, -3.31955723e-13, -5.06438165e-13, ...,\n",
       "        -1.11771467e-12, -2.78526128e-13, -8.92587401e-13],\n",
       "       [ 1.21192581e-13, -2.34468092e-13, -2.57325798e-13, ...,\n",
       "        -1.07168995e-12, -4.57925831e-13, -7.15031369e-13],\n",
       "       [-3.05490388e-13, -1.36980461e-13, -8.21343031e-15, ...,\n",
       "        -1.02566523e-12, -6.37325533e-13, -5.37475338e-13]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>LI_Demod_1_Y (Backward)</span></div><div class='xr-var-dims'>(Y, X)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-1.035e-12 1.518e-12 ... 5.566e-13</div><input id='attrs-3909334c-e9b7-4083-8f8b-400dce190529' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3909334c-e9b7-4083-8f8b-400dce190529' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8d92b298-305c-45ad-8229-6dcbc086f90d' class='xr-var-data-in' type='checkbox'><label for='data-8d92b298-305c-45ad-8229-6dcbc086f90d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[-1.03503436e-12,  1.51809934e-12,  4.14646963e-12, ...,\n",
       "         2.52643566e-12,  4.33683558e-12,  6.49815228e-12],\n",
       "       [-5.82442954e-13,  9.96474125e-13,  2.28323378e-12, ...,\n",
       "         1.20434242e-12,  2.14819981e-12,  3.14083895e-12],\n",
       "       [-1.29851546e-13,  4.74848909e-13,  4.19997940e-13, ...,\n",
       "        -1.17750826e-13, -4.04359515e-14, -2.16474385e-13],\n",
       "       ...,\n",
       "       [ 3.01343795e-14,  6.15230328e-13,  1.29107402e-13, ...,\n",
       "        -3.26399802e-13, -6.49371931e-13, -1.75909976e-13],\n",
       "       [-2.55679047e-14,  6.21446509e-13,  2.20970884e-13, ...,\n",
       "        -7.17303579e-14, -6.27787341e-13,  1.90362637e-13],\n",
       "       [-8.12701889e-14,  6.27662690e-13,  3.12834367e-13, ...,\n",
       "         1.82939086e-13, -6.06202751e-13,  5.56635250e-13]])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-69955dbb-a6ac-4daf-80de-b29ba98e65d3' class='xr-section-summary-in' type='checkbox'  ><label for='section-69955dbb-a6ac-4daf-80de-b29ba98e65d3' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>X</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b446310e-f1bb-4f7a-9e64-9c05e7ac1a1d' class='xr-index-data-in' type='checkbox'/><label for='index-b446310e-f1bb-4f7a-9e64-9c05e7ac1a1d' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([               1.1e-07, 1.1003906250000001e-07,         1.10078125e-07,\n",
       "       1.1011718750000001e-07,          1.1015625e-07, 1.1019531250000001e-07,\n",
       "               1.10234375e-07, 1.1027343750000001e-07,           1.103125e-07,\n",
       "       1.1035156250000001e-07,\n",
       "       ...\n",
       "               1.49609375e-07, 1.4964843750000002e-07, 1.4968750000000002e-07,\n",
       "       1.4972656250000003e-07,         1.49765625e-07, 1.4980468750000001e-07,\n",
       "       1.4984375000000002e-07,        1.498828125e-07,         1.49921875e-07,\n",
       "       1.4996093750000001e-07],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;X&#x27;, length=1024))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>Y</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b6e6ea36-30b0-4227-826a-b534f2aee0bc' class='xr-index-data-in' type='checkbox'/><label for='index-b6e6ea36-30b0-4227-826a-b534f2aee0bc' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([               1.1e-07, 1.1003902431573803e-07, 1.1007804863147606e-07,\n",
       "       1.1011707294721408e-07,  1.101560972629521e-07, 1.1019512157869013e-07,\n",
       "       1.1023414589442816e-07, 1.1027317021016618e-07,  1.103121945259042e-07,\n",
       "       1.1035121884164223e-07,\n",
       "       ...\n",
       "       1.4957065615835777e-07,  1.496096804740958e-07, 1.4964870478983385e-07,\n",
       "       1.4968772910557186e-07, 1.4972675342130988e-07, 1.4976577773704792e-07,\n",
       "       1.4980480205278594e-07, 1.4984382636852395e-07,   1.49882850684262e-07,\n",
       "               1.49921875e-07],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;Y&#x27;, length=1024))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-18e5a928-e78e-4469-9c76-fd35e36514d1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-18e5a928-e78e-4469-9c76-fd35e36514d1' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>ref_a0 :</span></dt><dd>3.8e-10</dd><dt><span>ref_q0 :</span></dt><dd>2631578947.368421</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                  (Y: 1024, X: 1024)\n",
       "Coordinates:\n",
       "  * X                        (X) float64 1.1e-07 1.1e-07 ... 1.499e-07 1.5e-07\n",
       "  * Y                        (Y) float64 1.1e-07 1.1e-07 ... 1.499e-07 1.499e-07\n",
       "Data variables:\n",
       "    z_f                      (Y, X) float64 -3.923e-08 -3.923e-08 ... -3.923e-08\n",
       "    z_b                      (Y, X) float64 -3.912e-08 -3.911e-08 ... -3.937e-08\n",
       "    Current (Forward)        (Y, X) float64 1.99e-10 1.981e-10 ... 2.004e-10\n",
       "    Current (Backward)       (Y, X) float64 1.849e-10 2.034e-10 ... 2.002e-10\n",
       "    LIX_f                    (Y, X) float64 1.338e-12 1.397e-12 ... 1.378e-12\n",
       "    LIX_b                    (Y, X) float64 3.378e-12 3.756e-12 ... 1.245e-12\n",
       "    LI_Demod_1_Y (Forward)   (Y, X) float64 -2.519e-13 1.868e-13 ... -5.375e-13\n",
       "    LI_Demod_1_Y (Backward)  (Y, X) float64 -1.035e-12 1.518e-12 ... 5.566e-13\n",
       "Attributes:\n",
       "    ref_a0:   3.8e-10\n",
       "    ref_q0:   2631578947.368421"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gwy_intrplt_xr(xrdata):\n",
    "    \"\"\"\n",
    "    Perform interpolation on the given xrdata.\n",
    "\n",
    "    Parameters:\n",
    "    - xrdata (xarray.Dataset): Input xr dataset to be interpolated.\n",
    "\n",
    "    Returns:\n",
    "    - xrdata (xarray.Dataset): Interpolated xr dataset.\n",
    "    \"\"\"\n",
    "    ############################\n",
    "    # check the XY ratio /w spacing size\n",
    "    ############################ \n",
    "    if  xrdata.X.X_spacing == xrdata.Y.Y_spacing: \n",
    "        pass\n",
    "    else : \n",
    "        print ('X_spacing != Y_spacing')\n",
    "    # if xy size is not same, report it! \n",
    "    step_dx = xrdata.X.X_spacing\n",
    "    step_dy = xrdata.Y.Y_spacing\n",
    "    if step_dx != step_dy :\n",
    "        xystep_ratio = xrdata.dims['X']/xrdata.dims['Y'] # check the XY pixel_ratio\n",
    "        X_interp = np.linspace(xrdata.X[0], xrdata.X[-1], xrdata.X.shape[0]*1)\n",
    "        step_dx = step_dx # step_dx check \n",
    "\n",
    "        Y_interp = np.linspace(xrdata.Y[0], xrdata.Y[-1], int(xrdata.Y.shape[0]*xystep_ratio)) \n",
    "        step_dy = step_dy/ xystep_ratio # step_dy check \n",
    "\n",
    "        # interpolation ratio should be int\n",
    "        xrdata= xrdata.interp(X = X_interp, Y = Y_interp, method=\"linear\")\n",
    "        print('step_dx/step_dy = ', xystep_ratio)\n",
    "        print ('xrdata ==> reshaped')\n",
    "    else: print('step_dx == step_dy')\n",
    "        \n",
    "    print('gwy_xr', 'step_dx, step_dy = ', \n",
    "      re.findall('\\{([^}]+)', str(xrdata.dims)))\n",
    "    return xrdata\n",
    "\n",
    "#gwy_intrplt_xr(gwy_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf94cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b504f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
